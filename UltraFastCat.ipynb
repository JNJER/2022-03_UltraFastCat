{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2022-02-22 Ultra-fast categorization of image containing animals *in sillico*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hi! I am  [Jean-Nicolas Jérémie](https://github.com/JNJER) in this notebook, I will use the [Pytorch](https://pytorch.org/) library to run the networks and the [pandas](https://pandas.pydata.org/docs/getting_started/index.html) library to collect and display the results. This notebook focused on the training and the test of Deep convolutional neuronal networks (DCNNs) for ecological tasks such as detecting an animal in a natural scene.\n",
    "\n",
    "I uses transfer learning to train the DCNN, starting from a VGG16 network, taken from the `torchvision.models` library, pre-trained on the [Imagenet](http://image-net.org/) dataset which allows to perform label detection on naturals images for $K = 1000$ labels. Then re-train the whole network to perfom the same task but in a sub-set of $K = 1$ synset from the Imagenet dataset. The dataset I used here to train the networks is not multilabel (as we have the information about the occurence of only one synset on the scene), in order to train networks on independant task I choose to limit the output of the DCNN to $K = 1$ synset. \n",
    "Here, I am going to adopt differents strategies of transfer learning:\n",
    "\n",
    "* VGG General : Substitute the last layer of the Pytorch VGG16 network ($K = 1000$ labels) with a new layer build from a specific subset ($K = 10$ labels).\n",
    "* VGG Gray : Same architecture as the VGG General network but trained with images in grayscale.\n",
    "* VGG Scale : Same architecture as the VGG General network but trained with images of different size.\n",
    "\n",
    "The first part consist of the training of the network and the last part of this notebook is dedicated to the test of the robustness of the resulted networks while appliying various geometric tranformations to the input. Finally I analyse the similarities in the performances of the networks compared with physiological data. \n",
    "\n",
    "This notebook was done during my thesis at the Neurosciences Institute of Timone (INT) under the supervision of [Laurent PERRINET](https://laurentperrinet.github.io/). It is curated in the following [github repo](https://github.com/JNJER/2022-03_UltraFastCat)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Some useful links :* TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:08.276744Z",
     "iopub.status.busy": "2022-05-13T15:25:08.276317Z",
     "iopub.status.idle": "2022-05-13T15:25:09.056717Z",
     "shell.execute_reply": "2022-05-13T15:25:09.055405Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\r\n",
      "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\u001b[31m\r\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.1 is available.\r\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\r\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:09.062176Z",
     "iopub.status.busy": "2022-05-13T15:25:09.061807Z",
     "iopub.status.idle": "2022-05-13T15:25:09.793025Z",
     "shell.execute_reply": "2022-05-13T15:25:09.791590Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%mkdir -p UltraFastCat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainning process\n",
    "\n",
    "This part of the notebook focus on the training process of the network. I use the variables set in the scripts generated by the `Ìnit_src.ipynb` noteboook.\n",
    "The script `experiment_train.py`, a pretty classic trainning script with pytorch. Since I only have one synset to discriminate in the scene i use `criterion = nn.BCEWithLogitsLoss()` to compute the loss during the training process. For further statistical analyses, we extract factors (like the accuracy and loss) in a `pandas` object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:09.798924Z",
     "iopub.status.busy": "2022-05-13T15:25:09.798531Z",
     "iopub.status.idle": "2022-05-13T15:25:09.803743Z",
     "shell.execute_reply": "2022-05-13T15:25:09.802943Z"
    }
   },
   "outputs": [],
   "source": [
    "scriptname = 'UltraFastCat/experiment_train.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:09.807755Z",
     "iopub.status.busy": "2022-05-13T15:25:09.807513Z",
     "iopub.status.idle": "2022-05-13T15:25:09.816730Z",
     "shell.execute_reply": "2022-05-13T15:25:09.816035Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting UltraFastCat/experiment_train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {scriptname}\n",
    "from src.model import *  \n",
    "from PIL import ImageFile\n",
    "import math\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "def train_model(model, num_epochs, dataloaders, lr=args.lr, momentum=args.momentum, beta2=args.beta2, log_interval=100, **kwargs):\n",
    "    \n",
    "    model.to(device)\n",
    "    if beta2 > 0.: \n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=(momentum, beta2)) #, amsgrad=amsgrad)\n",
    "    else:\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum) # to set training variables\n",
    "\n",
    "    df_train = pd.DataFrame([], columns=['epoch', 'avg_loss', 'avg_acc', 'avg_loss_val', 'avg_acc_val', 'device_type']) \n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        loss_train = 0\n",
    "        acc_train = 0\n",
    "        for i, (images, labels) in enumerate(dataloaders['train']):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs[:,0], labels.float())\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_train += loss.item() * images.size(0)\n",
    "            preds = torch.round(torch.sigmoid(outputs[:,0].data))\n",
    "            acc_train += torch.sum(preds == labels.data)\n",
    "            \n",
    "        avg_loss = loss_train / dataset_sizes[task]['train']\n",
    "        avg_acc = acc_train / dataset_sizes[task]['train']\n",
    "           \n",
    "        with torch.no_grad():\n",
    "            loss_val = 0\n",
    "            acc_val = 0\n",
    "            for i, (images, labels) in enumerate(dataloaders['val']):\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs[:,0], labels.float())\n",
    "\n",
    "                loss_val += loss.item() * images.size(0)\n",
    "                preds = torch.round(torch.sigmoid(outputs[:,0].data))\n",
    "                acc_val += torch.sum(preds == labels.data)\n",
    "        \n",
    "            avg_loss_val = loss_val / dataset_sizes[task]['val']\n",
    "            avg_acc_val = acc_val / dataset_sizes[task]['val']\n",
    "        \n",
    "        df_train.loc[epoch] = {'epoch':epoch, 'avg_loss':avg_loss, 'avg_acc':float(avg_acc),\n",
    "                               'avg_loss_val':avg_loss_val, 'avg_acc_val':float(avg_acc_val), 'device_type':device.type}\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} : train= loss: {avg_loss:.4f} / acc : {avg_acc:.4f} - val= loss : {avg_loss_val:.4f} / acc : {avg_acc_val:.4f}\")\n",
    "\n",
    "    model.cpu()\n",
    "    torch.cuda.empty_cache()\n",
    "    return model, df_train\n",
    "\n",
    "# https://towardsdatascience.com/cross-entropy-for-classification-d98e7f974451\n",
    "criterion = nn.BCEWithLogitsLoss() #binary_cross_entropy_with_logits\n",
    "\n",
    "# Training and saving the network\n",
    "\n",
    "models_vgg = {}\n",
    "opt = {}\n",
    "n_output = 1\n",
    "all_models = []\n",
    "    \n",
    "# Downloading the model\n",
    "model_filenames = {}\n",
    "for task in args.tasks :\n",
    "    for model in args.model_names:\n",
    "        model_name = model+'_'+task\n",
    "        all_models.append(model_name)\n",
    "        model_filenames[model_name] = args.model_path + model_name + '.pt'\n",
    "        filename = f'results/{datetag}_{args.HOST}_train_{model_name}.json'\n",
    "\n",
    "        models_vgg[model_name] = torchvision.models.vgg16(pretrained=True) \n",
    "\n",
    "        num_features = models_vgg[model_name].classifier[-1].in_features\n",
    "        features = list(models_vgg[model_name].classifier.children())[:-1] # Remove last layer\n",
    "        features.extend([nn.Linear(num_features, n_output)]) # Add our layer with 10 outputs\n",
    "        models_vgg[model_name].classifier = nn.Sequential(*features) # Replace the model classifier\n",
    "\n",
    "        if os.path.isfile(model_filenames[model_name]):\n",
    "            print(\"Loading pretrained model for..\", model_name, ' from', model_filenames[model_name])\n",
    "\n",
    "            if device.type == 'cuda':\n",
    "                models_vgg[model_name].load_state_dict(torch.load(model_filenames[model_name])) #on GPU\n",
    "            else:\n",
    "                models_vgg[model_name].load_state_dict(torch.load(model_filenames[model_name], map_location=torch.device('cpu'))) #on CPU\n",
    "\n",
    "        else:\n",
    "            print(\"Re-training pretrained model...\", model_filenames[model_name])\n",
    "            since = time.time()\n",
    "            p = 1 if 'gray' in model_name  else 0\n",
    "            if 'scale' in model_name:\n",
    "                df_train = None\n",
    "                for image_size_ in args.image_sizes: # starting with low resolution images \n",
    "                    print(f\"Traning {model_name}, image_size = {image_size_}, p (Grayscale) = {p}\")\n",
    "                    (dataset_sizes, dataloaders, image_datasets, data_transforms) = datasets_transforms(image_size=image_size_, p=p)\n",
    "                    models_vgg[model_name], df_train_ = train_model(models_vgg[model_name], num_epochs=args.num_epochs//len(args.image_sizes),\n",
    "                                                                 dataloaders=dataloaders[task])\n",
    "                    df_train = df_train_ if df_train is None else df_train.append(df_train_, ignore_index=True)\n",
    "            else :\n",
    "                print(f\"Traning {model_name}, image_size = {args.image_size}, p (Grayscale) = {p}\")\n",
    "                (dataset_sizes, dataloaders, image_datasets, data_transforms) = datasets_transforms(image_size=args.image_size, p=p)\n",
    "                models_vgg[model_name], df_train = train_model(models_vgg[model_name], num_epochs=args.num_epochs,\n",
    "                                                            dataloaders=dataloaders[task])\n",
    "            torch.save(models_vgg[model_name].state_dict(), model_filenames[model_name])\n",
    "            df_train.to_json(filename)\n",
    "            elapsed_time = time.time() - since\n",
    "            print(f\"Training completed in {elapsed_time // 60:.0f}m {elapsed_time % 60:.0f}s\")\n",
    "            print()\n",
    "            \n",
    "updict = {\"vgg_16\" : torchvision.models.vgg16(pretrained=True)}\n",
    "updict.update(models_vgg)\n",
    "models_vgg = updict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:09.820273Z",
     "iopub.status.busy": "2022-05-13T15:25:09.820075Z",
     "iopub.status.idle": "2022-05-13T15:25:12.225554Z",
     "shell.execute_reply": "2022-05-13T15:25:12.224986Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating file results/2022-05-13_config_args.json\n",
      "On date 2022-05-13 , Running benchmark on host babbage  with device cuda\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - '/home/laurent/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/corpus/util.py:84\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 84\u001b[0m     root \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mzip_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet.zip/wordnet/\u001b[0m\n\n  Searched in:\n    - '/home/laurent/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/metagit/JNJER/2022-03_UltraFastCat/UltraFastCat/experiment_train.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageFile\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n",
      "File \u001b[0;32m~/metagit/JNJER/2022-03_UltraFastCat/src/model.py:2\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnnf\u001b[39;00m\n",
      "File \u001b[0;32m~/metagit/JNJER/2022-03_UltraFastCat/src/init.py:116\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    114\u001b[0m reverse_id_labels \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i_img, img_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(Imagenet_urls_ILSVRC_2016):\n\u001b[0;32m--> 116\u001b[0m     syn_\u001b[38;5;241m=\u001b[39m \u001b[43mwn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msynset_from_pos_and_offset\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mint\u001b[39m(img_id\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[1;32m    117\u001b[0m     reverse_id_labels[img_id] \u001b[38;5;241m=\u001b[39m syn_\u001b[38;5;241m.\u001b[39mlemmas()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mname()\n\u001b[1;32m    118\u001b[0m     labels\u001b[38;5;241m.\u001b[39mappend(syn_\u001b[38;5;241m.\u001b[39mlemmas()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mname())\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/corpus/util.py:121\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLazyCorpusLoader object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# This looks circular, but its not, since __load() changes our\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# __class__ to something new:\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/corpus/util.py:86\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m             root \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubdir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mzip_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n\u001b[0;32m---> 86\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Load the corpus.\u001b[39;00m\n\u001b[1;32m     89\u001b[0m corpus \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__reader_cls(root, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__kwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/corpus/util.py:81\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m         root \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[1;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - '/home/laurent/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IPython CPU timings (estimated):\n",
      "  User   :       2.22 s.\n",
      "  System :       0.33 s.\n",
      "Wall time:       2.40 s.\n"
     ]
    }
   ],
   "source": [
    "%run -int {scriptname}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average accuracy and loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we display both average accuracy and loss during the training phase and during the validation one : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:12.233141Z",
     "iopub.status.busy": "2022-05-13T15:25:12.232905Z",
     "iopub.status.idle": "2022-05-13T15:25:12.284868Z",
     "shell.execute_reply": "2022-05-13T15:25:12.284207Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m datetag \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2021-11-18\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m \u001b[43mall_models\u001b[49m:\n\u001b[1;32m      3\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetag\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39mHOST\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_train_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m     df_train \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_json(filename)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_models' is not defined"
     ]
    }
   ],
   "source": [
    "datetag = '2021-11-18'\n",
    "for model_name in all_models:\n",
    "    filename = f'results/{datetag}_{args.HOST}_train_{model_name}.json'\n",
    "    df_train = pd.read_json(filename)\n",
    "    fig, axs = plt.subplots(figsize=(fig_width, fig_width/phi/2))\n",
    "    ax = df_train['avg_loss'].plot(lw=2, marker='.', markersize=10)\n",
    "    ax = df_train['avg_loss_val'].plot(lw=2, marker='.', markersize=10)\n",
    "    ax.legend([\"avg_loss\", \"avg_loss_val\"], fontsize=18);\n",
    "    ax.set_xlabel(\"Epoch\", size=18)\n",
    "    ax.spines['left'].set_position(('axes', -0.01))\n",
    "    ax.set_xlim(-0.5, args.num_epochs)\n",
    "    ax.grid(which='both')\n",
    "    for side in ['top', 'right'] :ax.spines[side].set_visible(False)\n",
    "    ax.set_ylim(0., 1.1)\n",
    "    axs.set_title(f'Average values of the loss by epoch : {filename}' , size = 20)\n",
    "    ax.get_legend().remove()\n",
    "    fig.legend(bbox_to_anchor=(1.05, .5), loc='lower right', fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:12.289951Z",
     "iopub.status.busy": "2022-05-13T15:25:12.289751Z",
     "iopub.status.idle": "2022-05-13T15:25:12.320116Z",
     "shell.execute_reply": "2022-05-13T15:25:12.319416Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m \u001b[43mall_models\u001b[49m:\n\u001b[1;32m      2\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetag\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39mHOST\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_train_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m     df_train \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_json(filename)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_models' is not defined"
     ]
    }
   ],
   "source": [
    "for model_name in all_models:\n",
    "    filename = f'results/{datetag}_{args.HOST}_train_{model_name}.json'\n",
    "    df_train = pd.read_json(filename)\n",
    "    fig, axs = plt.subplots(figsize=(fig_width, fig_width/phi/2))\n",
    "    ax = df_train['avg_acc'].plot(lw=2, marker='.', markersize=10)\n",
    "    ax = df_train['avg_acc_val'].plot(lw=2, marker='.', markersize=10)\n",
    "    ax.legend([\"avg_acc\", \"avg_acc_val\"], fontsize=18);\n",
    "    ax.set_xlabel(\"Epoch\", size=18)\n",
    "    ax.spines['left'].set_position(('axes', -0.01))\n",
    "    ax.set_ylim(0.70, .992)\n",
    "    ax.set_yscale(\"logit\", one_half=\"1/2\", use_overline=True)\n",
    "    ax.grid(which='both')\n",
    "    ax.set_xlim(-0.5, args.num_epochs+.5)\n",
    "    for side in ['top', 'right'] :ax.spines[side].set_visible(False)\n",
    "    axs.set_title(f'Average values of the accuracy by epoch : {filename}' , size = 20)\n",
    "    ax.get_legend().remove()\n",
    "    fig.legend(bbox_to_anchor=(1.05, .5), loc='lower right', fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the new networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the networks seems ready for the comparison. The second part of this notebook offers a comparison between:\n",
    "\n",
    "- A pre-trained image recognition's networks, here VGG, trained on the [Imagenet](http://image-net.org/) dataset wich allows to work on naturals images for $1000$ labels, taken from the `torchvision.models` library\n",
    "\n",
    "- And three re-trained version of the same network VGG16 based on a Wordnet semantic from the Imagenet database wich allows to work on naturals images for $1$ synsets. \n",
    "\n",
    "As a control I re-train networks on the artifact synset too. Another interresing analysis will be the study of the link between the performances on these two conditions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"exp1\"></a>\n",
    "## Experiment 1: Image processing and recognition for differents labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:12.324735Z",
     "iopub.status.busy": "2022-05-13T15:25:12.324547Z",
     "iopub.status.idle": "2022-05-13T15:25:12.327529Z",
     "shell.execute_reply": "2022-05-13T15:25:12.326981Z"
    }
   },
   "outputs": [],
   "source": [
    "scriptname =  'UltraFastCat/experiment_basic.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:12.330728Z",
     "iopub.status.busy": "2022-05-13T15:25:12.330455Z",
     "iopub.status.idle": "2022-05-13T15:25:12.336917Z",
     "shell.execute_reply": "2022-05-13T15:25:12.336297Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting UltraFastCat/experiment_basic.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {scriptname}\n",
    "\n",
    "#import model's script and set the output file\n",
    "from experiment_train import *\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "filename = f'results/{datetag}_results_1_{args.HOST}.json'\n",
    "print(f'{filename=}')\n",
    "\n",
    "def main():\n",
    "    if os.path.isfile(filename):\n",
    "        df = pd.read_json(filename)\n",
    "    else:\n",
    "        i_trial = 0\n",
    "        df = pd.DataFrame([], columns=['model', 'model_task', 'task', 'goal', 'likelihood', 'fps', 'time', 'i_image', 'filename', 'top_1', 'device_type']) \n",
    "            # image preprocessing\n",
    "        (dataset_sizes, dataloaders, image_datasets, data_transforms) = datasets_transforms(image_size=args.image_size, batch_size=1)\n",
    "        for task in args.tasks:\n",
    "            pprint(task)\n",
    "            for i_image, (data, label) in enumerate(dataloaders[task]['test']):\n",
    "                data, label = data.to(device), label.to(device)\n",
    "                for model_name in models_vgg:\n",
    "                    model = models_vgg[model_name].to(device)\n",
    "                    with torch.no_grad():\n",
    "                        goal = 'target' if 'target' in image_datasets[task]['test'].imgs[i_image][0] else 'distractor'\n",
    "                        model_task = 'animal' if 'animal' in model_name else 'artifact'\n",
    "                        tic = time.time()\n",
    "                        out = model(data).squeeze(0)\n",
    "                        if model_name == 'vgg_16':\n",
    "                            temp_, likelihood = 0, 0\n",
    "                            model_task = 'Imagenet_challenge'\n",
    "                            percentage = torch.nn.functional.softmax(out, dim=0) * 100\n",
    "                            for idx in np.arange(0, 1000, 1): #Todo : check calcul likelihood\n",
    "                                if idx in match[task]:\n",
    "                                    likelihood += math.exp(percentage[idx].item())\n",
    "                                else:\n",
    "                                    temp_ += math.exp(percentage[idx].item())  \n",
    "                            likelihood = likelihood/temp_\n",
    "                        else:\n",
    "                            likelihood = float((torch.sigmoid(out) * 100).detach().cpu().numpy()[0])\n",
    "                        top_1 = 'target' if likelihood>50 else 'distractor'\n",
    "                        elapsed_time = time.time() - tic\n",
    "                    df.loc[i_trial] = {'model':model_name,'model_task':model_task, 'task':task, 'top_1':top_1, 'goal':goal, 'likelihood':likelihood, 'time':elapsed_time, 'fps': 1/elapsed_time,\n",
    "                                          'i_image':i_image, 'filename':image_datasets[task]['test'].imgs[i_image][0], 'device_type':device.type}\n",
    "                    print(f'The {model_name} model categorize {model_task} with {likelihood:.3f} % likelihood ({top_1}) in {elapsed_time:.3f} seconds, groundtrue : {task}, {goal}')\n",
    "                    i_trial += 1\n",
    "        df.to_json(filename)\n",
    "main()         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:12.340704Z",
     "iopub.status.busy": "2022-05-13T15:25:12.340309Z",
     "iopub.status.idle": "2022-05-13T15:25:12.923798Z",
     "shell.execute_reply": "2022-05-13T15:25:12.921713Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating file results/2022-05-13_config_args.json\n",
      "On date 2022-05-13 , Running benchmark on host babbage  with device cuda\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - '/home/laurent/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/corpus/util.py:84\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 84\u001b[0m     root \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mzip_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet.zip/wordnet/\u001b[0m\n\n  Searched in:\n    - '/home/laurent/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/metagit/JNJER/2022-03_UltraFastCat/UltraFastCat/experiment_basic.py:3\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#import model's script and set the output file\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexperiment_train\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageFile\n\u001b[1;32m      5\u001b[0m ImageFile\u001b[38;5;241m.\u001b[39mLOAD_TRUNCATED_IMAGES \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/metagit/JNJER/2022-03_UltraFastCat/UltraFastCat/experiment_train.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageFile\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n",
      "File \u001b[0;32m~/metagit/JNJER/2022-03_UltraFastCat/src/model.py:2\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnnf\u001b[39;00m\n",
      "File \u001b[0;32m~/metagit/JNJER/2022-03_UltraFastCat/src/init.py:116\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    114\u001b[0m reverse_id_labels \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i_img, img_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(Imagenet_urls_ILSVRC_2016):\n\u001b[0;32m--> 116\u001b[0m     syn_\u001b[38;5;241m=\u001b[39m \u001b[43mwn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msynset_from_pos_and_offset\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mint\u001b[39m(img_id\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[1;32m    117\u001b[0m     reverse_id_labels[img_id] \u001b[38;5;241m=\u001b[39m syn_\u001b[38;5;241m.\u001b[39mlemmas()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mname()\n\u001b[1;32m    118\u001b[0m     labels\u001b[38;5;241m.\u001b[39mappend(syn_\u001b[38;5;241m.\u001b[39mlemmas()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mname())\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/corpus/util.py:121\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLazyCorpusLoader object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# This looks circular, but its not, since __load() changes our\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# __class__ to something new:\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/corpus/util.py:86\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m             root \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubdir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mzip_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n\u001b[0;32m---> 86\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Load the corpus.\u001b[39;00m\n\u001b[1;32m     89\u001b[0m corpus \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__reader_cls(root, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__kwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/corpus/util.py:81\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m         root \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[1;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - '/home/laurent/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IPython CPU timings (estimated):\n",
      "  User   :       0.46 s.\n",
      "  System :       0.12 s.\n",
      "Wall time:       0.57 s.\n"
     ]
    }
   ],
   "source": [
    "%run -int {scriptname}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:12.928507Z",
     "iopub.status.busy": "2022-05-13T15:25:12.928204Z",
     "iopub.status.idle": "2022-05-13T15:25:12.949878Z",
     "shell.execute_reply": "2022-05-13T15:25:12.949336Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model_animal \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      2\u001b[0m model_artifact \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 3\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetag\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_results_1_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39mHOST\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_json(filename)\n\u001b[1;32m      5\u001b[0m data_animal \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mloc[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_task\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124manimal\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "model_animal = []\n",
    "model_artifact = []\n",
    "filename = f'results/{datetag}_results_1_{args.HOST}.json'\n",
    "df = pd.read_json(filename)\n",
    "data_animal = df.loc[df['model_task'] == 'animal']\n",
    "data_artifact = df.loc[df['model_task'] == 'artifact']\n",
    "for model in models_vgg:\n",
    "    model_animal.append(model) if 'animal' in model else model_artifact.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Animal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On this notebook I choose to focus on the analysis of the networks trained on a specific task on both animal and artifact datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I displayed the images in various conditions with the likelihood at the output of the network as the `y_label`, the label found by the network and the name of the networks as the `x_label`. If the labels are in green the categorization made by the network is correct (detect a target:'animal' in the scene when there is indeed an animal in the scene), if the labels are red the network failed the categorization. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the images with the higher likelihood of the networks : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:12.954379Z",
     "iopub.status.busy": "2022-05-13T15:25:12.954195Z",
     "iopub.status.idle": "2022-05-13T15:25:12.992114Z",
     "shell.execute_reply": "2022-05-13T15:25:12.991616Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m N_image_i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[1;32m      3\u001b[0m N_image_j \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[0;32m----> 4\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39msubplots(N_image_i, N_image_j, figsize\u001b[38;5;241m=\u001b[39m(fig_width\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1.3\u001b[39m, fig_width))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i_image, idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data_animal\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlikelihood\u001b[39m\u001b[38;5;124m'\u001b[39m], ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mhead(N_image_i\u001b[38;5;241m*\u001b[39mN_image_j)\u001b[38;5;241m.\u001b[39mindex):\n\u001b[1;32m      6\u001b[0m     ax \u001b[38;5;241m=\u001b[39m axs[i_image\u001b[38;5;241m%\u001b[39mN_image_i][i_image\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mN_image_i]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "N_image_i = 8\n",
    "N_image_j = 8\n",
    "fig, axs = plt.subplots(N_image_i, N_image_j, figsize=(fig_width*1.3, fig_width))\n",
    "for i_image, idx in enumerate(data_animal.sort_values(by=['likelihood'], ascending=False).head(N_image_i*N_image_j).index):\n",
    "    ax = axs[i_image%N_image_i][i_image//N_image_i]\n",
    "    img_address = image_datasets['animal']['test'].imgs[data_animal.loc[idx]['i_image']][0]\n",
    "    ax.imshow(imageio.imread(img_address))\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    color = 'g' if data_animal.loc[idx]['top_1'] == data_animal.loc[idx]['goal'] else 'r'\n",
    "    ax.set_xlabel(data_animal.loc[idx]['top_1'] + ' | ' + data_animal.loc[idx]['model'], color=color)\n",
    "    likelihood = data_animal.loc[idx]['likelihood']\n",
    "    ax.set_ylabel(f'P ={likelihood:2.3f}%', color=color)\n",
    "fig.set_facecolor(color='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the images with the lowest likelihood of the networks :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:12.996609Z",
     "iopub.status.busy": "2022-05-13T15:25:12.996450Z",
     "iopub.status.idle": "2022-05-13T15:25:13.023395Z",
     "shell.execute_reply": "2022-05-13T15:25:13.022466Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m N_image_i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[1;32m      3\u001b[0m N_image_j \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[0;32m----> 4\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39msubplots(N_image_i, N_image_j, figsize\u001b[38;5;241m=\u001b[39m(fig_width\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1.3\u001b[39m, fig_width))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i_image, idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data_animal\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlikelihood\u001b[39m\u001b[38;5;124m'\u001b[39m], ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mhead(N_image_i\u001b[38;5;241m*\u001b[39mN_image_j)\u001b[38;5;241m.\u001b[39mindex):\n\u001b[1;32m      6\u001b[0m     ax \u001b[38;5;241m=\u001b[39m axs[i_image\u001b[38;5;241m%\u001b[39mN_image_i][i_image\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mN_image_i]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "N_image_i = 8\n",
    "N_image_j = 8\n",
    "fig, axs = plt.subplots(N_image_i, N_image_j, figsize=(fig_width*1.3, fig_width))\n",
    "for i_image, idx in enumerate(data_animal.sort_values(by=['likelihood'], ascending=True).head(N_image_i*N_image_j).index):\n",
    "    ax = axs[i_image%N_image_i][i_image//N_image_i]\n",
    "    img_address = image_datasets['animal']['test'].imgs[data_animal.loc[idx]['i_image']][0]\n",
    "    ax.imshow(imageio.imread(img_address))\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    color = 'g' if data_animal.loc[idx]['top_1'] == data_animal.loc[idx]['goal'] else 'r'\n",
    "    ax.set_xlabel(data_animal.loc[idx]['top_1'] + ' | ' + data_animal.loc[idx]['model'], color=color)\n",
    "    likelihood = data_animal.loc[idx]['likelihood']\n",
    "    ax.set_ylabel(f'P ={likelihood:2.3f}%', color=color)  \n",
    "fig.set_facecolor(color='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:13.026750Z",
     "iopub.status.busy": "2022-05-13T15:25:13.026366Z",
     "iopub.status.idle": "2022-05-13T15:25:13.057910Z",
     "shell.execute_reply": "2022-05-13T15:25:13.057306Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, precision_score, f1_score\n\u001b[0;32m----> 2\u001b[0m df_acc \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame({model_name: {task: f1_score(data_animal[(data_animal[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mmodel_name) \u001b[38;5;241m&\u001b[39m (data_animal[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mtask)][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_1\u001b[39m\u001b[38;5;124m\"\u001b[39m], \n\u001b[1;32m      3\u001b[0m                                                                data_animal[(data_animal[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mmodel_name) \u001b[38;5;241m&\u001b[39m (data_animal[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mtask)][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoal\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      4\u001b[0m                                                   average \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmicro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m                                     \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m args\u001b[38;5;241m.\u001b[39mtasks} \n\u001b[1;32m      6\u001b[0m                        \u001b[38;5;28;01mfor\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m model_animal})\n\u001b[1;32m      7\u001b[0m test \u001b[38;5;241m=\u001b[39m df_acc\n\u001b[1;32m      8\u001b[0m ax \u001b[38;5;241m=\u001b[39m df_acc\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mplot\u001b[38;5;241m.\u001b[39mbar(rot\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(fig_width, fig_width\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m4\u001b[39m), fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
    "df_acc = pd.DataFrame({model_name: {task: f1_score(data_animal[(data_animal['model']==model_name) & (data_animal['task']==task)][\"top_1\"], \n",
    "                                                               data_animal[(data_animal['model']==model_name) & (data_animal['task']==task)][\"goal\"],\n",
    "                                                  average = 'micro')\n",
    "                                    for task in args.tasks} \n",
    "                       for model_name in model_animal})\n",
    "test = df_acc\n",
    "ax = df_acc.T.plot.bar(rot=0, figsize=(fig_width, fig_width//4), fontsize=20)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.hlines(xmin=-.5, xmax=len(all_models)-.5, y=1/2, ls='--', ec='k', label='chance level')\n",
    "# https://matplotlib.org/stable/gallery/lines_bars_and_markers/bar_label_demo.html\n",
    "for container in ax.containers: ax.bar_label(container, padding=-50, color='black', fontsize=14, fmt='%.3f', rotation=60)\n",
    "plt.legend(bbox_to_anchor=(1.2, .35), loc='lower right', fontsize=18)\n",
    "ax.set_title(f'Animal vs Artifact images f1 score for re-trained models', size=22)\n",
    "ax.set_ylabel('Accuracy', size=20)\n",
    "ax.set_xlabel('Model', size=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the images with the highest likelihood of the networks :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:13.061955Z",
     "iopub.status.busy": "2022-05-13T15:25:13.061800Z",
     "iopub.status.idle": "2022-05-13T15:25:13.087478Z",
     "shell.execute_reply": "2022-05-13T15:25:13.086864Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m N_image_i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[1;32m      3\u001b[0m N_image_j \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[0;32m----> 4\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39msubplots(N_image_i, N_image_j, figsize\u001b[38;5;241m=\u001b[39m(fig_width\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1.3\u001b[39m, fig_width))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i_image, idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data_artifact\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlikelihood\u001b[39m\u001b[38;5;124m'\u001b[39m], ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mhead(N_image_i\u001b[38;5;241m*\u001b[39mN_image_j)\u001b[38;5;241m.\u001b[39mindex):\n\u001b[1;32m      6\u001b[0m     ax \u001b[38;5;241m=\u001b[39m axs[i_image\u001b[38;5;241m%\u001b[39mN_image_i][i_image\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mN_image_i]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "N_image_i = 8\n",
    "N_image_j = 8\n",
    "fig, axs = plt.subplots(N_image_i, N_image_j, figsize=(fig_width*1.3, fig_width))\n",
    "for i_image, idx in enumerate(data_artifact.sort_values(by=['likelihood'], ascending=False).head(N_image_i*N_image_j).index):\n",
    "    ax = axs[i_image%N_image_i][i_image//N_image_i]\n",
    "    img_address = image_datasets['artifact']['test'].imgs[data_artifact.loc[idx]['i_image']][0]\n",
    "    ax.imshow(imageio.imread(img_address))\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    color = 'g' if data_artifact.loc[idx]['top_1'] == data_artifact.loc[idx]['goal'] else 'r'\n",
    "    ax.set_xlabel(data_artifact.loc[idx]['top_1'] + ' | ' + data_artifact.loc[idx]['model'], color=color)\n",
    "    likelihood = data_artifact.loc[idx]['likelihood']\n",
    "    ax.set_ylabel(f'P ={likelihood:2.3f}%', color=color)\n",
    "fig.set_facecolor(color='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the images with the lowest likelihood of the networks :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:13.092973Z",
     "iopub.status.busy": "2022-05-13T15:25:13.092790Z",
     "iopub.status.idle": "2022-05-13T15:25:13.118858Z",
     "shell.execute_reply": "2022-05-13T15:25:13.118432Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m N_image_i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[1;32m      3\u001b[0m N_image_j \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[0;32m----> 4\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39msubplots(N_image_i, N_image_j, figsize\u001b[38;5;241m=\u001b[39m(fig_width\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1.3\u001b[39m, fig_width))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i_image, idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data_artifact\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlikelihood\u001b[39m\u001b[38;5;124m'\u001b[39m], ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mhead(N_image_i\u001b[38;5;241m*\u001b[39mN_image_j)\u001b[38;5;241m.\u001b[39mindex):\n\u001b[1;32m      6\u001b[0m     ax \u001b[38;5;241m=\u001b[39m axs[i_image\u001b[38;5;241m%\u001b[39mN_image_i][i_image\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mN_image_i]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "N_image_i = 8\n",
    "N_image_j = 8\n",
    "fig, axs = plt.subplots(N_image_i, N_image_j, figsize=(fig_width*1.3, fig_width))\n",
    "for i_image, idx in enumerate(data_artifact.sort_values(by=['likelihood'], ascending=True).head(N_image_i*N_image_j).index):\n",
    "    ax = axs[i_image%N_image_i][i_image//N_image_i]\n",
    "    img_address = image_datasets['artifact']['test'].imgs[data_artifact.loc[idx]['i_image']][0]\n",
    "    ax.imshow(imageio.imread(img_address))\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    color = 'g' if data_artifact.loc[idx]['top_1'] == data_artifact.loc[idx]['goal'] else 'r'\n",
    "    ax.set_xlabel(data_artifact.loc[idx]['top_1'] + ' | ' + data_artifact.loc[idx]['model'], color=color)\n",
    "    likelihood = data_artifact.loc[idx]['likelihood']\n",
    "    ax.set_ylabel(f'P ={likelihood:2.3f}%', color=color) \n",
    "fig.set_facecolor(color='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:13.122831Z",
     "iopub.status.busy": "2022-05-13T15:25:13.122673Z",
     "iopub.status.idle": "2022-05-13T15:25:13.150600Z",
     "shell.execute_reply": "2022-05-13T15:25:13.149656Z"
    }
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "pop from empty list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, precision_score, f1_score\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel_artifact\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m df_acc \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({model_name: {task: f1_score(data_artifact[(data_artifact[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mmodel_name) \u001b[38;5;241m&\u001b[39m (data_artifact[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mtask)][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_1\u001b[39m\u001b[38;5;124m\"\u001b[39m], \n\u001b[1;32m      4\u001b[0m                                                                data_artifact[(data_artifact[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mmodel_name) \u001b[38;5;241m&\u001b[39m (data_artifact[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mtask)][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoal\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      5\u001b[0m                                                   average \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmicro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m                                     \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m args\u001b[38;5;241m.\u001b[39mtasks} \n\u001b[1;32m      7\u001b[0m                        \u001b[38;5;28;01mfor\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m model_artifact})\n\u001b[1;32m      9\u001b[0m ax \u001b[38;5;241m=\u001b[39m df_acc\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mplot\u001b[38;5;241m.\u001b[39mbar(rot\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(fig_width, fig_width\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m4\u001b[39m), fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from empty list"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
    "model_artifact.pop(0)\n",
    "df_acc = pd.DataFrame({model_name: {task: f1_score(data_artifact[(data_artifact['model']==model_name) & (data_artifact['task']==task)][\"top_1\"], \n",
    "                                                               data_artifact[(data_artifact['model']==model_name) & (data_artifact['task']==task)][\"goal\"],\n",
    "                                                  average = 'micro')\n",
    "                                    for task in args.tasks} \n",
    "                       for model_name in model_artifact})\n",
    "\n",
    "ax = df_acc.T.plot.bar(rot=20, figsize=(fig_width, fig_width//4), fontsize=20)\n",
    "test_ = df_acc\n",
    "ax.set_ylim(0, 1)\n",
    "ax.hlines(xmin=-.5, xmax=len(models_vgg)-.5, y=1/2, ls='--', ec='k', label='chance level')\n",
    "# https://matplotlib.org/stable/gallery/lines_bars_and_markers/bar_label_demo.html\n",
    "for container in ax.containers: ax.bar_label(container, padding=-50, color='black', fontsize=14, fmt='%.3f', rotation=60)\n",
    "plt.legend(bbox_to_anchor=(1.2, .35), loc='lower right', fontsize=18)\n",
    "ax.set_title(f'Animal vs Artifact images f1 score for re-trained models', size=22)\n",
    "ax.set_ylabel('Accuracy', size=20)\n",
    "ax.set_xlabel('Model', size=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computation Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:13.153980Z",
     "iopub.status.busy": "2022-05-13T15:25:13.153635Z",
     "iopub.status.idle": "2022-05-13T15:25:13.186262Z",
     "shell.execute_reply": "2022-05-13T15:25:13.185756Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;28mlen\u001b[39m(models_vgg), \u001b[38;5;241m1\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(fig_width, fig_width\u001b[38;5;241m*\u001b[39mphi\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m), sharex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, sharey\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m cmap \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mcm\u001b[38;5;241m.\u001b[39mget_cmap(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minferno\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m color_dict \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries({k:cmap(i\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique())) \u001b[38;5;28;01mfor\u001b[39;00m i,k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique())})\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "fig, axs = plt.subplots(len(models_vgg), 1, figsize=(fig_width, fig_width*phi/2), sharex=True, sharey=True)\n",
    "cmap = plt.cm.get_cmap('inferno')\n",
    "color_dict = pd.Series({k:cmap(i/len(df['model'].unique())) for i,k in enumerate(df['model'].unique())})\n",
    "for ax, color, model_name in zip(axs, color_dict, models_vgg):\n",
    "    df[df['model']==model_name]['time'].plot.hist(bins=50, lw=1, label=model_name,ax=ax, color=[color_dict[model_name],], density=True)\n",
    "    ax.set_xlim(df['time'].quantile(.01), df['time'].quantile(.99))\n",
    "    ax.set_ylim(0, 3500)\n",
    "    ax.legend(bbox_to_anchor=(1.21, .35), loc='lower right', fontsize=15)\n",
    "    ax.grid(which='both', axis='y')\n",
    "    ax.set_xlabel('Processing time (s): ' + model_name, size=22)\n",
    "    ax.set_ylabel('')\n",
    "axs[0].set_title('Distribution of the Processing time (s). Processed on : ' + args.HOST + '_' + str(df['device_type'][0]), size = 20)\n",
    "axs[len(models_vgg)//2].set_ylabel('Frequency', fontsize=22);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy comparison for all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:13.190684Z",
     "iopub.status.busy": "2022-05-13T15:25:13.190325Z",
     "iopub.status.idle": "2022-05-13T15:25:13.243000Z",
     "shell.execute_reply": "2022-05-13T15:25:13.242484Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m df_test \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m x\u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGen\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mScale\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGray\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 6\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m, sharex\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcol\u001b[39m\u001b[38;5;124m'\u001b[39m, sharey\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrow\u001b[39m\u001b[38;5;124m'\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(fig_width\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m1.5\u001b[39m, fig_width\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m args\u001b[38;5;241m.\u001b[39mtasks:\n\u001b[1;32m      8\u001b[0m     temp_ \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mloc[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m task]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
    "animal_acc = {}\n",
    "artifact_acc = {}\n",
    "df_test = []\n",
    "x= ['Gen', 'Scale', 'Gray']\n",
    "fig, axs = plt.subplots(2, 2, sharex='col', sharey='row', figsize=(fig_width//1.5, fig_width//3))\n",
    "for task in args.tasks:\n",
    "    temp_ = df.loc[df['task'] == task]\n",
    "    animal_acc[task]=[]\n",
    "    artifact_acc[task]=[]\n",
    "    for model_name in models_vgg:\n",
    "        if 'animal' in model_name:\n",
    "            animal_acc[task].append(accuracy_score(temp_[temp_['model']==model_name][\"top_1\"], temp_[temp_['model']==model_name][\"goal\"]))\n",
    "        elif 'artifact' in model_name:\n",
    "            artifact_acc[task].append(accuracy_score(temp_[temp_['model']==model_name][\"top_1\"], temp_[temp_['model']==model_name][\"goal\"]))\n",
    "\n",
    "    df_test.append(animal_acc[task])\n",
    "    df_test.append(artifact_acc[task])\n",
    "\n",
    "cmap = plt.cm.get_cmap('viridis_r')\n",
    "color_dict = pd.Series({k:cmap(i/len(x)) for i,k in enumerate(x)})\n",
    "\n",
    "n= 3\n",
    "\n",
    "titles = [\"(A) Animal on animal\", \"(B) Animal on artifact\" ,\"(C) Artifact on animal\" ,\"(D) Artifact on artifact\"]\n",
    "\n",
    "ax1 = axs[0][0]\n",
    "ax2 = axs[0][1]\n",
    "ax3 = axs[1][0]\n",
    "ax4 = axs[1][1]\n",
    "ax1.bar(x, df_test[0], color= color_dict)\n",
    "ax2.bar(x, df_test[1], color= color_dict)\n",
    "ax3.bar(x, df_test[2], color= color_dict)\n",
    "ax4.bar(x, df_test[3], color= color_dict)\n",
    "ax1.set_ylim(0, 1)\n",
    "ax3.set_ylim(0, 1)\n",
    "ax1.hlines(xmin=-.5, xmax=2.5, y=1/2, ls='--', ec='k')\n",
    "ax2.hlines(xmin=-.5, xmax=2.5, y=1/2, ls='--', ec='k')\n",
    "ax3.hlines(xmin=-.5, xmax=2.5, y=1/2, ls='--', ec='k')\n",
    "ax4.hlines(xmin=-.5, xmax=2.5, y=1/2, ls='--', ec='k')\n",
    "ax1.set_title(titles[0], fontsize = 18, fontweight=\"bold\")\n",
    "ax2.set_title(titles[1], fontsize = 18, fontweight=\"bold\")\n",
    "ax3.set_title(titles[2], fontsize = 18, fontweight=\"bold\")\n",
    "ax4.set_title(titles[3], fontsize = 18, fontweight=\"bold\")\n",
    "axxx = [ax1, ax2, ax3, ax4]\n",
    "# https://matplotlib.org/stable/gallery/lines_bars_and_markers/bar_label_demo.html\n",
    "for axs in axxx:\n",
    "    for i, container in enumerate(axs.containers): axs.bar_label(container, padding=-50, color='black', fontsize=18, fmt='%.3f', rotation=0, label_type = 'edge', fontweight='bold')\n",
    "#plt.legend(bbox_to_anchor=(1.2, .35), loc='lower right', fontsize=15)\n",
    "plt.xticks(fontsize=20,  fontweight='bold')\n",
    "\n",
    "ax1.set_ylabel('Accuracy', fontsize=20, fontweight='bold')\n",
    "ax3.set_ylabel('Accuracy', fontsize=20, fontweight='bold')\n",
    "plt.tight_layout();\n",
    "ax3.set_xticks([])\n",
    "plt.yticks(fontsize=20,  fontweight='bold');\n",
    "#plt.savefig('IJCNN_fig.5.pdf');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "\n",
    "We tested the networks Vgg Gen, Vgg Scale and Vgg Gray trained to detect an animal on the dataset where the targets are 'animal' (respectively train to detect an artifact on dataset where targets are artifacts). Then we tested the networks trained to detect an 'animal' on the dataset where the targets are 'artifact' and vice versa. Here, by exposing the predictions for the 'animal' and 'artifact' labels, we highlight a bias in the composition of the dataset. Although the outputs are independent, 'animal' images confidently correspond to 'non-artifact' images (and vice versa), thus facilitating the overall detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Todo : Analysis network serre/person"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"exp2\"></a>\n",
    "## Experiment 2: Image processing and recognition for differents flip transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:13.248087Z",
     "iopub.status.busy": "2022-05-13T15:25:13.247728Z",
     "iopub.status.idle": "2022-05-13T15:25:13.251650Z",
     "shell.execute_reply": "2022-05-13T15:25:13.251106Z"
    }
   },
   "outputs": [],
   "source": [
    "scriptname =  'UltraFastCat/experiment_flip.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:13.256208Z",
     "iopub.status.busy": "2022-05-13T15:25:13.255965Z",
     "iopub.status.idle": "2022-05-13T15:25:13.262204Z",
     "shell.execute_reply": "2022-05-13T15:25:13.261697Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting UltraFastCat/experiment_flip.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {scriptname}\n",
    "\n",
    "#import model's script and set the output file\n",
    "from experiment_train import *\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "flips = {}\n",
    "flips['Horizontal'] = transforms.RandomHorizontalFlip(p=1)\n",
    "flips['Vertical'] = transforms.RandomVerticalFlip(p=1)\n",
    "\n",
    "filename = f'results/{datetag}_results_flip_{args.HOST}.json'\n",
    "print(f'{filename=}')\n",
    "\n",
    "def main():\n",
    "    if os.path.isfile(filename):\n",
    "        df = pd.read_json(filename)\n",
    "    else:\n",
    "        i_trial = 0\n",
    "        df_flip = pd.DataFrame([], columns=['model', 'model_task', 'task', 'goal', 'likelihood', 'fps', 'time', 'i_image', 'filename', 'top_1', 'device_type', 'flip'])   \n",
    "        # image preprocessing\n",
    "        (dataset_sizes, dataloaders, image_datasets, data_transforms) = datasets_transforms(image_size=args.image_size, batch_size=1)\n",
    "        for flip in flips:\n",
    "            pprint(flip)\n",
    "            for task in args.tasks:\n",
    "                for i_image, (data, label) in enumerate(dataloaders[task]['test']):\n",
    "                    data = flips[flip](data)\n",
    "                    data, label, = data.to(device), label.to(device)\n",
    "                    for model_name in models_vgg:\n",
    "                        model = models_vgg[model_name].to(device)\n",
    "                        with torch.no_grad():\n",
    "                            goal = 'target' if 'target' in image_datasets[task]['test'].imgs[i_image][0] else 'distractor'\n",
    "                            model_task = 'animal' if 'animal' in model_name else 'artifact'\n",
    "                            tic = time.time()\n",
    "                            out = model(data).squeeze(0)\n",
    "                            if model_name == 'vgg_16':\n",
    "                                temp_, likelihood = 0, 0\n",
    "                                model_task = 'Imagenet_challenge'\n",
    "                                percentage = torch.nn.functional.softmax(out, dim=0) * 100\n",
    "                                for idx in np.arange(0,1000,1):\n",
    "                                    if idx in match[task]:\n",
    "                                        likelihood += math.exp(percentage[idx].item())\n",
    "                                    else:\n",
    "                                        temp_ += math.exp(percentage[idx].item())  \n",
    "                                likelihood = likelihood/temp_\n",
    "                            else:\n",
    "                                likelihood = float((torch.sigmoid(out) * 100).detach().cpu().numpy()[0])\n",
    "                            elapsed_time = time.time() - tic\n",
    "                            top_1 = 'target' if likelihood>50 else 'distractor'\n",
    "                        df_flip.loc[i_trial] = {'model':model_name,'model_task':model_task, 'task':task, 'top_1':top_1, 'goal':goal, 'likelihood':likelihood, 'time':elapsed_time, 'fps': 1/elapsed_time,\n",
    "                                               'i_image':i_image, 'filename':image_datasets[task]['test'].imgs[i_image][0], 'device_type':device.type, 'flip':flip}\n",
    "                        print(f'The {model_name} model categorize {model_task} with {likelihood:.3f} % likelihood ({top_1}) in {elapsed_time:.3f} seconds, groundtrue : {task}, {goal}')\n",
    "                        i_trial += 1\n",
    "\n",
    "            df_flip.to_json(filename)\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:13.265554Z",
     "iopub.status.busy": "2022-05-13T15:25:13.265315Z",
     "iopub.status.idle": "2022-05-13T15:25:13.828400Z",
     "shell.execute_reply": "2022-05-13T15:25:13.827906Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating file results/2022-05-13_config_args.json\n",
      "On date 2022-05-13 , Running benchmark on host babbage  with device cuda\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - '/home/laurent/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/corpus/util.py:84\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 84\u001b[0m     root \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mzip_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet.zip/wordnet/\u001b[0m\n\n  Searched in:\n    - '/home/laurent/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/metagit/JNJER/2022-03_UltraFastCat/UltraFastCat/experiment_flip.py:3\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#import model's script and set the output file\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexperiment_train\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageFile\n\u001b[1;32m      5\u001b[0m ImageFile\u001b[38;5;241m.\u001b[39mLOAD_TRUNCATED_IMAGES \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/metagit/JNJER/2022-03_UltraFastCat/UltraFastCat/experiment_train.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageFile\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n",
      "File \u001b[0;32m~/metagit/JNJER/2022-03_UltraFastCat/src/model.py:2\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnnf\u001b[39;00m\n",
      "File \u001b[0;32m~/metagit/JNJER/2022-03_UltraFastCat/src/init.py:116\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    114\u001b[0m reverse_id_labels \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i_img, img_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(Imagenet_urls_ILSVRC_2016):\n\u001b[0;32m--> 116\u001b[0m     syn_\u001b[38;5;241m=\u001b[39m \u001b[43mwn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msynset_from_pos_and_offset\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mint\u001b[39m(img_id\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[1;32m    117\u001b[0m     reverse_id_labels[img_id] \u001b[38;5;241m=\u001b[39m syn_\u001b[38;5;241m.\u001b[39mlemmas()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mname()\n\u001b[1;32m    118\u001b[0m     labels\u001b[38;5;241m.\u001b[39mappend(syn_\u001b[38;5;241m.\u001b[39mlemmas()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mname())\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/corpus/util.py:121\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLazyCorpusLoader object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# This looks circular, but its not, since __load() changes our\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# __class__ to something new:\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/corpus/util.py:86\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m             root \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubdir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mzip_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n\u001b[0;32m---> 86\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Load the corpus.\u001b[39;00m\n\u001b[1;32m     89\u001b[0m corpus \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__reader_cls(root, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__kwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/corpus/util.py:81\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m         root \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[1;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - '/home/laurent/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IPython CPU timings (estimated):\n",
      "  User   :       0.45 s.\n",
      "  System :       0.11 s.\n",
      "Wall time:       0.56 s.\n"
     ]
    }
   ],
   "source": [
    "%run -int {scriptname}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:13.834679Z",
     "iopub.status.busy": "2022-05-13T15:25:13.834483Z",
     "iopub.status.idle": "2022-05-13T15:25:13.859771Z",
     "shell.execute_reply": "2022-05-13T15:25:13.858922Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m model_animal \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m model_artifact \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 4\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetag\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_results_flip_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39mHOST\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      5\u001b[0m flips \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      6\u001b[0m flips[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHorizontal\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mRandomHorizontalFlip(p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "datetag = '2021-12-07'\n",
    "model_animal = []\n",
    "model_artifact = []\n",
    "filename = f'results/{datetag}_results_flip_{args.HOST}.json'\n",
    "flips = {}\n",
    "flips['Horizontal'] = transforms.RandomHorizontalFlip(p=1)\n",
    "flips['Vertical'] = transforms.RandomVerticalFlip(p=1)\n",
    "df_flip = pd.read_json(filename)\n",
    "test = df_acc\n",
    "data_animal = df_flip.loc[df_flip['model_task'] == 'animal']\n",
    "data_artifact = df_flip.loc[df_flip['model_task'] == 'artifact']\n",
    "for model in all_models:\n",
    "    model_animal.append(model) if 'animal' in model else model_artifact.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Animal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the images with the highest likelihood of the networks :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:13.863737Z",
     "iopub.status.busy": "2022-05-13T15:25:13.863505Z",
     "iopub.status.idle": "2022-05-13T15:25:13.885881Z",
     "shell.execute_reply": "2022-05-13T15:25:13.885279Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m N_image_i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[1;32m      3\u001b[0m N_image_j \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[0;32m----> 4\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39msubplots(N_image_i, N_image_j, figsize\u001b[38;5;241m=\u001b[39m(fig_width\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1.3\u001b[39m, fig_width))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i_image, idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data_animal\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlikelihood\u001b[39m\u001b[38;5;124m'\u001b[39m], ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mhead(N_image_i\u001b[38;5;241m*\u001b[39mN_image_j)\u001b[38;5;241m.\u001b[39mindex):\n\u001b[1;32m      6\u001b[0m     ax \u001b[38;5;241m=\u001b[39m axs[i_image\u001b[38;5;241m%\u001b[39mN_image_i][i_image\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mN_image_i]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "N_image_i = 8\n",
    "N_image_j = 8\n",
    "fig, axs = plt.subplots(N_image_i, N_image_j, figsize=(fig_width*1.3, fig_width))\n",
    "for i_image, idx in enumerate(data_animal.sort_values(by=['likelihood'], ascending=False).head(N_image_i*N_image_j).index):\n",
    "    ax = axs[i_image%N_image_i][i_image//N_image_i]\n",
    "    img_address = image_datasets['animal']['test'].imgs[data_animal.loc[idx]['i_image']][0]\n",
    "    ax.imshow(imageio.imread(img_address))\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    color = 'g' if data_animal.loc[idx]['top_1'] == data_animal.loc[idx]['goal'] else 'r'\n",
    "    ax.set_xlabel(data_animal.loc[idx]['top_1'] + ' | ' + data_animal.loc[idx]['model'], color=color)\n",
    "    likelihood = data_animal.loc[idx]['likelihood']\n",
    "    ax.set_ylabel(f'P ={likelihood:2.3f}%', color=color)\n",
    "fig.set_facecolor(color='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the images with the lowest likelihood of the networks :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:13.889176Z",
     "iopub.status.busy": "2022-05-13T15:25:13.889003Z",
     "iopub.status.idle": "2022-05-13T15:25:13.915688Z",
     "shell.execute_reply": "2022-05-13T15:25:13.915052Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m N_image_i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[1;32m      3\u001b[0m N_image_j \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[0;32m----> 4\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39msubplots(N_image_i, N_image_j, figsize\u001b[38;5;241m=\u001b[39m(fig_width\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1.3\u001b[39m, fig_width))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i_image, idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data_animal\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlikelihood\u001b[39m\u001b[38;5;124m'\u001b[39m], ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mhead(N_image_i\u001b[38;5;241m*\u001b[39mN_image_j)\u001b[38;5;241m.\u001b[39mindex):\n\u001b[1;32m      6\u001b[0m     ax \u001b[38;5;241m=\u001b[39m axs[i_image\u001b[38;5;241m%\u001b[39mN_image_i][i_image\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mN_image_i]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "N_image_i = 8\n",
    "N_image_j = 8\n",
    "fig, axs = plt.subplots(N_image_i, N_image_j, figsize=(fig_width*1.3, fig_width))\n",
    "for i_image, idx in enumerate(data_animal.sort_values(by=['likelihood'], ascending=True).head(N_image_i*N_image_j).index):\n",
    "    ax = axs[i_image%N_image_i][i_image//N_image_i]\n",
    "    img_address = image_datasets['animal']['test'].imgs[data_animal.loc[idx]['i_image']][0]\n",
    "    ax.imshow(imageio.imread(img_address))\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    color = 'g' if data_animal.loc[idx]['top_1'] == data_animal.loc[idx]['goal'] else 'r'\n",
    "    ax.set_xlabel(data_animal.loc[idx]['top_1'] + ' | ' + data_animal.loc[idx]['model'], color=color)\n",
    "    likelihood = data_animal.loc[idx]['likelihood']\n",
    "    ax.set_ylabel(data_animal.loc[idx]['goal'], color=color)  \n",
    "fig.set_facecolor(color='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:13.920911Z",
     "iopub.status.busy": "2022-05-13T15:25:13.920715Z",
     "iopub.status.idle": "2022-05-13T15:25:13.956840Z",
     "shell.execute_reply": "2022-05-13T15:25:13.956320Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, precision_score, f1_score\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, task \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43margs\u001b[49m\u001b[38;5;241m.\u001b[39mtasks):\n\u001b[1;32m      3\u001b[0m     df_acc \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({model_name: {flip: f1_score(data_animal[(data_animal[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mmodel_name) \u001b[38;5;241m&\u001b[39m (data_animal[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mtask) \u001b[38;5;241m&\u001b[39m (data_animal[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflip\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mflip) ][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_1\u001b[39m\u001b[38;5;124m\"\u001b[39m], \n\u001b[1;32m      4\u001b[0m                                                                    data_animal[(data_animal[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mmodel_name) \u001b[38;5;241m&\u001b[39m (data_animal[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mtask) \u001b[38;5;241m&\u001b[39m (data_animal[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflip\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mflip)][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoal\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      5\u001b[0m                                                       average \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmicro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m                                         \u001b[38;5;28;01mfor\u001b[39;00m flip \u001b[38;5;129;01min\u001b[39;00m flips} \n\u001b[1;32m      7\u001b[0m                            \u001b[38;5;28;01mfor\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m model_animal})\n\u001b[1;32m      8\u001b[0m     df_acc\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;28mlen\u001b[39m(df_acc\u001b[38;5;241m.\u001b[39mindex)] \u001b[38;5;241m=\u001b[39m test\u001b[38;5;241m.\u001b[39miloc[i]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
    "for i, task in enumerate(args.tasks):\n",
    "    df_acc = pd.DataFrame({model_name: {flip: f1_score(data_animal[(data_animal['model']==model_name) & (data_animal['task']==task) & (data_animal['flip']==flip) ][\"top_1\"], \n",
    "                                                                   data_animal[(data_animal['model']==model_name) & (data_animal['task']==task) & (data_animal['flip']==flip)][\"goal\"],\n",
    "                                                      average = 'micro')\n",
    "                                        for flip in flips} \n",
    "                           for model_name in model_animal})\n",
    "    df_acc.loc[len(df_acc.index)] = test.iloc[i]\n",
    "    temp_ = list(flips)\n",
    "    temp_.append('Base')\n",
    "    df_acc.index = temp_\n",
    "    ax = df_acc.T.plot.bar(rot=0, figsize=(fig_width, fig_width//4), fontsize=20)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.hlines(xmin=-.5, xmax=len(models_vgg.keys())-.5, y=1/2, ls='--', ec='k', label='chance level')\n",
    "    # https://matplotlib.org/stable/gallery/lines_bars_and_markers/bar_label_demo.html\n",
    "    for container in ax.containers: ax.bar_label(container, padding=-50, color='black', fontsize=14, fmt='%.3f', rotation=60)\n",
    "    plt.legend(bbox_to_anchor=(1.15, .35), loc='lower right', fontsize=14)\n",
    "    ax.set_title(f'Animal vs Artifact images f1 score for re-trained models, task: {task}', size=22)\n",
    "    ax.set_ylabel('F1 score', size=20)\n",
    "    ax.set_xlabel('Model', size=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the images with the highest likelihood of the networks :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:13.960924Z",
     "iopub.status.busy": "2022-05-13T15:25:13.960741Z",
     "iopub.status.idle": "2022-05-13T15:25:13.987088Z",
     "shell.execute_reply": "2022-05-13T15:25:13.986623Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m N_image_i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[1;32m      3\u001b[0m N_image_j \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[0;32m----> 4\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39msubplots(N_image_i, N_image_j, figsize\u001b[38;5;241m=\u001b[39m(fig_width\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1.3\u001b[39m, fig_width))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i_image, idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data_artifact\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlikelihood\u001b[39m\u001b[38;5;124m'\u001b[39m], ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mhead(N_image_i\u001b[38;5;241m*\u001b[39mN_image_j)\u001b[38;5;241m.\u001b[39mindex):\n\u001b[1;32m      6\u001b[0m     ax \u001b[38;5;241m=\u001b[39m axs[i_image\u001b[38;5;241m%\u001b[39mN_image_i][i_image\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mN_image_i]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "N_image_i = 8\n",
    "N_image_j = 8\n",
    "fig, axs = plt.subplots(N_image_i, N_image_j, figsize=(fig_width*1.3, fig_width))\n",
    "for i_image, idx in enumerate(data_artifact.sort_values(by=['likelihood'], ascending=True).head(N_image_i*N_image_j).index):\n",
    "    ax = axs[i_image%N_image_i][i_image//N_image_i]\n",
    "    img_address = image_datasets['animal']['test'].imgs[data_artifact.loc[idx]['i_image']][0]\n",
    "    ax.imshow(imageio.imread(img_address))\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    color = 'g' if data_artifact.loc[idx]['top_1'] == data_artifact.loc[idx]['goal'] else 'r'\n",
    "    ax.set_xlabel(data_artifact.loc[idx]['top_1'] + ' | ' + data_artifact.loc[idx]['model'], color=color)\n",
    "    likelihood = data_artifact.loc[idx]['likelihood']\n",
    "    ax.set_ylabel(data_artifact.loc[idx]['goal'], color=color) \n",
    "fig.set_facecolor(color='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the images with the lowest likelihood of the networks :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:13.993423Z",
     "iopub.status.busy": "2022-05-13T15:25:13.993071Z",
     "iopub.status.idle": "2022-05-13T15:25:14.022834Z",
     "shell.execute_reply": "2022-05-13T15:25:14.022303Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m N_image_i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[1;32m      3\u001b[0m N_image_j \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[0;32m----> 4\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39msubplots(N_image_i, N_image_j, figsize\u001b[38;5;241m=\u001b[39m(fig_width\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1.3\u001b[39m, fig_width))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i_image, idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data_artifact\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlikelihood\u001b[39m\u001b[38;5;124m'\u001b[39m], ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mhead(N_image_i\u001b[38;5;241m*\u001b[39mN_image_j)\u001b[38;5;241m.\u001b[39mindex):\n\u001b[1;32m      6\u001b[0m     ax \u001b[38;5;241m=\u001b[39m axs[i_image\u001b[38;5;241m%\u001b[39mN_image_i][i_image\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mN_image_i]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "N_image_i = 8\n",
    "N_image_j = 8\n",
    "fig, axs = plt.subplots(N_image_i, N_image_j, figsize=(fig_width*1.3, fig_width))\n",
    "for i_image, idx in enumerate(data_artifact.sort_values(by=['likelihood'], ascending=False).head(N_image_i*N_image_j).index):\n",
    "    ax = axs[i_image%N_image_i][i_image//N_image_i]\n",
    "    img_address = image_datasets['animal']['test'].imgs[data_artifact.loc[idx]['i_image']][0]\n",
    "    ax.imshow(imageio.imread(img_address))\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    color = 'g' if data_artifact.loc[idx]['top_1'] == data_artifact.loc[idx]['goal'] else 'r'\n",
    "    ax.set_xlabel(data_artifact.loc[idx]['top_1'] + ' | ' + data_artifact.loc[idx]['model'], color=color)\n",
    "    likelihood = data_artifact.loc[idx]['likelihood']\n",
    "    ax.set_ylabel(f'P ={likelihood:2.3f}%', color=color)\n",
    "fig.set_facecolor(color='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:14.026780Z",
     "iopub.status.busy": "2022-05-13T15:25:14.026598Z",
     "iopub.status.idle": "2022-05-13T15:25:14.064042Z",
     "shell.execute_reply": "2022-05-13T15:25:14.063381Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, precision_score, f1_score\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i,task \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43margs\u001b[49m\u001b[38;5;241m.\u001b[39mtasks):\n\u001b[1;32m      3\u001b[0m     df_acc \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({model_name: {flip: f1_score(data_artifact[(data_artifact[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mmodel_name) \u001b[38;5;241m&\u001b[39m (data_artifact[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mtask) \u001b[38;5;241m&\u001b[39m (data_artifact[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflip\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mflip) ][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_1\u001b[39m\u001b[38;5;124m\"\u001b[39m], \n\u001b[1;32m      4\u001b[0m                                                                    data_artifact[(data_artifact[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mmodel_name) \u001b[38;5;241m&\u001b[39m (data_artifact[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mtask) \u001b[38;5;241m&\u001b[39m (data_artifact[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflip\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mflip)][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoal\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      5\u001b[0m                                                       average \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmicro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m                                         \u001b[38;5;28;01mfor\u001b[39;00m flip \u001b[38;5;129;01min\u001b[39;00m flips} \n\u001b[1;32m      7\u001b[0m                            \u001b[38;5;28;01mfor\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m model_artifact})\n\u001b[1;32m      8\u001b[0m     df_acc\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;28mlen\u001b[39m(df_acc\u001b[38;5;241m.\u001b[39mindex)] \u001b[38;5;241m=\u001b[39m test_\u001b[38;5;241m.\u001b[39miloc[i]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
    "for i,task in enumerate(args.tasks):\n",
    "    df_acc = pd.DataFrame({model_name: {flip: f1_score(data_artifact[(data_artifact['model']==model_name) & (data_artifact['task']==task) & (data_artifact['flip']==flip) ][\"top_1\"], \n",
    "                                                                   data_artifact[(data_artifact['model']==model_name) & (data_artifact['task']==task) & (data_artifact['flip']==flip)][\"goal\"],\n",
    "                                                      average = 'micro')\n",
    "                                        for flip in flips} \n",
    "                           for model_name in model_artifact})\n",
    "    df_acc.loc[len(df_acc.index)] = test_.iloc[i]\n",
    "    temp_ = list(flips)\n",
    "    temp_.append('Base')\n",
    "    df_acc.index = temp_\n",
    "    ax = df_acc.T.plot.bar(rot=30, figsize=(fig_width, fig_width//4), fontsize=20)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.hlines(xmin=-.5, xmax=len(models_vgg.keys())-.5, y=1/2, ls='--', ec='k', label='chance level')\n",
    "    # https://matplotlib.org/stable/gallery/lines_bars_and_markers/bar_label_demo.html\n",
    "    for container in ax.containers: ax.bar_label(container, padding=-50, color='black', fontsize=14, fmt='%.3f', rotation=60)\n",
    "    plt.legend(bbox_to_anchor=(1.2, .35), loc='lower right', fontsize=14)\n",
    "    ax.set_title(f'Animal vs Artifact images f1 score for re-trained models, task: {task}', size=22)\n",
    "    ax.set_ylabel('F1 score', size=20)\n",
    "    ax.set_xlabel('Model', size=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computation Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:14.069707Z",
     "iopub.status.busy": "2022-05-13T15:25:14.069252Z",
     "iopub.status.idle": "2022-05-13T15:25:14.101385Z",
     "shell.execute_reply": "2022-05-13T15:25:14.100802Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39msubplots(figsize\u001b[38;5;241m=\u001b[39m(fig_width, fig_width\u001b[38;5;241m/\u001b[39mphi))\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m color, model_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(colors, models_vgg\u001b[38;5;241m.\u001b[39mkeys()):\n\u001b[1;32m      3\u001b[0m     axs \u001b[38;5;241m=\u001b[39m sns\u001b[38;5;241m.\u001b[39mviolinplot(x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflip\u001b[39m\u001b[38;5;124m\"\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m\"\u001b[39m, data\u001b[38;5;241m=\u001b[39mdf_flip, inner\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquartile\u001b[39m\u001b[38;5;124m\"\u001b[39m, hue\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "fig, axs = plt.subplots(figsize=(fig_width, fig_width/phi))\n",
    "for color, model_name in zip(colors, models_vgg.keys()):\n",
    "    axs = sns.violinplot(x=\"flip\", y=\"time\", data=df_flip, inner=\"quartile\", hue='model')\n",
    "    axs.set_title('Processing time (s) for each network at different image size. Processed on : ' + args.HOST + '_' + str(df_flip['device_type'][0]), size = 20)\n",
    "    axs.set_ylabel('Computation time (s)', size=18)\n",
    "    axs.set_xlabel('Image size', size=18)\n",
    "    axs.set_yscale('log')\n",
    "    axs.grid(which='both', axis='y')\n",
    "    for side in ['top', 'right'] :axs.spines[side].set_visible(False)\n",
    "h, l = axs.get_legend_handles_labels()\n",
    "axs.legend(h[:5], l[:5], loc='upper center', fontsize=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy comparison for all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:14.105037Z",
     "iopub.status.busy": "2022-05-13T15:25:14.104808Z",
     "iopub.status.idle": "2022-05-13T15:25:14.138396Z",
     "shell.execute_reply": "2022-05-13T15:25:14.137549Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m \u001b[43margs\u001b[49m\u001b[38;5;241m.\u001b[39mtasks:\n\u001b[1;32m      2\u001b[0m     df_acc \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({model_name: {flip: f1_score(df_flip[(df_flip[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mmodel_name) \u001b[38;5;241m&\u001b[39m (df_flip[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mtask) \u001b[38;5;241m&\u001b[39m (df_flip[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflip\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mflip) ][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_1\u001b[39m\u001b[38;5;124m\"\u001b[39m], \n\u001b[1;32m      3\u001b[0m                                                                    df_flip[(df_flip[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mmodel_name) \u001b[38;5;241m&\u001b[39m (df_flip[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mtask) \u001b[38;5;241m&\u001b[39m (df_flip[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflip\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mflip)][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoal\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      4\u001b[0m                                                       average \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmicro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m                                         \u001b[38;5;28;01mfor\u001b[39;00m flip \u001b[38;5;129;01min\u001b[39;00m flips} \n\u001b[1;32m      6\u001b[0m                            \u001b[38;5;28;01mfor\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m models_vgg})\n\u001b[1;32m      8\u001b[0m     ax \u001b[38;5;241m=\u001b[39m df_acc\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mplot\u001b[38;5;241m.\u001b[39mbar(rot\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m60\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(fig_width, fig_width\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m4\u001b[39m), fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "for task in args.tasks:\n",
    "    df_acc = pd.DataFrame({model_name: {flip: f1_score(df_flip[(df_flip['model']==model_name) & (df_flip['task']==task) & (df_flip['flip']==flip) ][\"top_1\"], \n",
    "                                                                   df_flip[(df_flip['model']==model_name) & (df_flip['task']==task) & (df_flip['flip']==flip)][\"goal\"],\n",
    "                                                      average = 'micro')\n",
    "                                        for flip in flips} \n",
    "                           for model_name in models_vgg})\n",
    "\n",
    "    ax = df_acc.T.plot.bar(rot=60, figsize=(fig_width, fig_width//4), fontsize=20)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.hlines(xmin=-.5, xmax=len(models_vgg.keys())-.5, y=1/2, ls='--', ec='k', label='chance level')\n",
    "    # https://matplotlib.org/stable/gallery/lines_bars_and_markers/bar_label_demo.html\n",
    "    for container in ax.containers: ax.bar_label(container, padding=-50, color='black', fontsize=14, fmt='%.3f', rotation=90)\n",
    "    plt.legend(bbox_to_anchor=(1.2, .35), loc='lower right', fontsize=14)\n",
    "    ax.set_title(f'Animal vs Artifact images f1 score for re-trained models, task: {task}', size=22)\n",
    "    ax.set_ylabel('F1 score', size=20)\n",
    "    ax.set_xlabel('Model', size=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "\n",
    "We tested the Vgg Gen network on the ImageNet dataset with either a vertical or horizontal reflection applied on the input. The networks keeps a good mean accuracy on the flipped dataset (about 95%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"exp3\"></a>\n",
    "## Experiment 3: Image processing and recognition for differents resolutions :\n",
    "\n",
    "Let's now study that same likelihood indicators at different image resolutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:14.141815Z",
     "iopub.status.busy": "2022-05-13T15:25:14.141456Z",
     "iopub.status.idle": "2022-05-13T15:25:14.145153Z",
     "shell.execute_reply": "2022-05-13T15:25:14.144688Z"
    }
   },
   "outputs": [],
   "source": [
    "scriptname = 'UltraFastCat/experiment_downsample.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:14.148299Z",
     "iopub.status.busy": "2022-05-13T15:25:14.148016Z",
     "iopub.status.idle": "2022-05-13T15:25:14.155478Z",
     "shell.execute_reply": "2022-05-13T15:25:14.154676Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting UltraFastCat/experiment_downsample.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {scriptname}\n",
    "\n",
    "#import model's script and set the output file\n",
    "from experiment_train import *\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "filename = f'results/{datetag}_results_downsample_{args.HOST}.json'\n",
    "print(f'{filename=}')\n",
    "\n",
    "def main():\n",
    "    if os.path.isfile(filename):\n",
    "        df_downsample = pd.read_json(filename)\n",
    "    else:\n",
    "        i_trial = 0\n",
    "        df_downsample = pd.DataFrame([], columns=['model', 'model_task', 'task', 'goal', 'likelihood', 'fps', 'time', 'i_image', 'filename', 'top_1', 'image_size', 'device_type'])   \n",
    "        # image preprocessing\n",
    "        for image_size in args.image_sizes:\n",
    "            (dataset_sizes, dataloaders, image_datasets, data_transforms) = datasets_transforms(image_size=image_size, batch_size=1)\n",
    "            print(f'Résolution de {image_size=}')\n",
    "            for task in args.tasks:\n",
    "                print(task)\n",
    "                for i_image, (data, label) in enumerate(dataloaders[task]['test']):\n",
    "                    data, label, = data.to(device), label.to(device)\n",
    "                    for model_name in models_vgg:\n",
    "                        model = models_vgg[model_name].to(device)\n",
    "                        with torch.no_grad():\n",
    "                            goal = 'target' if 'target' in image_datasets[task]['test'].imgs[i_image][0] else 'distractor'\n",
    "                            model_task = 'animal' if 'animal' in model_name else 'artifact'\n",
    "                            tic = time.time()\n",
    "                            out = model(data).squeeze(0)\n",
    "                            if model_name == 'vgg_16':\n",
    "                                temp_, likelihood = 0, 0\n",
    "                                model_task = 'Imagenet_challenge'\n",
    "                                percentage = torch.nn.functional.softmax(out, dim=0) * 100\n",
    "                                for idx in np.arange(0,1000,1):\n",
    "                                    if idx in match[task]:\n",
    "                                        likelihood += math.exp(percentage[idx].item())\n",
    "                                    else:\n",
    "                                        temp_ += math.exp(percentage[idx].item())  \n",
    "                                likelihood = likelihood/temp_\n",
    "                            else:\n",
    "                                likelihood = float((torch.sigmoid(out) * 100).detach().cpu().numpy()[0])\n",
    "                            top_1 = 'target' if likelihood>50 else 'distractor'\n",
    "                            elapsed_time = time.time() - tic \n",
    "                        df_downsample.loc[i_trial] = {'model':model_name,'model_task':model_task, 'task':task, 'top_1':top_1, 'goal':goal, 'likelihood':likelihood, 'time':elapsed_time, 'fps': 1/elapsed_time,\n",
    "                                               'i_image':i_image, 'filename':image_datasets[task]['test'].imgs[i_image][0], 'device_type':device.type, 'image_size':image_size}\n",
    "                        #print(f'The {model_name} model categorize {model_task} with {likelihood:.3f} % likelihood ({top_1}) in {elapsed_time:.3f} seconds, groundtrue : {task}, {goal}')\n",
    "                        i_trial += 1\n",
    "\n",
    "            df_downsample.to_json(filename)\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:14.158941Z",
     "iopub.status.busy": "2022-05-13T15:25:14.158662Z",
     "iopub.status.idle": "2022-05-13T15:25:14.729487Z",
     "shell.execute_reply": "2022-05-13T15:25:14.729041Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating file results/2022-05-13_config_args.json\n",
      "On date 2022-05-13 , Running benchmark on host babbage  with device cuda\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - '/home/laurent/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/corpus/util.py:84\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 84\u001b[0m     root \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mzip_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet.zip/wordnet/\u001b[0m\n\n  Searched in:\n    - '/home/laurent/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/metagit/JNJER/2022-03_UltraFastCat/UltraFastCat/experiment_downsample.py:3\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#import model's script and set the output file\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexperiment_train\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageFile\n\u001b[1;32m      5\u001b[0m ImageFile\u001b[38;5;241m.\u001b[39mLOAD_TRUNCATED_IMAGES \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/metagit/JNJER/2022-03_UltraFastCat/UltraFastCat/experiment_train.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageFile\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n",
      "File \u001b[0;32m~/metagit/JNJER/2022-03_UltraFastCat/src/model.py:2\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnnf\u001b[39;00m\n",
      "File \u001b[0;32m~/metagit/JNJER/2022-03_UltraFastCat/src/init.py:116\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    114\u001b[0m reverse_id_labels \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i_img, img_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(Imagenet_urls_ILSVRC_2016):\n\u001b[0;32m--> 116\u001b[0m     syn_\u001b[38;5;241m=\u001b[39m \u001b[43mwn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msynset_from_pos_and_offset\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mint\u001b[39m(img_id\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[1;32m    117\u001b[0m     reverse_id_labels[img_id] \u001b[38;5;241m=\u001b[39m syn_\u001b[38;5;241m.\u001b[39mlemmas()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mname()\n\u001b[1;32m    118\u001b[0m     labels\u001b[38;5;241m.\u001b[39mappend(syn_\u001b[38;5;241m.\u001b[39mlemmas()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mname())\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/corpus/util.py:121\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLazyCorpusLoader object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# This looks circular, but its not, since __load() changes our\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# __class__ to something new:\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/corpus/util.py:86\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m             root \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubdir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mzip_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n\u001b[0;32m---> 86\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Load the corpus.\u001b[39;00m\n\u001b[1;32m     89\u001b[0m corpus \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__reader_cls(root, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__kwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/corpus/util.py:81\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m         root \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[1;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - '/home/laurent/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IPython CPU timings (estimated):\n",
      "  User   :       0.46 s.\n",
      "  System :       0.11 s.\n",
      "Wall time:       0.57 s.\n"
     ]
    }
   ],
   "source": [
    "%run -int {scriptname}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:14.735315Z",
     "iopub.status.busy": "2022-05-13T15:25:14.735104Z",
     "iopub.status.idle": "2022-05-13T15:25:14.754847Z",
     "shell.execute_reply": "2022-05-13T15:25:14.754366Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [35]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m model_animal \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m model_artifact \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 4\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetag\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_results_downsample_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39mHOST\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      5\u001b[0m df_downsample \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_json(filename)\n\u001b[1;32m      6\u001b[0m data_animal \u001b[38;5;241m=\u001b[39m df_downsample\u001b[38;5;241m.\u001b[39mloc[df_downsample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_task\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124manimal\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "datetag = '2021-12-06'\n",
    "model_animal = []\n",
    "model_artifact = []\n",
    "filename = f'results/{datetag}_results_downsample_{args.HOST}.json'\n",
    "df_downsample = pd.read_json(filename)\n",
    "data_animal = df_downsample.loc[df_downsample['model_task'] == 'animal']\n",
    "data_artifact = df_downsample.loc[df_downsample['model_task'] == 'artifact']\n",
    "for model in models_vgg:\n",
    "    model_animal.append(model) if 'animal' in model else model_artifact.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Animal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image display "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the images with the highest likelihood of the networks :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:14.758264Z",
     "iopub.status.busy": "2022-05-13T15:25:14.758108Z",
     "iopub.status.idle": "2022-05-13T15:25:14.785112Z",
     "shell.execute_reply": "2022-05-13T15:25:14.784183Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [36]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m N_image_i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[1;32m      3\u001b[0m N_image_j \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[0;32m----> 4\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39msubplots(N_image_i, N_image_j, figsize\u001b[38;5;241m=\u001b[39m(fig_width\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1.3\u001b[39m, fig_width))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i_image, idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data_animal\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlikelihood\u001b[39m\u001b[38;5;124m'\u001b[39m], ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mhead(N_image_i\u001b[38;5;241m*\u001b[39mN_image_j)\u001b[38;5;241m.\u001b[39mindex):\n\u001b[1;32m      6\u001b[0m     ax \u001b[38;5;241m=\u001b[39m axs[i_image\u001b[38;5;241m%\u001b[39mN_image_i][i_image\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mN_image_i]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "N_image_i = 8\n",
    "N_image_j = 8\n",
    "fig, axs = plt.subplots(N_image_i, N_image_j, figsize=(fig_width*1.3, fig_width))\n",
    "for i_image, idx in enumerate(data_animal.sort_values(by=['likelihood'], ascending=False).head(N_image_i*N_image_j).index):\n",
    "    ax = axs[i_image%N_image_i][i_image//N_image_i]\n",
    "    img_address = image_datasets['animal']['test'].imgs[data_animal.loc[idx]['i_image']][0]\n",
    "    ax.imshow(imageio.imread(img_address))\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    color = 'g' if data_animal.loc[idx]['top_1'] == data_animal.loc[idx]['goal'] else 'r'\n",
    "    ax.set_xlabel(data_animal.loc[idx]['top_1'] + ' | ' + data_animal.loc[idx]['model'] + ' | ' + str(data_animal.loc[idx]['image_size']), color=color)\n",
    "    likelihood = data_animal.loc[idx]['likelihood']\n",
    "    ax.set_ylabel(f'P ={likelihood:2.3f}%', color=color)\n",
    "fig.set_facecolor(color='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the images with the lowest likelihood of the networks :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:14.788468Z",
     "iopub.status.busy": "2022-05-13T15:25:14.788043Z",
     "iopub.status.idle": "2022-05-13T15:25:14.819064Z",
     "shell.execute_reply": "2022-05-13T15:25:14.818233Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [37]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m N_image_i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[1;32m      3\u001b[0m N_image_j \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[0;32m----> 4\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39msubplots(N_image_i, N_image_j, figsize\u001b[38;5;241m=\u001b[39m(fig_width\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1.3\u001b[39m, fig_width))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i_image, idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data_animal\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlikelihood\u001b[39m\u001b[38;5;124m'\u001b[39m], ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mhead(N_image_i\u001b[38;5;241m*\u001b[39mN_image_j)\u001b[38;5;241m.\u001b[39mindex):\n\u001b[1;32m      6\u001b[0m     ax \u001b[38;5;241m=\u001b[39m axs[i_image\u001b[38;5;241m%\u001b[39mN_image_i][i_image\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mN_image_i]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "N_image_i = 8\n",
    "N_image_j = 8\n",
    "fig, axs = plt.subplots(N_image_i, N_image_j, figsize=(fig_width*1.3, fig_width))\n",
    "for i_image, idx in enumerate(data_animal.sort_values(by=['likelihood'], ascending=True).head(N_image_i*N_image_j).index):\n",
    "    ax = axs[i_image%N_image_i][i_image//N_image_i]\n",
    "    img_address = image_datasets['animal']['test'].imgs[data_animal.loc[idx]['i_image']][0]\n",
    "    ax.imshow(imageio.imread(img_address))\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    color = 'g' if data_animal.loc[idx]['top_1'] == data_animal.loc[idx]['goal'] else 'r'\n",
    "    ax.set_xlabel(data_animal.loc[idx]['top_1'] + ' | ' + data_animal.loc[idx]['model'] + ' | ' + str(data_animal.loc[idx]['image_size']), color=color)\n",
    "    likelihood = data_animal.loc[idx]['likelihood']\n",
    "    ax.set_ylabel(f'P ={likelihood:2.3f}%', color=color)\n",
    "fig.set_facecolor(color='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:14.822065Z",
     "iopub.status.busy": "2022-05-13T15:25:14.821778Z",
     "iopub.status.idle": "2022-05-13T15:25:14.857195Z",
     "shell.execute_reply": "2022-05-13T15:25:14.856204Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [38]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, precision_score, f1_score\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m \u001b[43margs\u001b[49m\u001b[38;5;241m.\u001b[39mtasks:\n\u001b[1;32m      3\u001b[0m     df_acc \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({model_name: {image_size: f1_score(data_animal[(data_animal[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mmodel_name) \u001b[38;5;241m&\u001b[39m (data_animal[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mtask) \u001b[38;5;241m&\u001b[39m (data_animal[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_size\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mimage_size) ][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_1\u001b[39m\u001b[38;5;124m\"\u001b[39m], \n\u001b[1;32m      4\u001b[0m                                                                    data_animal[(data_animal[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mmodel_name) \u001b[38;5;241m&\u001b[39m (data_animal[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mtask) \u001b[38;5;241m&\u001b[39m (data_animal[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_size\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mimage_size)][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoal\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      5\u001b[0m                                                       average \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmicro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m                                         \u001b[38;5;28;01mfor\u001b[39;00m image_size \u001b[38;5;129;01min\u001b[39;00m args\u001b[38;5;241m.\u001b[39mimage_sizes} \n\u001b[1;32m      7\u001b[0m                            \u001b[38;5;28;01mfor\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m model_animal})\n\u001b[1;32m      9\u001b[0m     ax \u001b[38;5;241m=\u001b[39m df_acc\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mplot\u001b[38;5;241m.\u001b[39mbar(rot\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m60\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(fig_width, fig_width\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m4\u001b[39m), fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
    "for task in args.tasks:\n",
    "    df_acc = pd.DataFrame({model_name: {image_size: f1_score(data_animal[(data_animal['model']==model_name) & (data_animal['task']==task) & (data_animal['image_size']==image_size) ][\"top_1\"], \n",
    "                                                                   data_animal[(data_animal['model']==model_name) & (data_animal['task']==task) & (data_animal['image_size']==image_size)][\"goal\"],\n",
    "                                                      average = 'micro')\n",
    "                                        for image_size in args.image_sizes} \n",
    "                           for model_name in model_animal})\n",
    "\n",
    "    ax = df_acc.T.plot.bar(rot=60, figsize=(fig_width, fig_width//4), fontsize=20)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.hlines(xmin=-.5, xmax=len(models_vgg)-.5, y=1/2, ls='--', ec='k', label='chance level')\n",
    "    # https://matplotlib.org/stable/gallery/lines_bars_and_markers/bar_label_demo.html\n",
    "    for container in ax.containers: ax.bar_label(container, padding=-50, color='black', fontsize=14, fmt='%.3f', rotation=60)\n",
    "    plt.legend(bbox_to_anchor=(1.2, .35), loc='lower right', fontsize=14)\n",
    "    ax.set_title(f'Animal vs Artifact images f1 score for re-trained models, task: {task}', size=22)\n",
    "    ax.set_ylabel('F1 score', size=20)\n",
    "    ax.set_xlabel('Model', size=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image display :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the images with the highest likelihood of the networks :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:14.860319Z",
     "iopub.status.busy": "2022-05-13T15:25:14.860030Z",
     "iopub.status.idle": "2022-05-13T15:25:14.892279Z",
     "shell.execute_reply": "2022-05-13T15:25:14.891310Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [39]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m N_image_i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[1;32m      3\u001b[0m N_image_j \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[0;32m----> 4\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39msubplots(N_image_i, N_image_j, figsize\u001b[38;5;241m=\u001b[39m(fig_width\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1.3\u001b[39m, fig_width))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i_image, idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data_artifact\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlikelihood\u001b[39m\u001b[38;5;124m'\u001b[39m], ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mhead(N_image_i\u001b[38;5;241m*\u001b[39mN_image_j)\u001b[38;5;241m.\u001b[39mindex):\n\u001b[1;32m      6\u001b[0m     ax \u001b[38;5;241m=\u001b[39m axs[i_image\u001b[38;5;241m%\u001b[39mN_image_i][i_image\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mN_image_i]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "N_image_i = 8\n",
    "N_image_j = 8\n",
    "fig, axs = plt.subplots(N_image_i, N_image_j, figsize=(fig_width*1.3, fig_width))\n",
    "for i_image, idx in enumerate(data_artifact.sort_values(by=['likelihood'], ascending=False).head(N_image_i*N_image_j).index):\n",
    "    ax = axs[i_image%N_image_i][i_image//N_image_i]\n",
    "    img_address = image_datasets['artifact']['test'].imgs[data_artifact.loc[idx]['i_image']][0]\n",
    "    ax.imshow(imageio.imread(img_address))\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    color = 'g' if data_artifact.loc[idx]['top_1'] == data_artifact.loc[idx]['goal'] else 'r'\n",
    "    ax.set_xlabel(data_artifact.loc[idx]['top_1'] + ' | ' + data_artifact.loc[idx]['model'] + ' | ' + str(data_artifact.loc[idx]['image_size']), color=color)\n",
    "    likelihood = data_artifact.loc[idx]['likelihood']\n",
    "    ax.set_ylabel(f'P ={likelihood:2.3f}%', color=color)\n",
    "fig.set_facecolor(color='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the images with the lowest likelihood of the networks :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:14.895708Z",
     "iopub.status.busy": "2022-05-13T15:25:14.895352Z",
     "iopub.status.idle": "2022-05-13T15:25:14.925914Z",
     "shell.execute_reply": "2022-05-13T15:25:14.925241Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [40]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m N_image_i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[1;32m      3\u001b[0m N_image_j \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[0;32m----> 4\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39msubplots(N_image_i, N_image_j, figsize\u001b[38;5;241m=\u001b[39m(fig_width\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1.3\u001b[39m, fig_width))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i_image, idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data_artifact\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlikelihood\u001b[39m\u001b[38;5;124m'\u001b[39m], ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mhead(N_image_i\u001b[38;5;241m*\u001b[39mN_image_j)\u001b[38;5;241m.\u001b[39mindex):\n\u001b[1;32m      6\u001b[0m     ax \u001b[38;5;241m=\u001b[39m axs[i_image\u001b[38;5;241m%\u001b[39mN_image_i][i_image\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mN_image_i]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "N_image_i = 8\n",
    "N_image_j = 8\n",
    "fig, axs = plt.subplots(N_image_i, N_image_j, figsize=(fig_width*1.3, fig_width))\n",
    "for i_image, idx in enumerate(data_artifact.sort_values(by=['likelihood'], ascending=True).head(N_image_i*N_image_j).index):\n",
    "    ax = axs[i_image%N_image_i][i_image//N_image_i]\n",
    "    img_address = image_datasets['artifact']['test'].imgs[data_artifact.loc[idx]['i_image']][0]\n",
    "    ax.imshow(imageio.imread(img_address))\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    color = 'g' if data_artifact.loc[idx]['top_1'] == data_artifact.loc[idx]['goal'] else 'r'\n",
    "    ax.set_xlabel(data_artifact.loc[idx]['top_1'] + ' | ' + data_artifact.loc[idx]['model'] + ' | ' + str(data_artifact.loc[idx]['image_size']), color=color)\n",
    "    likelihood = data_artifact.loc[idx]['likelihood']\n",
    "    ax.set_ylabel(f'P ={likelihood:2.3f}%', color=color)\n",
    "fig.set_facecolor(color='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:14.930390Z",
     "iopub.status.busy": "2022-05-13T15:25:14.930028Z",
     "iopub.status.idle": "2022-05-13T15:25:14.966961Z",
     "shell.execute_reply": "2022-05-13T15:25:14.966290Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [41]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, precision_score, f1_score\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m \u001b[43margs\u001b[49m\u001b[38;5;241m.\u001b[39mtasks:\n\u001b[1;32m      3\u001b[0m     df_acc \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({model_name: {image_size: f1_score(data_artifact[(data_artifact[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mmodel_name) \u001b[38;5;241m&\u001b[39m (data_artifact[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mtask) \u001b[38;5;241m&\u001b[39m (data_artifact[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_size\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mimage_size) ][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_1\u001b[39m\u001b[38;5;124m\"\u001b[39m], \n\u001b[1;32m      4\u001b[0m                                                                    data_artifact[(data_artifact[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mmodel_name) \u001b[38;5;241m&\u001b[39m (data_artifact[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mtask) \u001b[38;5;241m&\u001b[39m (data_artifact[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_size\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mimage_size)][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoal\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      5\u001b[0m                                                       average \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmicro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m                                        \u001b[38;5;28;01mfor\u001b[39;00m image_size \u001b[38;5;129;01min\u001b[39;00m args\u001b[38;5;241m.\u001b[39mimage_sizes} \n\u001b[1;32m      7\u001b[0m                            \u001b[38;5;28;01mfor\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m model_artifact})\n\u001b[1;32m      9\u001b[0m     ax \u001b[38;5;241m=\u001b[39m df_acc\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mplot\u001b[38;5;241m.\u001b[39mbar(rot\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(fig_width, fig_width\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m4\u001b[39m), fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
    "for task in args.tasks:\n",
    "    df_acc = pd.DataFrame({model_name: {image_size: f1_score(data_artifact[(data_artifact['model']==model_name) & (data_artifact['task']==task) & (data_artifact['image_size']==image_size) ][\"top_1\"], \n",
    "                                                                   data_artifact[(data_artifact['model']==model_name) & (data_artifact['task']==task) & (data_artifact['image_size']==image_size)][\"goal\"],\n",
    "                                                      average = 'micro')\n",
    "                                       for image_size in args.image_sizes} \n",
    "                           for model_name in model_artifact})\n",
    "\n",
    "    ax = df_acc.T.plot.bar(rot=30, figsize=(fig_width, fig_width//4), fontsize=20)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.hlines(xmin=-.5, xmax=len(models_vgg)-.5, y=1/2, ls='--', ec='k', label='chance level')\n",
    "    # https://matplotlib.org/stable/gallery/lines_bars_and_markers/bar_label_demo.html\n",
    "    for container in ax.containers: ax.bar_label(container, padding=-50, color='black', fontsize=14, fmt='%.3f', rotation=60)\n",
    "    plt.legend(bbox_to_anchor=(1.2, .35), loc='lower right', fontsize=14)\n",
    "    ax.set_title(f'Animal vs Artifact images f1 score for re-trained models, task: {task}', size=22)\n",
    "    ax.set_ylabel('F1 score', size=20)\n",
    "    ax.set_xlabel('Model', size=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computation time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:14.970000Z",
     "iopub.status.busy": "2022-05-13T15:25:14.969816Z",
     "iopub.status.idle": "2022-05-13T15:25:14.993152Z",
     "shell.execute_reply": "2022-05-13T15:25:14.992616Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [42]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39msubplots(figsize\u001b[38;5;241m=\u001b[39m(fig_width, fig_width\u001b[38;5;241m/\u001b[39mphi))\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m color, model_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(colors, models_vgg):\n\u001b[1;32m      3\u001b[0m     axs \u001b[38;5;241m=\u001b[39m sns\u001b[38;5;241m.\u001b[39mviolinplot(x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_size\u001b[39m\u001b[38;5;124m\"\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m\"\u001b[39m, data\u001b[38;5;241m=\u001b[39mdf_downsample, inner\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquartile\u001b[39m\u001b[38;5;124m\"\u001b[39m, hue\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "fig, axs = plt.subplots(figsize=(fig_width, fig_width/phi))\n",
    "for color, model_name in zip(colors, models_vgg):\n",
    "    axs = sns.violinplot(x=\"image_size\", y=\"time\", data=df_downsample, inner=\"quartile\", hue='model')\n",
    "    axs.set_title('Processing time (s) for each network at different image size. Processed on : ' + args.HOST + '_' + str(df_downsample['device_type'][0]), size = 20)\n",
    "    axs.set_ylabel('Computation time (s)', size=18)\n",
    "    axs.set_xlabel('Image size', size=18)\n",
    "    axs.set_yscale('log')\n",
    "    axs.grid(which='both', axis='y')\n",
    "    for side in ['top', 'right'] :axs.spines[side].set_visible(False)\n",
    "h, l = axs.get_legend_handles_labels()\n",
    "axs.legend(h[:5], l[:5], loc='upper center', fontsize=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy comparison for all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:14.996227Z",
     "iopub.status.busy": "2022-05-13T15:25:14.996024Z",
     "iopub.status.idle": "2022-05-13T15:25:15.025523Z",
     "shell.execute_reply": "2022-05-13T15:25:15.025020Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [43]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, precision_score, f1_score\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m \u001b[43margs\u001b[49m\u001b[38;5;241m.\u001b[39mtasks:\n\u001b[1;32m      3\u001b[0m     df_acc \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({model_name: {image_size: f1_score(df_downsample[(df_downsample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mmodel_name) \u001b[38;5;241m&\u001b[39m (df_downsample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mtask) \u001b[38;5;241m&\u001b[39m (df_downsample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_size\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mimage_size) ][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_1\u001b[39m\u001b[38;5;124m\"\u001b[39m], \n\u001b[1;32m      4\u001b[0m                                                                    df_downsample[(df_downsample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mmodel_name) \u001b[38;5;241m&\u001b[39m (df_downsample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mtask) \u001b[38;5;241m&\u001b[39m (df_downsample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_size\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mimage_size)][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoal\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      5\u001b[0m                                                       average \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmicro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m                                         \u001b[38;5;28;01mfor\u001b[39;00m image_size \u001b[38;5;129;01min\u001b[39;00m args\u001b[38;5;241m.\u001b[39mimage_sizes} \n\u001b[1;32m      7\u001b[0m                            \u001b[38;5;28;01mfor\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m models_vgg})\n\u001b[1;32m      9\u001b[0m     ax \u001b[38;5;241m=\u001b[39m df_acc\u001b[38;5;241m.\u001b[39mplot\u001b[38;5;241m.\u001b[39mbar(rot\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m60\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(fig_width, fig_width\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m4\u001b[39m), fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
    "for task in args.tasks:\n",
    "    df_acc = pd.DataFrame({model_name: {image_size: f1_score(df_downsample[(df_downsample['model']==model_name) & (df_downsample['task']==task) & (df_downsample['image_size']==image_size) ][\"top_1\"], \n",
    "                                                                   df_downsample[(df_downsample['model']==model_name) & (df_downsample['task']==task) & (df_downsample['image_size']==image_size)][\"goal\"],\n",
    "                                                      average = 'micro')\n",
    "                                        for image_size in args.image_sizes} \n",
    "                           for model_name in models_vgg})\n",
    "\n",
    "    ax = df_acc.plot.bar(rot=60, figsize=(fig_width, fig_width//4), fontsize=20)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.hlines(xmin=-.5, xmax=len(models_vgg)-.5, y=1/2, ls='--', ec='k', label='chance level')\n",
    "    # https://matplotlib.org/stable/gallery/lines_bars_and_markers/bar_label_demo.html\n",
    "    for container in ax.containers: ax.bar_label(container, padding=-50, color='black', fontsize=14, fmt='%.3f', rotation=90)\n",
    "    plt.legend(bbox_to_anchor=(1.2, .3), loc='lower right', fontsize=14)\n",
    "    ax.set_title(f'Animal vs Artifact images f1 score for re-trained models, task: {task}', size=22)\n",
    "    ax.set_ylabel('F1 score', size=20)\n",
    "    ax.set_xlabel('Model', size=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:15.030382Z",
     "iopub.status.busy": "2022-05-13T15:25:15.030192Z",
     "iopub.status.idle": "2022-05-13T15:25:15.063781Z",
     "shell.execute_reply": "2022-05-13T15:25:15.063199Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [44]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, precision_score, f1_score\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m \u001b[43margs\u001b[49m\u001b[38;5;241m.\u001b[39mtasks:\n\u001b[1;32m      3\u001b[0m     df_acc \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({model_name: {image_size: f1_score(df_downsample[(df_downsample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mmodel_name) \u001b[38;5;241m&\u001b[39m (df_downsample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mtask) \u001b[38;5;241m&\u001b[39m (df_downsample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_size\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mimage_size) ][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_1\u001b[39m\u001b[38;5;124m\"\u001b[39m], \n\u001b[1;32m      4\u001b[0m                                                                    df_downsample[(df_downsample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mmodel_name) \u001b[38;5;241m&\u001b[39m (df_downsample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mtask) \u001b[38;5;241m&\u001b[39m (df_downsample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_size\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mimage_size)][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoal\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      5\u001b[0m                                                       average \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmicro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m                                         \u001b[38;5;28;01mfor\u001b[39;00m image_size \u001b[38;5;129;01min\u001b[39;00m args\u001b[38;5;241m.\u001b[39mimage_sizes} \n\u001b[1;32m      7\u001b[0m                            \u001b[38;5;28;01mfor\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m models_vgg})\n\u001b[1;32m      9\u001b[0m     ax \u001b[38;5;241m=\u001b[39m df_acc\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mplot\u001b[38;5;241m.\u001b[39mbar(rot\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m60\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(fig_width, fig_width\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m4\u001b[39m), fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
    "for task in args.tasks:\n",
    "    df_acc = pd.DataFrame({model_name: {image_size: f1_score(df_downsample[(df_downsample['model']==model_name) & (df_downsample['task']==task) & (df_downsample['image_size']==image_size) ][\"top_1\"], \n",
    "                                                                   df_downsample[(df_downsample['model']==model_name) & (df_downsample['task']==task) & (df_downsample['image_size']==image_size)][\"goal\"],\n",
    "                                                      average = 'micro')\n",
    "                                        for image_size in args.image_sizes} \n",
    "                           for model_name in models_vgg})\n",
    "\n",
    "    ax = df_acc.T.plot.bar(rot=60, figsize=(fig_width, fig_width//4), fontsize=20)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.hlines(xmin=-.5, xmax=len(models_vgg)-.5, y=1/2, ls='--', ec='k', label='chance level')\n",
    "    # https://matplotlib.org/stable/gallery/lines_bars_and_markers/bar_label_demo.html\n",
    "    for container in ax.containers: ax.bar_label(container, padding=-50, color='black', fontsize=14, fmt='%.3f', rotation=90)\n",
    "    plt.legend(bbox_to_anchor=(1.2, .3), loc='lower right', fontsize=14)\n",
    "    ax.set_title(f'Animal vs Artifact images f1 score for re-trained models, task: {task}', size=22)\n",
    "    ax.set_ylabel('F1 score', size=20)\n",
    "    ax.set_xlabel('Model', size=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "\n",
    "We found similar results as in flip transformation when testing  the netxworks on our dataset with different image sizes [experiment 3](#exp3), even if the network train on such transformation seems more robust to this transformation than the others the networks keeps a good mean accuracy on the whole downscaling dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"exp4\"></a>\n",
    "## Experiment 4: Image processing and recognition on grayscale images :\n",
    "\n",
    "Again, same likelihood indicators but now with a grayscale transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:15.067670Z",
     "iopub.status.busy": "2022-05-13T15:25:15.067493Z",
     "iopub.status.idle": "2022-05-13T15:25:15.070471Z",
     "shell.execute_reply": "2022-05-13T15:25:15.069966Z"
    }
   },
   "outputs": [],
   "source": [
    "scriptname = 'UltraFastCat/experiment_grayscale.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:15.073060Z",
     "iopub.status.busy": "2022-05-13T15:25:15.072831Z",
     "iopub.status.idle": "2022-05-13T15:25:15.078409Z",
     "shell.execute_reply": "2022-05-13T15:25:15.077868Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting UltraFastCat/experiment_grayscale.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {scriptname}\n",
    "\n",
    "#import model's script and set the output file\n",
    "\n",
    "#from UltraFastCat.model import *\n",
    "from experiment_train import *\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "filename = f'results/{datetag}_results_3_{args.HOST}.json'\n",
    "print(f'{filename=}')\n",
    "\n",
    "def main():\n",
    "    if os.path.isfile(filename):\n",
    "        df_gray = pd.read_json(filename)\n",
    "    else:\n",
    "        i_trial = 0\n",
    "        df_gray = pd.DataFrame([], columns=['model', 'model_task', 'task', 'goal', 'likelihood', 'fps', 'time', 'i_image', 'filename', 'top_1', 'device_type']) \n",
    "            # image preprocessing\n",
    "        (dataset_sizes, dataloaders, image_datasets, data_transforms) = datasets_transforms(image_size=args.image_size, batch_size=1, p=1)\n",
    "        for task in args.tasks:\n",
    "            pprint(task)\n",
    "            for i_image, (data, label) in enumerate(dataloaders[task]['test']):\n",
    "                data, label = data.to(device), label.to(device)\n",
    "                for model_name in models_vgg:\n",
    "                    model = models_vgg[model_name].to(device)\n",
    "                    with torch.no_grad():\n",
    "                        goal = 'target' if 'target' in image_datasets[task]['test'].imgs[i_image][0] else 'distractor'\n",
    "                        model_task = 'animal' if 'animal' in model_name else 'artifact'\n",
    "                        tic = time.time()\n",
    "                        out = model(data).squeeze(0)\n",
    "                        if model_name == 'vgg_16':\n",
    "                            temp_, likelihood = 0, 0\n",
    "                            model_task = 'Imagenet_challenge'\n",
    "                            percentage = torch.nn.functional.softmax(out, dim=0) * 100\n",
    "                            for idx in np.arange(0,1000,1):\n",
    "                                if idx in match[task]:\n",
    "                                    likelihood += math.exp(percentage[idx].item())\n",
    "                                else:\n",
    "                                    temp_ += math.exp(percentage[idx].item())  \n",
    "                            likelihood = likelihood/temp_\n",
    "                        else:\n",
    "                            likelihood = float((torch.sigmoid(out) * 100).detach().cpu().numpy()[0])\n",
    "                        top_1 = 'target' if percentage>50 else 'distractor'\n",
    "                        elapsed_time = time.time() - tic\n",
    "                    df_gray.loc[i_trial] = {'model':model_name,'model_task':model_task, 'task':task, 'top_1':top_1, 'goal':goal, 'likelihood':likelihood, 'time':elapsed_time, 'fps': 1/elapsed_time,\n",
    "                                          'i_image':i_image, 'filename':image_datasets[task]['test'].imgs[i_image][0], 'device_type':device.type}\n",
    "                    print(f'The {model_name} model categorize {model_task} with {likelihood:.3f} % likelihood ({top_1}) in {elapsed_time:.3f} seconds, groundtrue : {task}, {goal}')\n",
    "                    i_trial += 1\n",
    "        df_gray.to_json(filename)\n",
    "main()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:15.081272Z",
     "iopub.status.busy": "2022-05-13T15:25:15.081031Z",
     "iopub.status.idle": "2022-05-13T15:25:15.628277Z",
     "shell.execute_reply": "2022-05-13T15:25:15.627832Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating file results/2022-05-13_config_args.json\n",
      "On date 2022-05-13 , Running benchmark on host babbage  with device cuda\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - '/home/laurent/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/corpus/util.py:84\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 84\u001b[0m     root \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mzip_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet.zip/wordnet/\u001b[0m\n\n  Searched in:\n    - '/home/laurent/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/metagit/JNJER/2022-03_UltraFastCat/UltraFastCat/experiment_grayscale.py:5\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#import model's script and set the output file\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#from UltraFastCat.model import *\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexperiment_train\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageFile\n\u001b[1;32m      7\u001b[0m ImageFile\u001b[38;5;241m.\u001b[39mLOAD_TRUNCATED_IMAGES \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/metagit/JNJER/2022-03_UltraFastCat/UltraFastCat/experiment_train.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageFile\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n",
      "File \u001b[0;32m~/metagit/JNJER/2022-03_UltraFastCat/src/model.py:2\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnnf\u001b[39;00m\n",
      "File \u001b[0;32m~/metagit/JNJER/2022-03_UltraFastCat/src/init.py:116\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    114\u001b[0m reverse_id_labels \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i_img, img_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(Imagenet_urls_ILSVRC_2016):\n\u001b[0;32m--> 116\u001b[0m     syn_\u001b[38;5;241m=\u001b[39m \u001b[43mwn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msynset_from_pos_and_offset\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mint\u001b[39m(img_id\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[1;32m    117\u001b[0m     reverse_id_labels[img_id] \u001b[38;5;241m=\u001b[39m syn_\u001b[38;5;241m.\u001b[39mlemmas()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mname()\n\u001b[1;32m    118\u001b[0m     labels\u001b[38;5;241m.\u001b[39mappend(syn_\u001b[38;5;241m.\u001b[39mlemmas()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mname())\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/corpus/util.py:121\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLazyCorpusLoader object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# This looks circular, but its not, since __load() changes our\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# __class__ to something new:\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/corpus/util.py:86\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m             root \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubdir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mzip_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n\u001b[0;32m---> 86\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Load the corpus.\u001b[39;00m\n\u001b[1;32m     89\u001b[0m corpus \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__reader_cls(root, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__kwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/corpus/util.py:81\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m         root \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[1;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - '/home/laurent/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IPython CPU timings (estimated):\n",
      "  User   :       0.40 s.\n",
      "  System :       0.14 s.\n",
      "Wall time:       0.54 s.\n"
     ]
    }
   ],
   "source": [
    "%run -int {scriptname}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:15.633619Z",
     "iopub.status.busy": "2022-05-13T15:25:15.633467Z",
     "iopub.status.idle": "2022-05-13T15:25:15.652724Z",
     "shell.execute_reply": "2022-05-13T15:25:15.652126Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [48]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m model_animal \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m model_artifact \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 4\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetag\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_results_3_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39mHOST\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      5\u001b[0m df_gray \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_json(filename)\n\u001b[1;32m      6\u001b[0m data_animal \u001b[38;5;241m=\u001b[39m df_gray\u001b[38;5;241m.\u001b[39mloc[df_gray[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_task\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124manimal\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "datetag = '2021-12-09'\n",
    "model_animal = []\n",
    "model_artifact = []\n",
    "filename = f'results/{datetag}_results_3_{args.HOST}.json'\n",
    "df_gray = pd.read_json(filename)\n",
    "data_animal = df_gray.loc[df_gray['model_task'] == 'animal']\n",
    "data_artifact = df_gray.loc[df_gray['model_task'] == 'artifact']\n",
    "for model in models_vgg:\n",
    "    model_animal.append(model) if 'animal' in model else model_artifact.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Animal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the images with the highest likelihood of the networks :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:15.655580Z",
     "iopub.status.busy": "2022-05-13T15:25:15.655257Z",
     "iopub.status.idle": "2022-05-13T15:25:15.682088Z",
     "shell.execute_reply": "2022-05-13T15:25:15.681333Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [49]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m N_image_i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[1;32m      3\u001b[0m N_image_j \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[0;32m----> 4\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39msubplots(N_image_i, N_image_j, figsize\u001b[38;5;241m=\u001b[39m(fig_width\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1.3\u001b[39m, fig_width))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i_image, idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data_animal\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlikelihood\u001b[39m\u001b[38;5;124m'\u001b[39m], ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mhead(N_image_i\u001b[38;5;241m*\u001b[39mN_image_j)\u001b[38;5;241m.\u001b[39mindex):\n\u001b[1;32m      6\u001b[0m     ax \u001b[38;5;241m=\u001b[39m axs[i_image\u001b[38;5;241m%\u001b[39mN_image_i][i_image\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mN_image_i]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "N_image_i = 8\n",
    "N_image_j = 8\n",
    "fig, axs = plt.subplots(N_image_i, N_image_j, figsize=(fig_width*1.3, fig_width))\n",
    "for i_image, idx in enumerate(data_animal.sort_values(by=['likelihood'], ascending=False).head(N_image_i*N_image_j).index):\n",
    "    ax = axs[i_image%N_image_i][i_image//N_image_i]\n",
    "    img_address = image_datasets['animal']['test'].imgs[data_animal.loc[idx]['i_image']][0]\n",
    "    ax.imshow(imageio.imread(img_address, pilmode=\"L\"), cmap='gray')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    color = 'g' if data_animal.loc[idx]['top_1'] == data_animal.loc[idx]['goal'] else 'r'\n",
    "    ax.set_xlabel(data_animal.loc[idx]['top_1'] + ' | ' + data_animal.loc[idx]['model'], color=color)\n",
    "    likelihood = data_animal.loc[idx]['likelihood']\n",
    "    ax.set_ylabel(f'P ={likelihood:2.3f}%', color=color)\n",
    "fig.set_facecolor(color='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the images with the lowest likelihood of the networks :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:15.686201Z",
     "iopub.status.busy": "2022-05-13T15:25:15.685862Z",
     "iopub.status.idle": "2022-05-13T15:25:15.713918Z",
     "shell.execute_reply": "2022-05-13T15:25:15.713489Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [50]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m N_image_i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[1;32m      3\u001b[0m N_image_j \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[0;32m----> 4\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39msubplots(N_image_i, N_image_j, figsize\u001b[38;5;241m=\u001b[39m(fig_width\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1.3\u001b[39m, fig_width))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i_image, idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data_animal\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlikelihood\u001b[39m\u001b[38;5;124m'\u001b[39m], ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mhead(N_image_i\u001b[38;5;241m*\u001b[39mN_image_j)\u001b[38;5;241m.\u001b[39mindex):\n\u001b[1;32m      6\u001b[0m     ax \u001b[38;5;241m=\u001b[39m axs[i_image\u001b[38;5;241m%\u001b[39mN_image_i][i_image\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mN_image_i]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "N_image_i = 8\n",
    "N_image_j = 8\n",
    "fig, axs = plt.subplots(N_image_i, N_image_j, figsize=(fig_width*1.3, fig_width))\n",
    "for i_image, idx in enumerate(data_animal.sort_values(by=['likelihood'], ascending=True).head(N_image_i*N_image_j).index):\n",
    "    ax = axs[i_image%N_image_i][i_image//N_image_i]\n",
    "    img_address = image_datasets['animal']['test'].imgs[data_animal.loc[idx]['i_image']][0]\n",
    "    ax.imshow(imageio.imread(img_address, pilmode=\"L\"), cmap='gray')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    color = 'g' if data_animal.loc[idx]['top_1'] == data_animal.loc[idx]['goal'] else 'r'\n",
    "    ax.set_xlabel(data_animal.loc[idx]['top_1'] + ' | ' + data_animal.loc[idx]['model'], color=color)\n",
    "    likelihood = data_animal.loc[idx]['likelihood']\n",
    "    ax.set_ylabel(f'P ={likelihood:2.3f}%', color=color) \n",
    "fig.set_facecolor(color='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:15.716588Z",
     "iopub.status.busy": "2022-05-13T15:25:15.716317Z",
     "iopub.status.idle": "2022-05-13T15:25:15.744379Z",
     "shell.execute_reply": "2022-05-13T15:25:15.743952Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [51]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, precision_score, f1_score\n\u001b[0;32m----> 2\u001b[0m df_acc \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame({model_name: {task: f1_score(data_animal[(data_animal[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mmodel_name) \u001b[38;5;241m&\u001b[39m (data_animal[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mtask)][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_1\u001b[39m\u001b[38;5;124m\"\u001b[39m], \n\u001b[1;32m      3\u001b[0m                                                                data_animal[(data_animal[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mmodel_name) \u001b[38;5;241m&\u001b[39m (data_animal[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mtask)][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoal\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      4\u001b[0m                                                   average \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmicro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m                                     \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m args\u001b[38;5;241m.\u001b[39mtasks} \n\u001b[1;32m      6\u001b[0m                        \u001b[38;5;28;01mfor\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m model_animal})\n\u001b[1;32m      7\u001b[0m test \u001b[38;5;241m=\u001b[39m df_acc\n\u001b[1;32m      8\u001b[0m ax \u001b[38;5;241m=\u001b[39m df_acc\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mplot\u001b[38;5;241m.\u001b[39mbar(rot\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(fig_width, fig_width\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m4\u001b[39m), fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
    "df_acc = pd.DataFrame({model_name: {task: f1_score(data_animal[(data_animal['model']==model_name) & (data_animal['task']==task)][\"top_1\"], \n",
    "                                                               data_animal[(data_animal['model']==model_name) & (data_animal['task']==task)][\"goal\"],\n",
    "                                                  average = 'micro')\n",
    "                                    for task in args.tasks} \n",
    "                       for model_name in model_animal})\n",
    "test = df_acc\n",
    "ax = df_acc.T.plot.bar(rot=0, figsize=(fig_width, fig_width//4), fontsize=20)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.hlines(xmin=-.5, xmax=len(models_vgg)-.5, y=1/2, ls='--', ec='k', label='chance level')\n",
    "# https://matplotlib.org/stable/gallery/lines_bars_and_markers/bar_label_demo.html\n",
    "for container in ax.containers: ax.bar_label(container, padding=-50, color='black', fontsize=14, fmt='%.3f', rotation=60)\n",
    "plt.legend(bbox_to_anchor=(1.2, .35), loc='lower right', fontsize=18)\n",
    "ax.set_title(f'Animal vs Artifact images f1 score for re-trained models', size=22)\n",
    "ax.set_ylabel('Accuracy', size=20)\n",
    "ax.set_xlabel('Model', size=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the images with the highest likelihood of the networks :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:15.748677Z",
     "iopub.status.busy": "2022-05-13T15:25:15.748530Z",
     "iopub.status.idle": "2022-05-13T15:25:15.774892Z",
     "shell.execute_reply": "2022-05-13T15:25:15.773984Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [52]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m N_image_i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[1;32m      3\u001b[0m N_image_j \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[0;32m----> 4\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39msubplots(N_image_i, N_image_j, figsize\u001b[38;5;241m=\u001b[39m(fig_width\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1.3\u001b[39m, fig_width))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i_image, idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data_artifact\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlikelihood\u001b[39m\u001b[38;5;124m'\u001b[39m], ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mhead(N_image_i\u001b[38;5;241m*\u001b[39mN_image_j)\u001b[38;5;241m.\u001b[39mindex):\n\u001b[1;32m      6\u001b[0m     ax \u001b[38;5;241m=\u001b[39m axs[i_image\u001b[38;5;241m%\u001b[39mN_image_i][i_image\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mN_image_i]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "N_image_i = 8\n",
    "N_image_j = 8\n",
    "fig, axs = plt.subplots(N_image_i, N_image_j, figsize=(fig_width*1.3, fig_width))\n",
    "for i_image, idx in enumerate(data_artifact.sort_values(by=['likelihood'], ascending=False).head(N_image_i*N_image_j).index):\n",
    "    ax = axs[i_image%N_image_i][i_image//N_image_i]\n",
    "    img_address = image_datasets['artifact']['test'].imgs[data_artifact.loc[idx]['i_image']][0]\n",
    "    ax.imshow(imageio.imread(img_address, pilmode=\"L\"), cmap='gray')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    color = 'g' if data_artifact.loc[idx]['top_1'] == data_artifact.loc[idx]['goal'] else 'r'\n",
    "    ax.set_xlabel(data_artifact.loc[idx]['top_1'] + ' | ' + data_artifact.loc[idx]['model'], color=color)\n",
    "    likelihood = data_artifact.loc[idx]['likelihood']\n",
    "    ax.set_ylabel(f'P ={likelihood:2.3f}%', color=color)\n",
    "fig.set_facecolor(color='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the images with the lowest likelihood of the networks :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:15.778183Z",
     "iopub.status.busy": "2022-05-13T15:25:15.777790Z",
     "iopub.status.idle": "2022-05-13T15:25:15.809022Z",
     "shell.execute_reply": "2022-05-13T15:25:15.808024Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [53]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m N_image_i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[1;32m      3\u001b[0m N_image_j \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[0;32m----> 4\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39msubplots(N_image_i, N_image_j, figsize\u001b[38;5;241m=\u001b[39m(fig_width\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1.3\u001b[39m, fig_width))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i_image, idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data_artifact\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlikelihood\u001b[39m\u001b[38;5;124m'\u001b[39m], ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mhead(N_image_i\u001b[38;5;241m*\u001b[39mN_image_j)\u001b[38;5;241m.\u001b[39mindex):\n\u001b[1;32m      6\u001b[0m     ax \u001b[38;5;241m=\u001b[39m axs[i_image\u001b[38;5;241m%\u001b[39mN_image_i][i_image\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mN_image_i]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "N_image_i = 8\n",
    "N_image_j = 8\n",
    "fig, axs = plt.subplots(N_image_i, N_image_j, figsize=(fig_width*1.3, fig_width))\n",
    "for i_image, idx in enumerate(data_artifact.sort_values(by=['likelihood'], ascending=True).head(N_image_i*N_image_j).index):\n",
    "    ax = axs[i_image%N_image_i][i_image//N_image_i]\n",
    "    img_address = image_datasets['artifact']['test'].imgs[data_artifact.loc[idx]['i_image']][0]\n",
    "    ax.imshow(imageio.imread(img_address, pilmode=\"L\"), cmap='gray')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    color = 'g' if data_artifact.loc[idx]['top_1'] == data_artifact.loc[idx]['goal'] else 'r'\n",
    "    ax.set_xlabel(data_artifact.loc[idx]['top_1'] + ' | ' + data_artifact.loc[idx]['model'], color=color)\n",
    "    likelihood = data_artifact.loc[idx]['likelihood']\n",
    "    ax.set_ylabel(f'P ={likelihood:2.3f}%', color=color)\n",
    "fig.set_facecolor(color='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:15.811851Z",
     "iopub.status.busy": "2022-05-13T15:25:15.811636Z",
     "iopub.status.idle": "2022-05-13T15:25:15.838363Z",
     "shell.execute_reply": "2022-05-13T15:25:15.837440Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [54]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, precision_score, f1_score\n\u001b[0;32m----> 2\u001b[0m df_acc \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame({model_name: {task: f1_score(data_artifact[(data_artifact[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mmodel_name) \u001b[38;5;241m&\u001b[39m (data_artifact[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mtask)][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_1\u001b[39m\u001b[38;5;124m\"\u001b[39m], \n\u001b[1;32m      3\u001b[0m                                                                data_artifact[(data_artifact[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mmodel_name) \u001b[38;5;241m&\u001b[39m (data_artifact[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mtask)][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoal\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      4\u001b[0m                                                   average \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmicro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m                                     \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m args\u001b[38;5;241m.\u001b[39mtasks} \n\u001b[1;32m      6\u001b[0m                        \u001b[38;5;28;01mfor\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m model_artifact})\n\u001b[1;32m      8\u001b[0m ax \u001b[38;5;241m=\u001b[39m df_acc\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mplot\u001b[38;5;241m.\u001b[39mbar(rot\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(fig_width, fig_width\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m4\u001b[39m), fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[1;32m      9\u001b[0m test_ \u001b[38;5;241m=\u001b[39m df_acc\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
    "df_acc = pd.DataFrame({model_name: {task: f1_score(data_artifact[(data_artifact['model']==model_name) & (data_artifact['task']==task)][\"top_1\"], \n",
    "                                                               data_artifact[(data_artifact['model']==model_name) & (data_artifact['task']==task)][\"goal\"],\n",
    "                                                  average = 'micro')\n",
    "                                    for task in args.tasks} \n",
    "                       for model_name in model_artifact})\n",
    "\n",
    "ax = df_acc.T.plot.bar(rot=20, figsize=(fig_width, fig_width//4), fontsize=20)\n",
    "test_ = df_acc\n",
    "ax.set_ylim(0, 1)\n",
    "ax.hlines(xmin=-.5, xmax=len(models_vgg)-.5, y=1/2, ls='--', ec='k', label='chance level')\n",
    "# https://matplotlib.org/stable/gallery/lines_bars_and_markers/bar_label_demo.html\n",
    "for container in ax.containers: ax.bar_label(container, padding=-50, color='black', fontsize=14, fmt='%.3f', rotation=60)\n",
    "plt.legend(bbox_to_anchor=(1.2, .35), loc='lower right', fontsize=18)\n",
    "ax.set_title(f'Animal vs Artifact images f1 score for re-trained models', size=22)\n",
    "ax.set_ylabel('Accuracy', size=20)\n",
    "ax.set_xlabel('Model', size=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computation time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:15.841771Z",
     "iopub.status.busy": "2022-05-13T15:25:15.841172Z",
     "iopub.status.idle": "2022-05-13T15:25:15.869679Z",
     "shell.execute_reply": "2022-05-13T15:25:15.869109Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [55]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;28mlen\u001b[39m(models_vgg), \u001b[38;5;241m1\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(fig_width, fig_width\u001b[38;5;241m*\u001b[39mphi\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m color, df_, label, legend \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m'\u001b[39m], [df_gray, df], [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblack\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolor\u001b[39m\u001b[38;5;124m'\u001b[39m], [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGrayscale\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRegular\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ax, model_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(axs, models_vgg):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "fig, axs = plt.subplots(len(models_vgg), 1, figsize=(fig_width, fig_width*phi/2))\n",
    "for color, df_, label, legend in zip(['gray', 'red'], [df_gray, df], ['black', 'color'], ['Grayscale', 'Regular']):\n",
    "    for ax, model_name in zip(axs, models_vgg):\n",
    "        ax.set_ylabel('Frequency', fontsize=20) \n",
    "        df_[df_['model']==model_name]['time'].plot.hist(bins=150, lw=1, label=str(legend+ ' ' + model_name), ax=ax, color=color, density=True)\n",
    "        ax.legend(loc='upper right', fontsize=20)\n",
    "        ax.set_xlim(df_gray['time'].quantile(.01), df_gray['time'].quantile(.99))\n",
    "        ax.legend(bbox_to_anchor=(1.18, .35), loc='lower right')\n",
    "axs[-1].set_xlabel('Processing time (s)', size=18)\n",
    "axs[0].set_title('Processed on : ' + args.HOST + '_' + str(df['device_type'][0]), size = 20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:15.873578Z",
     "iopub.status.busy": "2022-05-13T15:25:15.873230Z",
     "iopub.status.idle": "2022-05-13T15:25:15.907653Z",
     "shell.execute_reply": "2022-05-13T15:25:15.907192Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [56]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, precision_score, f1_score\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m \u001b[43margs\u001b[49m\u001b[38;5;241m.\u001b[39mtasks:\n\u001b[1;32m      3\u001b[0m     df_acc \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({model_name: {label: f1_score(df_[(df_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mmodel_name) \u001b[38;5;241m&\u001b[39m (df_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mtask)][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_1\u001b[39m\u001b[38;5;124m\"\u001b[39m], \n\u001b[1;32m      4\u001b[0m                                                                    df_[(df_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mmodel_name) \u001b[38;5;241m&\u001b[39m (df_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mtask)][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoal\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      5\u001b[0m                                                        average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmicro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m                                         \u001b[38;5;28;01mfor\u001b[39;00m label, df_ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moriginal\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m'\u001b[39m], [df, df_gray])} \n\u001b[1;32m      7\u001b[0m                            \u001b[38;5;28;01mfor\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m models_vgg})\n\u001b[1;32m      9\u001b[0m     ax \u001b[38;5;241m=\u001b[39m df_acc\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mplot\u001b[38;5;241m.\u001b[39mbar(rot\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(fig_width, fig_width\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m4\u001b[39m), fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m18\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
    "for task in args.tasks:\n",
    "    df_acc = pd.DataFrame({model_name: {label: f1_score(df_[(df_['model']==model_name) & (df_['task']==task)][\"top_1\"], \n",
    "                                                                   df_[(df_['model']==model_name) & (df_['task']==task)][\"goal\"],\n",
    "                                                       average='micro')\n",
    "                                        for label, df_ in zip(['original', 'gray'], [df, df_gray])} \n",
    "                           for model_name in models_vgg})\n",
    "\n",
    "    ax = df_acc.T.plot.bar(rot=30, figsize=(fig_width, fig_width//4), fontsize=18)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.hlines(xmin=-.5, xmax=len(models_vgg)-.5, y=1/2, ls='--', ec='k', label='chance level')\n",
    "    # https://matplotlib.org/stable/gallery/lines_bars_and_markers/bar_label_demo.html\n",
    "    for container in ax.containers: ax.bar_label(container, padding=-50, color='black', fontsize=14, fmt='%.3f', rotation=90)\n",
    "    plt.legend(bbox_to_anchor=(1.16, .35), loc='lower right', fontsize=16)\n",
    "    ax.grid(which='both', axis='y')\n",
    "    for side in ['top', 'right'] :ax.spines[side].set_visible(False)\n",
    "    ax.set_title(f'Experiment 3 - color vs gray images, task: {task}', size=20)\n",
    "    ax.set_ylabel('F1 Score', size=18)\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "\n",
    "We tested the networks on the ImageNet dataset with a grayscale filter applied on the input. The networks keeps a good mean accuracy on the grayscale dataset (about 94%). Note that the Vgg Gray networks achieves the task with a gray scale applied with a sightly better mean accuracy ([experiment 4](#exp4)) but not on the regular 'test' dataset ([experiment 1](#exp1))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id=\"exp5\"></a>\n",
    "## Experiment 5: Image processing and recognition on rotated images :\n",
    "\n",
    "In addition we tested all networks on our IMAGENET dataset while rotating the image around the center by -180° to +180°."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:15.913470Z",
     "iopub.status.busy": "2022-05-13T15:25:15.913189Z",
     "iopub.status.idle": "2022-05-13T15:25:15.917155Z",
     "shell.execute_reply": "2022-05-13T15:25:15.916502Z"
    }
   },
   "outputs": [],
   "source": [
    "scriptname = 'UltraFastCat/experiment_rotate.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:15.920917Z",
     "iopub.status.busy": "2022-05-13T15:25:15.920680Z",
     "iopub.status.idle": "2022-05-13T15:25:15.925899Z",
     "shell.execute_reply": "2022-05-13T15:25:15.925347Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting UltraFastCat/experiment_rotate.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {scriptname}\n",
    "\n",
    "#import model's script and set the output file\n",
    "from experiment_train import *\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "angles = np.arange(-180, 181, 1)\n",
    "angle = 0\n",
    "\n",
    "datetag = '2022-02-11'\n",
    "filename = f'results/{datetag}_results_rotate_{args.HOST}.json'\n",
    "print(f'{filename=}')\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    if os.path.isfile(filename):\n",
    "        df_angle = pd.read_json(filename)\n",
    "    else:\n",
    "        i_trial = 0\n",
    "        df_angle = pd.DataFrame([], columns=['model', 'model_task', 'task', 'goal', 'likelihood', 'fps', 'time', 'i_image', 'filename', 'top_1', 'angle', 'device_type'])   \n",
    "        # image preprocessing\n",
    "        for task in args.tasks:\n",
    "            print(task)\n",
    "            #for angle in angles :\n",
    "            print(angle)\n",
    "            for i_image, (data, label) in enumerate(dataloaders[task]['test']):\n",
    "                data = transforms.functional.rotate(data, angle=float(angle), expand = True)\n",
    "                data, label, = data.to(device), label.to(device)\n",
    "                for model_name in models_vgg:\n",
    "                    model = models_vgg[model_name].to(device)\n",
    "                    with torch.no_grad():\n",
    "                        goal = 'target' if 'target' in image_datasets[task]['test'].imgs[i_image][0] else 'distractor'\n",
    "                        model_task = 'animal' if 'animal' in model_name else 'artifact'\n",
    "                        tic = time.time()\n",
    "                        out = model(data).squeeze(0)\n",
    "                        if model_name == 'vgg_16':\n",
    "                            temp_, likelihood = 0, 0\n",
    "                            model_task = 'Imagenet_challenge'\n",
    "                            percentage = torch.nn.functional.softmax(out, dim=0) * 100\n",
    "                            for idx in np.arange(0,1000,1):\n",
    "                                if idx in match[task]:\n",
    "                                    likelihood += math.exp(percentage[idx].item())\n",
    "                                else:\n",
    "                                    temp_ += math.exp(percentage[idx].item())  \n",
    "                            likelihood = likelihood/temp_\n",
    "                        else:\n",
    "                            likelihood = float((torch.sigmoid(out) * 100).detach().cpu().numpy()[0])\n",
    "                        top_1 = 'target' if likelihood>50 else 'distractor'\n",
    "                        elapsed_time = time.time() - tic \n",
    "                    df_angle.loc[i_trial] = {'model':model_name,'model_task':model_task, 'task':task, 'top_1':top_1, 'goal':goal, 'likelihood':likelihood, 'time':elapsed_time, 'fps': 1/elapsed_time,\n",
    "                                           'i_image':i_image, 'filename':image_datasets[task]['test'].imgs[i_image][0], 'device_type':device.type, 'angle':angle}\n",
    "                    #print(f'The {model_name} model categorize {model_task} with {likelihood:.3f} % likelihood ({top_1}) in {elapsed_time:.3f} seconds, groundtrue : {task}, {goal}')\n",
    "                    i_trial += 1\n",
    "\n",
    "        df_angle.to_json(filename)\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:15.928329Z",
     "iopub.status.busy": "2022-05-13T15:25:15.928057Z",
     "iopub.status.idle": "2022-05-13T15:25:16.446905Z",
     "shell.execute_reply": "2022-05-13T15:25:16.446463Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating file results/2022-05-13_config_args.json\n",
      "On date 2022-05-13 , Running benchmark on host babbage  with device cuda\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - '/home/laurent/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/corpus/util.py:84\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 84\u001b[0m     root \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mzip_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet.zip/wordnet/\u001b[0m\n\n  Searched in:\n    - '/home/laurent/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/metagit/JNJER/2022-03_UltraFastCat/UltraFastCat/experiment_rotate.py:3\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#import model's script and set the output file\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexperiment_train\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageFile\n\u001b[1;32m      5\u001b[0m ImageFile\u001b[38;5;241m.\u001b[39mLOAD_TRUNCATED_IMAGES \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/metagit/JNJER/2022-03_UltraFastCat/UltraFastCat/experiment_train.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageFile\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n",
      "File \u001b[0;32m~/metagit/JNJER/2022-03_UltraFastCat/src/model.py:2\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnnf\u001b[39;00m\n",
      "File \u001b[0;32m~/metagit/JNJER/2022-03_UltraFastCat/src/init.py:116\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    114\u001b[0m reverse_id_labels \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i_img, img_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(Imagenet_urls_ILSVRC_2016):\n\u001b[0;32m--> 116\u001b[0m     syn_\u001b[38;5;241m=\u001b[39m \u001b[43mwn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msynset_from_pos_and_offset\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mint\u001b[39m(img_id\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[1;32m    117\u001b[0m     reverse_id_labels[img_id] \u001b[38;5;241m=\u001b[39m syn_\u001b[38;5;241m.\u001b[39mlemmas()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mname()\n\u001b[1;32m    118\u001b[0m     labels\u001b[38;5;241m.\u001b[39mappend(syn_\u001b[38;5;241m.\u001b[39mlemmas()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mname())\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/corpus/util.py:121\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLazyCorpusLoader object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# This looks circular, but its not, since __load() changes our\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# __class__ to something new:\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/corpus/util.py:86\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m             root \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubdir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mzip_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n\u001b[0;32m---> 86\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Load the corpus.\u001b[39;00m\n\u001b[1;32m     89\u001b[0m corpus \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__reader_cls(root, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__kwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/corpus/util.py:81\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m         root \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[1;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - '/home/laurent/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IPython CPU timings (estimated):\n",
      "  User   :       0.42 s.\n",
      "  System :       0.10 s.\n",
      "Wall time:       0.52 s.\n"
     ]
    }
   ],
   "source": [
    "%run -int {scriptname}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:16.453258Z",
     "iopub.status.busy": "2022-05-13T15:25:16.452910Z",
     "iopub.status.idle": "2022-05-13T15:25:16.474233Z",
     "shell.execute_reply": "2022-05-13T15:25:16.473806Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [60]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#datetag = '2022-01-24'\u001b[39;00m\n\u001b[1;32m      3\u001b[0m model_artifact \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 4\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetag\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_results_rotate_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39mHOST\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      5\u001b[0m df_angle \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_json(filename)\n\u001b[1;32m      6\u001b[0m data_animal \u001b[38;5;241m=\u001b[39m df_angle\u001b[38;5;241m.\u001b[39mloc[df_angle[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_task\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124manimal\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "model_animal = []\n",
    "#datetag = '2022-01-24'\n",
    "model_artifact = []\n",
    "filename = f'results/{datetag}_results_rotate_{args.HOST}.json'\n",
    "df_angle = pd.read_json(filename)\n",
    "data_animal = df_angle.loc[df_angle['model_task'] == 'animal']\n",
    "data_artifact = df_angle.loc[df_angle['model_task'] == 'artifact']\n",
    "for model in models_vgg:\n",
    "    model_animal.append(model) if 'animal' in model else model_artifact.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Animal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image display "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the images with the highest likelihood of the networks :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:16.478427Z",
     "iopub.status.busy": "2022-05-13T15:25:16.478280Z",
     "iopub.status.idle": "2022-05-13T15:25:16.948369Z",
     "shell.execute_reply": "2022-05-13T15:25:16.947382Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [61]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m N_image_i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[1;32m      3\u001b[0m N_image_j \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[0;32m----> 4\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39msubplots(N_image_i, N_image_j, figsize\u001b[38;5;241m=\u001b[39m(fig_width\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1.3\u001b[39m, fig_width))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i_image, idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data_animal\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlikelihood\u001b[39m\u001b[38;5;124m'\u001b[39m], ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mhead(N_image_i\u001b[38;5;241m*\u001b[39mN_image_j)\u001b[38;5;241m.\u001b[39mindex):\n\u001b[1;32m      6\u001b[0m     ax \u001b[38;5;241m=\u001b[39m axs[i_image\u001b[38;5;241m%\u001b[39mN_image_i][i_image\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mN_image_i]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "N_image_i = 8\n",
    "N_image_j = 8\n",
    "fig, axs = plt.subplots(N_image_i, N_image_j, figsize=(fig_width*1.3, fig_width))\n",
    "for i_image, idx in enumerate(data_animal.sort_values(by=['likelihood'], ascending=False).head(N_image_i*N_image_j).index):\n",
    "    ax = axs[i_image%N_image_i][i_image//N_image_i]\n",
    "    img_address = image_datasets['animal']['test'].imgs[data_animal.loc[idx]['i_image']][0]\n",
    "    ax.imshow(imageio.imread(img_address))\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    color = 'g' if data_animal.loc[idx]['top_1'] == data_animal.loc[idx]['goal'] else 'r'\n",
    "    ax.set_xlabel(data_animal.loc[idx]['top_1'] + ' | ' + data_animal.loc[idx]['model'] + ' | ' + str(data_animal.loc[idx]['angle']), color=color)\n",
    "    likelihood = data_animal.loc[idx]['likelihood']\n",
    "    ax.set_ylabel(f'P ={likelihood:2.3f}%', color=color)\n",
    "fig.set_facecolor(color='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the images with the lowest likelihood of the networks :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:16.951218Z",
     "iopub.status.busy": "2022-05-13T15:25:16.951062Z",
     "iopub.status.idle": "2022-05-13T15:25:16.982973Z",
     "shell.execute_reply": "2022-05-13T15:25:16.982387Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [62]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m N_image_i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[1;32m      3\u001b[0m N_image_j \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[0;32m----> 4\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39msubplots(N_image_i, N_image_j, figsize\u001b[38;5;241m=\u001b[39m(fig_width\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1.3\u001b[39m, fig_width))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i_image, idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data_animal\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlikelihood\u001b[39m\u001b[38;5;124m'\u001b[39m], ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mhead(N_image_i\u001b[38;5;241m*\u001b[39mN_image_j)\u001b[38;5;241m.\u001b[39mindex):\n\u001b[1;32m      6\u001b[0m     ax \u001b[38;5;241m=\u001b[39m axs[i_image\u001b[38;5;241m%\u001b[39mN_image_i][i_image\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mN_image_i]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "N_image_i = 8\n",
    "N_image_j = 8\n",
    "fig, axs = plt.subplots(N_image_i, N_image_j, figsize=(fig_width*1.3, fig_width))\n",
    "for i_image, idx in enumerate(data_animal.sort_values(by=['likelihood'], ascending=True).head(N_image_i*N_image_j).index):\n",
    "    ax = axs[i_image%N_image_i][i_image//N_image_i]\n",
    "    img_address = image_datasets['animal']['test'].imgs[data_animal.loc[idx]['i_image']][0]\n",
    "    ax.imshow(imageio.imread(img_address))\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    color = 'g' if data_animal.loc[idx]['top_1'] == data_animal.loc[idx]['goal'] else 'r'\n",
    "    ax.set_xlabel(data_animal.loc[idx]['top_1'] + ' | ' + data_animal.loc[idx]['model'] + ' | ' + str(data_animal.loc[idx]['angle']), color=color)\n",
    "    likelihood = data_animal.loc[idx]['likelihood']\n",
    "    ax.set_ylabel(f'P ={likelihood:2.3f}%', color=color) \n",
    "fig.set_facecolor(color='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:16.986008Z",
     "iopub.status.busy": "2022-05-13T15:25:16.985843Z",
     "iopub.status.idle": "2022-05-13T15:25:17.016359Z",
     "shell.execute_reply": "2022-05-13T15:25:17.015534Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_angle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [63]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m animal_acc \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      2\u001b[0m artifact_acc \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 3\u001b[0m animal \u001b[38;5;241m=\u001b[39m \u001b[43mdf_angle\u001b[49m\u001b[38;5;241m.\u001b[39mloc[df_angle[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124manimal\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m artifact \u001b[38;5;241m=\u001b[39m df_angle\u001b[38;5;241m.\u001b[39mloc[df_angle[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124martifact\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m models_vgg:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_angle' is not defined"
     ]
    }
   ],
   "source": [
    "animal_acc = []\n",
    "artifact_acc = []\n",
    "animal = df_angle.loc[df_angle['task'] == 'animal']\n",
    "artifact = df_angle.loc[df_angle['task'] == 'artifact']\n",
    "for model_name in models_vgg:\n",
    "    animal_acc.append(accuracy_score(animal[animal['model']==model_name][\"top_1\"], animal[animal['model']==model_name][\"goal\"]))\n",
    "    artifact_acc.append(accuracy_score(artifact[artifact['model']==model_name][\"top_1\"], artifact[artifact['model']==model_name][\"goal\"]))\n",
    "\n",
    "df_angle_test = pd.DataFrame({\"accuracy animal\": animal_acc, \"accuracy artifact\": artifact_acc}, index = models_vgg)\n",
    "ax = df_angle_test.plot.bar(rot=60, figsize=(fig_width, fig_width//4), fontsize=18)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.hlines(xmin=-.5, xmax=len(models_vgg)-.5, y=1/2, ls='--', ec='k', label='chance level')\n",
    "# https://matplotlib.org/stable/gallery/lines_bars_and_markers/bar_label_demo.html\n",
    "for container in ax.containers: ax.bar_label(container, padding=-50, color='black', fontsize=18, fmt='%.3f', rotation=60, label_type = 'edge')\n",
    "plt.legend(bbox_to_anchor=(1.2, .35), loc='lower right', fontsize=15)\n",
    "ax.grid(which='both', axis='y')\n",
    "for side in ['top', 'right'] :ax.spines[side].set_visible(False)\n",
    "ax.set_title(f'Experiment 1 - Accuracy Animal vs Artifact', size=20)\n",
    "ax.set_xlabel('Model', size=20);\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image display :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the images with the highest likelihood of the networks :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:17.019780Z",
     "iopub.status.busy": "2022-05-13T15:25:17.019414Z",
     "iopub.status.idle": "2022-05-13T15:25:17.048619Z",
     "shell.execute_reply": "2022-05-13T15:25:17.048129Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [64]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m N_image_i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[1;32m      3\u001b[0m N_image_j \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[0;32m----> 4\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39msubplots(N_image_i, N_image_j, figsize\u001b[38;5;241m=\u001b[39m(fig_width\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1.3\u001b[39m, fig_width))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i_image, idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data_artifact\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlikelihood\u001b[39m\u001b[38;5;124m'\u001b[39m], ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mhead(N_image_i\u001b[38;5;241m*\u001b[39mN_image_j)\u001b[38;5;241m.\u001b[39mindex):\n\u001b[1;32m      6\u001b[0m     ax \u001b[38;5;241m=\u001b[39m axs[i_image\u001b[38;5;241m%\u001b[39mN_image_i][i_image\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mN_image_i]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "N_image_i = 8\n",
    "N_image_j = 8\n",
    "fig, axs = plt.subplots(N_image_i, N_image_j, figsize=(fig_width*1.3, fig_width))\n",
    "for i_image, idx in enumerate(data_artifact.sort_values(by=['likelihood'], ascending=False).head(N_image_i*N_image_j).index):\n",
    "    ax = axs[i_image%N_image_i][i_image//N_image_i]\n",
    "    img_address = image_datasets['artifact']['test'].imgs[data_artifact.loc[idx]['i_image']][0]\n",
    "    ax.imshow(imageio.imread(img_address))\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    color = 'g' if data_artifact.loc[idx]['top_1'] == data_artifact.loc[idx]['goal'] else 'r'\n",
    "    ax.set_xlabel(data_artifact.loc[idx]['top_1'] + ' | ' + data_artifact.loc[idx]['model'] + ' | ' + str(data_artifact.loc[idx]['angle']), color=color)\n",
    "    likelihood = data_artifact.loc[idx]['likelihood']\n",
    "    ax.set_ylabel(f'P ={likelihood:2.3f}%', color=color)\n",
    "fig.set_facecolor(color='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the images with the lowest likelihood of the networks :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:17.051831Z",
     "iopub.status.busy": "2022-05-13T15:25:17.051683Z",
     "iopub.status.idle": "2022-05-13T15:25:17.077426Z",
     "shell.execute_reply": "2022-05-13T15:25:17.076573Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [65]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m N_image_i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[1;32m      3\u001b[0m N_image_j \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[0;32m----> 4\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39msubplots(N_image_i, N_image_j, figsize\u001b[38;5;241m=\u001b[39m(fig_width\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1.3\u001b[39m, fig_width))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i_image, idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data_artifact\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlikelihood\u001b[39m\u001b[38;5;124m'\u001b[39m], ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mhead(N_image_i\u001b[38;5;241m*\u001b[39mN_image_j)\u001b[38;5;241m.\u001b[39mindex):\n\u001b[1;32m      6\u001b[0m     ax \u001b[38;5;241m=\u001b[39m axs[i_image\u001b[38;5;241m%\u001b[39mN_image_i][i_image\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mN_image_i]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "N_image_i = 8\n",
    "N_image_j = 8\n",
    "fig, axs = plt.subplots(N_image_i, N_image_j, figsize=(fig_width*1.3, fig_width))\n",
    "for i_image, idx in enumerate(data_artifact.sort_values(by=['likelihood'], ascending=True).head(N_image_i*N_image_j).index):\n",
    "    ax = axs[i_image%N_image_i][i_image//N_image_i]\n",
    "    img_address = image_datasets['artifact']['test'].imgs[data_artifact.loc[idx]['i_image']][0]\n",
    "    ax.imshow(imageio.imread(img_address))\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    color = 'g' if data_artifact.loc[idx]['top_1'] == data_artifact.loc[idx]['goal'] else 'r'\n",
    "    ax.set_xlabel(data_artifact.loc[idx]['top_1'] + ' | ' + data_artifact.loc[idx]['model'] + ' | ' + str(data_artifact.loc[idx]['angle']), color=color)\n",
    "    likelihood = data_artifact.loc[idx]['likelihood']\n",
    "    ax.set_ylabel(f'P ={likelihood:2.3f}%', color=color)\n",
    "fig.set_facecolor(color='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:17.080821Z",
     "iopub.status.busy": "2022-05-13T15:25:17.080236Z",
     "iopub.status.idle": "2022-05-13T15:25:17.106295Z",
     "shell.execute_reply": "2022-05-13T15:25:17.105728Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_angle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [66]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m animal_acc \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      2\u001b[0m artifact_acc \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 3\u001b[0m animal \u001b[38;5;241m=\u001b[39m \u001b[43mdf_angle\u001b[49m\u001b[38;5;241m.\u001b[39mloc[df_angle[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124manimal\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m artifact \u001b[38;5;241m=\u001b[39m df_angle\u001b[38;5;241m.\u001b[39mloc[df_angle[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124martifact\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m models_vgg:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_angle' is not defined"
     ]
    }
   ],
   "source": [
    "animal_acc = []\n",
    "artifact_acc = []\n",
    "animal = df_angle.loc[df_angle['task'] == 'animal']\n",
    "artifact = df_angle.loc[df_angle['task'] == 'artifact']\n",
    "for model_name in models_vgg:\n",
    "    animal_acc.append(accuracy_score(animal[animal['model']==model_name][\"top_1\"], animal[animal['model']==model_name][\"goal\"]))\n",
    "    artifact_acc.append(accuracy_score(artifact[artifact['model']==model_name][\"top_1\"], artifact[artifact['model']==model_name][\"goal\"]))\n",
    "\n",
    "df_angle_test = pd.DataFrame({\"accuracy animal\": animal_acc, \"accuracy artifact\": artifact_acc}, index = models_vgg)\n",
    "ax = df_angle_test.plot.bar(rot=60, figsize=(fig_width, fig_width//4), fontsize=18)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.hlines(xmin=-.5, xmax=len(models_vgg)-.5, y=1/2, ls='--', ec='k', label='chance level')\n",
    "# https://matplotlib.org/stable/gallery/lines_bars_and_markers/bar_label_demo.html\n",
    "for container in ax.containers: ax.bar_label(container, padding=-50, color='black', fontsize=18, fmt='%.3f', rotation=60, label_type = 'edge')\n",
    "plt.legend(bbox_to_anchor=(1.2, .35), loc='lower right', fontsize=15)\n",
    "ax.grid(which='both', axis='y')\n",
    "for side in ['top', 'right'] :ax.spines[side].set_visible(False)\n",
    "ax.set_title(f'Experiment 1 - Accuracy Animal vs Artifact', size=20)\n",
    "ax.set_xlabel('Model', size=20);\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:17.109476Z",
     "iopub.status.busy": "2022-05-13T15:25:17.109328Z",
     "iopub.status.idle": "2022-05-13T15:25:17.123630Z",
     "shell.execute_reply": "2022-05-13T15:25:17.122837Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [67]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m datetag \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2022-02-13\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m model_artifact \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 4\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetag\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_results_rotate_2_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39mHOST\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      5\u001b[0m df_sheat \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_json(filename)\n\u001b[1;32m      6\u001b[0m df_sheat\n",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "model_animal = []\n",
    "datetag = '2022-02-13'\n",
    "model_artifact = []\n",
    "filename = f'results/{datetag}_results_rotate_2_{args.HOST}.json'\n",
    "df_sheat = pd.read_json(filename)\n",
    "df_sheat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:17.126578Z",
     "iopub.status.busy": "2022-05-13T15:25:17.126410Z",
     "iopub.status.idle": "2022-05-13T15:25:17.166833Z",
     "shell.execute_reply": "2022-05-13T15:25:17.166355Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [68]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, precision_score, f1_score\n\u001b[0;32m----> 2\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m      3\u001b[0m cmap \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mcm\u001b[38;5;241m.\u001b[39mget_cmap(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mviridis\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m color_dict \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries({k:cmap(i\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(df_angle[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique())) \u001b[38;5;28;01mfor\u001b[39;00m i,k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(df_angle[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique())})\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15, 5))\n",
    "cmap = plt.cm.get_cmap('viridis')\n",
    "color_dict = pd.Series({k:cmap(i/len(df_angle['model'].unique())) for i,k in enumerate(df_angle['model'].unique())})\n",
    "df_mean = pd.DataFrame([], columns=['mean_prediction', 'model', 'var'])\n",
    "angles = np.arange(-180, 181, 1)\n",
    "import statistics\n",
    "for model_name in df_angle['model'].unique():\n",
    "    df_mean = pd.DataFrame([], columns=['mean_prediction', 'model', 'var'])\n",
    "    for j,angle in enumerate(angles):\n",
    "        if angle < -35:\n",
    "            accuracy = f1_score(df_angle[(df_angle['model']==model_name)  & (df_angle['task']=='animal') & (df_angle['angle']==angle)][\"top_1\"], \n",
    "                                                               df_angle[(df_angle['model']==model_name) & (df_angle['task']=='animal') & (df_angle['angle']==angle)][\"goal\"],\n",
    "                                                                average='micro')\n",
    "            df_mean.loc[j] = {'model':model_name, 'mean_prediction':accuracy, 'var':angle} \n",
    "        else: \n",
    "            df_mean.loc[j] = {'model':model_name, 'mean_prediction':float(df_sheat[(df_sheat['model']==model_name) & (df_sheat['var']==angle)][\"mean_prediction\"]),\n",
    "                                'var':angle}\n",
    "    #dev = statistics.pstdev(df_mean[\"mean_prediction\"])\n",
    "    #mean = statistics.mean(df_mean[\"mean_prediction\"])\n",
    "    #print(model_name, 'dev: ', str(dev*100))\n",
    "    #print(model_name, 'mean: ', str(mean*100))\n",
    "    df_mean[(df_mean['model']==model_name)].plot.scatter(x=\"var\", y=\"mean_prediction\", c=[color_dict[model_name],],\n",
    "                                                        alpha=.5, marker='o', s=40, lw=0, label=model_name, ax=ax)\n",
    "    ax.legend(loc='center right', fontsize = 12)\n",
    "    ax.tick_params(axis='x', labelsize=14)\n",
    "    ax.tick_params(axis='y', labelsize=14)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_xlim(-185, 185)\n",
    "    #plt.set_cmap('Blues')\n",
    "    ax.set_xticks([-180, -90, 0, 90, 180])\n",
    "    ax.set_ylabel('Accuracy', size= 25, fontweight='bold')\n",
    "    ax.set_xlabel('Rotation (°)', size= 25, fontweight='bold')\n",
    "    plt.legend(bbox_to_anchor=(1.2, .5), loc='center', fontsize=20)\n",
    "    plt.xticks(fontsize=20,  fontweight='bold')\n",
    "    plt.yticks(fontsize=20,  fontweight='bold');\n",
    "    #plt.savefig('IJCNN_fig.5.pdf')\n",
    "    plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Todo : table mean + std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computation time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:17.171197Z",
     "iopub.status.busy": "2022-05-13T15:25:17.170972Z",
     "iopub.status.idle": "2022-05-13T15:25:17.197602Z",
     "shell.execute_reply": "2022-05-13T15:25:17.197158Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [69]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;28mlen\u001b[39m(models_vgg), \u001b[38;5;241m1\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(fig_width, fig_width\u001b[38;5;241m*\u001b[39mphi\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m), sharex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, sharey\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m cmap \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mcm\u001b[38;5;241m.\u001b[39mget_cmap(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minferno\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m color_dict \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries({k:cmap(i\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(df_angle[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique())) \u001b[38;5;28;01mfor\u001b[39;00m i,k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(df_angle[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique())})\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "fig, axs = plt.subplots(len(models_vgg), 1, figsize=(fig_width, fig_width*phi/2), sharex=True, sharey=True)\n",
    "cmap = plt.cm.get_cmap('inferno')\n",
    "color_dict = pd.Series({k:cmap(i/len(df_angle['model'].unique())) for i,k in enumerate(df_angle['model'].unique())})\n",
    "for ax, color, model_name in zip(axs, color_dict, models_vgg):\n",
    "    df_angle[df_angle['model']==model_name]['time'].plot.hist(bins=50, lw=1, label=model_name,ax=ax, color=[color_dict[model_name],], density=True)\n",
    "    ax.set_xlim(df_angle['time'].quantile(.01), df_angle['time'].quantile(.99))\n",
    "  #  ax.set_ylim(0, 3500)\n",
    "    ax.legend(bbox_to_anchor=(1.21, .35), loc='lower right', fontsize=15)\n",
    "    ax.grid(which='both', axis='y')\n",
    "    ax.set_xlabel('Processing time (s): ' + model_name, size=22)\n",
    "    ax.set_ylabel('')\n",
    "axs[0].set_title('Distribution of the Processing time (s). Processed on : ' + args.HOST + '_' + str(df_angle['device_type'][0]), size = 20)\n",
    "axs[len(models_vgg)//2].set_ylabel('Frequency', fontsize=22);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "\n",
    "The image size or a gray filter during training does not seem to impact the robustness to rotation as all three networks follow the same accuracy level for the categorization. Furthermore,\n",
    "these three networks maintain a good accuracy during the process (VGG GEN 90.272 +/- 2.05, VGG GRAY 89.464 +/-2.72, VGG SCALE 89.222: +/- 2.722) (see Figure 5). As the networks seems robust to relection [experiment 2](#exp2), to the resolution [experiment 3](#exp3) (in a short range centered in the training resolution) and to grayscale [experiment 4](#exp4), the robustness of the categorization to different image transformations by the models are similar to that reported in psychophysics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 6, a comparison between performances *in vivo* and *in sillico* : Test on Serre 2007 dataset\n",
    "\n",
    " As a control, we tested the networks on the dataset of [Serre & al](http://vision.stanford.edu/teaching/cs131_fall1415/lectures/Serre2007.pdf). This dataset contains a total of $600$ targets (images containing an animal) and $600$ distractors (images not containing an animal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:17.202979Z",
     "iopub.status.busy": "2022-05-13T15:25:17.202831Z",
     "iopub.status.idle": "2022-05-13T15:25:17.205553Z",
     "shell.execute_reply": "2022-05-13T15:25:17.205052Z"
    }
   },
   "outputs": [],
   "source": [
    "scriptname = 'UltraFastCat/experiment_serre.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:17.208154Z",
     "iopub.status.busy": "2022-05-13T15:25:17.207933Z",
     "iopub.status.idle": "2022-05-13T15:25:17.213220Z",
     "shell.execute_reply": "2022-05-13T15:25:17.212730Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting UltraFastCat/experiment_serre.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {scriptname}\n",
    "\n",
    "#import model's script and set the output file\n",
    "from experiment_train import *\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "#datetag = '2022-02-08'\n",
    "filename = f'results/{datetag}_results_serre_polar_{HOST}.json'\n",
    "print(f'{filename=}')\n",
    "serre = ['targets', 'distractors']\n",
    "paths['animal']['test'] = '/home/INT/jeremie.j/Serre_2007'\n",
    "\n",
    "# Output's set up\n",
    "def main():\n",
    "    if os.path.isfile(filename):\n",
    "        df_serre = pd.read_json(filename)\n",
    "    else:\n",
    "        df_serre = pd.DataFrame([], columns=['model', 'model_task', 'goal', 'likelihood', 'fps', 'time', 'i_image', 'filename', 'top_1', 'device_type']) \n",
    "        i_trial = 0\n",
    "        # image preprocessing\n",
    "        (dataset_sizes, dataloaders, image_datasets, data_transforms) = datasets_transforms(image_size=args.image_size, batch_size=1)\n",
    "        # Displays the input image of the model\n",
    "        for i_image, (data, label) in enumerate(dataloaders['animal']['test']):\n",
    "            data, label = data.to(device), label.to(device)\n",
    "            for model_name in models_vgg:\n",
    "                model = models_vgg[model_name].to(device)\n",
    "                with torch.no_grad():\n",
    "                    goal = 'target' if 'targets' in image_datasets['animal']['test'].imgs[i_image][0] else 'distractor'\n",
    "                    model_task = 'animal' if 'animal' in model_name else 'artifact'\n",
    "                    tic = time.time()\n",
    "                    out = model(data).squeeze(0)\n",
    "                    if model_name == 'vgg_16':\n",
    "                        temp_, likelihood = 0, 0\n",
    "                        model_task = 'Imagenet_challenge'\n",
    "                        percentage = torch.nn.functional.softmax(out, dim=0) * 100\n",
    "                        for idx in np.arange(0,1000,1):\n",
    "                            if idx in match['animal']:\n",
    "                                likelihood += math.exp(percentage[idx].item())\n",
    "                            else:\n",
    "                                temp_ += math.exp(percentage[idx].item())  \n",
    "                        likelihood = likelihood/temp_\n",
    "                    else:\n",
    "                        likelihood = float((torch.sigmoid(out) * 100).detach().cpu().numpy()[0])\n",
    "                    top_1 = 'target' if likelihood>50 and model_task == task else 'distractor'\n",
    "                    elapsed_time = time.time() - tic\n",
    "                df_serre.loc[i_trial] = {'model':model_name, 'model_task':model_task, 'likelihood':likelihood, 'time':elapsed_time, \n",
    "                                         'fps': 1/elapsed_time, 'goal': goal, 'i_image':i_image, 'top_1':top_1,\n",
    "                                         'filename':image_datasets['animal']['test'].imgs[i_image][0], 'device':device.type}\n",
    "                print(f'The {model_name} model categorize {model_task} with {likelihood:.3f} % likelihood ({top_1}) in {elapsed_time:.3f} seconds, groundtrue : animal, {goal}')\n",
    "                i_trial += 1\n",
    "    df_serre.to_json(filename)\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:17.215789Z",
     "iopub.status.busy": "2022-05-13T15:25:17.215593Z",
     "iopub.status.idle": "2022-05-13T15:25:17.731550Z",
     "shell.execute_reply": "2022-05-13T15:25:17.731094Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating file results/2022-05-13_config_args.json\n",
      "On date 2022-05-13 , Running benchmark on host babbage  with device cuda\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - '/home/laurent/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/corpus/util.py:84\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 84\u001b[0m     root \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mzip_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet.zip/wordnet/\u001b[0m\n\n  Searched in:\n    - '/home/laurent/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/metagit/JNJER/2022-03_UltraFastCat/UltraFastCat/experiment_serre.py:3\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#import model's script and set the output file\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexperiment_train\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageFile\n\u001b[1;32m      5\u001b[0m ImageFile\u001b[38;5;241m.\u001b[39mLOAD_TRUNCATED_IMAGES \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/metagit/JNJER/2022-03_UltraFastCat/UltraFastCat/experiment_train.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageFile\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n",
      "File \u001b[0;32m~/metagit/JNJER/2022-03_UltraFastCat/src/model.py:2\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnnf\u001b[39;00m\n",
      "File \u001b[0;32m~/metagit/JNJER/2022-03_UltraFastCat/src/init.py:116\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    114\u001b[0m reverse_id_labels \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i_img, img_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(Imagenet_urls_ILSVRC_2016):\n\u001b[0;32m--> 116\u001b[0m     syn_\u001b[38;5;241m=\u001b[39m \u001b[43mwn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msynset_from_pos_and_offset\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mint\u001b[39m(img_id\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[1;32m    117\u001b[0m     reverse_id_labels[img_id] \u001b[38;5;241m=\u001b[39m syn_\u001b[38;5;241m.\u001b[39mlemmas()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mname()\n\u001b[1;32m    118\u001b[0m     labels\u001b[38;5;241m.\u001b[39mappend(syn_\u001b[38;5;241m.\u001b[39mlemmas()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mname())\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/corpus/util.py:121\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLazyCorpusLoader object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# This looks circular, but its not, since __load() changes our\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# __class__ to something new:\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/corpus/util.py:86\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m             root \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubdir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mzip_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n\u001b[0;32m---> 86\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Load the corpus.\u001b[39;00m\n\u001b[1;32m     89\u001b[0m corpus \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__reader_cls(root, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__kwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/corpus/util.py:81\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m         root \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[1;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - '/home/laurent/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IPython CPU timings (estimated):\n",
      "  User   :       0.39 s.\n",
      "  System :       0.12 s.\n",
      "Wall time:       0.51 s.\n"
     ]
    }
   ],
   "source": [
    "%run -int {scriptname}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:17.736843Z",
     "iopub.status.busy": "2022-05-13T15:25:17.736690Z",
     "iopub.status.idle": "2022-05-13T15:25:17.751415Z",
     "shell.execute_reply": "2022-05-13T15:25:17.750632Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'HOST' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [73]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#datetag = '2022-02-08'\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetag\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_results_serre_polar_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mHOST\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m df_serre \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_json(filename)\n\u001b[1;32m      4\u001b[0m df_serre\n",
      "\u001b[0;31mNameError\u001b[0m: name 'HOST' is not defined"
     ]
    }
   ],
   "source": [
    "#datetag = '2022-02-08'\n",
    "filename = f'results/{datetag}_results_serre_polar_{HOST}.json'\n",
    "df_serre = pd.read_json(filename)\n",
    "df_serre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the images with the highest likelihood of the networks :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:17.754722Z",
     "iopub.status.busy": "2022-05-13T15:25:17.754430Z",
     "iopub.status.idle": "2022-05-13T15:25:17.782627Z",
     "shell.execute_reply": "2022-05-13T15:25:17.781781Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [74]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m N_image_i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[1;32m      3\u001b[0m N_image_j \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[0;32m----> 4\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39msubplots(N_image_i, N_image_j, figsize\u001b[38;5;241m=\u001b[39m(fig_width\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1.3\u001b[39m, fig_width))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i_image, idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(df_serre\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlikelihood\u001b[39m\u001b[38;5;124m'\u001b[39m], ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mhead(N_image_i\u001b[38;5;241m*\u001b[39mN_image_j)\u001b[38;5;241m.\u001b[39mindex):\n\u001b[1;32m      6\u001b[0m     ax \u001b[38;5;241m=\u001b[39m axs[i_image\u001b[38;5;241m%\u001b[39mN_image_i][i_image\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mN_image_i]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "N_image_i = 8\n",
    "N_image_j = 8\n",
    "fig, axs = plt.subplots(N_image_i, N_image_j, figsize=(fig_width*1.3, fig_width))\n",
    "for i_image, idx in enumerate(df_serre.sort_values(by=['likelihood'], ascending=False).head(N_image_i*N_image_j).index):\n",
    "    ax = axs[i_image%N_image_i][i_image//N_image_i]\n",
    "    img_address = image_datasets['animal']['test'].imgs[df_serre.loc[idx]['i_image']][0]\n",
    "    ax.imshow(imageio.imread(img_address))\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    color = 'g' if df_serre.loc[idx]['top_1'] == df_serre.loc[idx]['goal'] else 'r'\n",
    "    ax.set_xlabel(df_serre.loc[idx]['top_1'] + ' | ' + df_serre.loc[idx]['model'], color=color)\n",
    "    likelihood = df_serre.loc[idx]['likelihood']\n",
    "    ax.set_ylabel(f'P ={likelihood:2.3f}%', color=color)\n",
    "fig.set_facecolor(color='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the images with the lowest likelihood of the networks :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:17.785458Z",
     "iopub.status.busy": "2022-05-13T15:25:17.785152Z",
     "iopub.status.idle": "2022-05-13T15:25:17.813830Z",
     "shell.execute_reply": "2022-05-13T15:25:17.813366Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [75]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m N_image_i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[1;32m      3\u001b[0m N_image_j \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[0;32m----> 4\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39msubplots(N_image_i, N_image_j, figsize\u001b[38;5;241m=\u001b[39m(fig_width\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1.3\u001b[39m, fig_width))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i_image, idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(df_serre\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlikelihood\u001b[39m\u001b[38;5;124m'\u001b[39m], ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mhead(N_image_i\u001b[38;5;241m*\u001b[39mN_image_j)\u001b[38;5;241m.\u001b[39mindex):\n\u001b[1;32m      6\u001b[0m     ax \u001b[38;5;241m=\u001b[39m axs[i_image\u001b[38;5;241m%\u001b[39mN_image_i][i_image\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mN_image_i]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "N_image_i = 8\n",
    "N_image_j = 8\n",
    "fig, axs = plt.subplots(N_image_i, N_image_j, figsize=(fig_width*1.3, fig_width))\n",
    "for i_image, idx in enumerate(df_serre.sort_values(by=['likelihood'], ascending=True).head(N_image_i*N_image_j).index):\n",
    "    ax = axs[i_image%N_image_i][i_image//N_image_i]\n",
    "    img_address = image_datasets['animal']['test'].imgs[df_serre.loc[idx]['i_image']][0]\n",
    "    ax.imshow(imageio.imread(img_address))\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    color = 'g' if df_serre.loc[idx]['top_1'] == df_serre.loc[idx]['goal'] else 'r'\n",
    "    ax.set_xlabel(df_serre.loc[idx]['top_1'] + ' | ' + df_serre.loc[idx]['model'], color=color)\n",
    "    likelihood = df_serre.loc[idx]['likelihood']\n",
    "    ax.set_ylabel(f'P ={likelihood:2.3f}%', color=color)\n",
    "fig.set_facecolor(color='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:17.817678Z",
     "iopub.status.busy": "2022-05-13T15:25:17.817509Z",
     "iopub.status.idle": "2022-05-13T15:25:17.842996Z",
     "shell.execute_reply": "2022-05-13T15:25:17.842416Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [76]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, precision_score, f1_score\n\u001b[0;32m----> 2\u001b[0m df_acc \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m: [accuracy_score(df_serre[df_serre[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mmodel_name][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_1\u001b[39m\u001b[38;5;124m\"\u001b[39m], df_serre[df_serre[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mmodel_name][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoal\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m models_vgg]}, index\u001b[38;5;241m=\u001b[39mmodels_vgg)\n\u001b[1;32m      3\u001b[0m ax \u001b[38;5;241m=\u001b[39m df_acc\u001b[38;5;241m.\u001b[39mplot\u001b[38;5;241m.\u001b[39mbar(rot\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(fig_width, fig_width\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m4\u001b[39m), fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m18\u001b[39m)\n\u001b[1;32m      4\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_ylim(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
    "df_acc = pd.DataFrame({'accuracy': [accuracy_score(df_serre[df_serre['model']==model_name][\"top_1\"], df_serre[df_serre['model']==model_name][\"goal\"]) for model_name in models_vgg]}, index=models_vgg)\n",
    "ax = df_acc.plot.bar(rot=30, figsize=(fig_width, fig_width//4), fontsize=18)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.hlines(xmin=-.5, xmax=len(models_vgg)-.5, y=1/2, ls='--', ec='k', label='chance level')\n",
    "# https://matplotlib.org/stable/gallery/lines_bars_and_markers/bar_label_demo.html\n",
    "ax.bar_label(ax.containers[0], padding=-24, color='black', fontsize=14, fmt='%.3f')\n",
    "plt.legend(bbox_to_anchor=(1.1, .5), loc='lower right')\n",
    "ax.grid(which='both', axis='y')\n",
    "for side in ['top', 'right'] :ax.spines[side].set_visible(False)\n",
    "ax.set_title('Average accuracy top_1 : for each models - experiment 1', size=20)\n",
    "ax.set_xlabel('Model', size=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heuristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:17.847253Z",
     "iopub.status.busy": "2022-05-13T15:25:17.847051Z",
     "iopub.status.idle": "2022-05-13T15:25:17.879091Z",
     "shell.execute_reply": "2022-05-13T15:25:17.878518Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [77]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, precision_score, f1_score\n\u001b[0;32m----> 2\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m10\u001b[39m))\n\u001b[1;32m      3\u001b[0m df_mean \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([], columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mheuristic\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvar\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgoal\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      4\u001b[0m cmap \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mcm\u001b[38;5;241m.\u001b[39mget_cmap(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mviridis\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15, 10))\n",
    "df_mean = pd.DataFrame([], columns=['heuristic', 'var', 'goal'])\n",
    "cmap = plt.cm.get_cmap('viridis')\n",
    "color_dict = pd.Series({k:cmap(i/len(df_serre['goal'].unique())) for i,k in enumerate(df_serre['goal'].unique())})\n",
    "model_animal = []\n",
    "model_artifact = []\n",
    "data_animal = df_serre.loc[df_serre['model'] == 'vgg16_gen_animal']\n",
    "data_artifact = df_serre.loc[df_serre['model'] == 'vgg16_gen_artifact']\n",
    "for i_image in df_serre['i_image'].unique():\n",
    "    heuristic = 1 - (1 - float(data_animal[(data_animal['i_image']==i_image)][\"likelihood\"]/100)) * float(data_artifact[(data_artifact['i_image']==i_image)][\"likelihood\"]/100)\n",
    "    df_mean.loc[i_image] = {'heuristic':heuristic, 'var':i_image, 'goal':list(data_animal.goal)[i_image]}      \n",
    "for goal in df_serre['goal'].unique():\n",
    "    df_mean[(df_mean['goal']==goal)].plot.scatter(x=\"var\", y=\"heuristic\",  c=[color_dict[goal],],\n",
    "                                                         alpha=0.5, marker='o', lw=0, ax=ax, label=goal)\n",
    "ax.tick_params(axis='x', labelsize=14)\n",
    "ax.tick_params(axis='y', labelsize=14)\n",
    "ax.set_ylabel('Heuristic', size= 20)\n",
    "ax.set_xlabel('i image', size= 20)\n",
    "plt.legend(bbox_to_anchor=(1.1, .5), loc='center', fontsize=14,)\n",
    "ax.set_title('Heuristic : likelihood = 1 - (1 - likelihood_animal)  * likelihood_artifact', size = 20);\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel Density Estimation\n",
    "\n",
    "In statistics, kernel density estimation (KDE) is a non-parametric way to estimate the probability density function (PDF) of a random variable. This function uses Gaussian kernels and includes automatic bandwidth determination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:17.884656Z",
     "iopub.status.busy": "2022-05-13T15:25:17.884466Z",
     "iopub.status.idle": "2022-05-13T15:25:17.906837Z",
     "shell.execute_reply": "2022-05-13T15:25:17.906371Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [78]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m10\u001b[39m))\n\u001b[1;32m      2\u001b[0m data_animal \u001b[38;5;241m=\u001b[39m df_serre\u001b[38;5;241m.\u001b[39mloc[df_serre[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_task\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124manimal\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      3\u001b[0m data_artifact \u001b[38;5;241m=\u001b[39m df_serre\u001b[38;5;241m.\u001b[39mloc[df_serre[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_task\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124martifact\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(15, 10))\n",
    "data_animal = df_serre.loc[df_serre['model_task'] == 'animal']\n",
    "data_artifact = df_serre.loc[df_serre['model_task'] == 'artifact']\n",
    "df_test = pd.DataFrame({\"accuracy animal\": list(data_animal.likelihood), \"accuracy artifact\": list(data_artifact.likelihood), \"goal\": list(data_animal.goal)})\n",
    "sns.kdeplot(data=df_test, x=\"accuracy animal\", y=\"accuracy artifact\", hue=\"goal\", fill=True, ax=ax)\n",
    "ax.set_ylabel('Likelihood artifact', size= 20)\n",
    "ax.set_xlabel('Likelihood animal', size= 20)\n",
    "ax.set_ylim(0, 100)\n",
    "ax.set_xlim(0, 100)\n",
    "ax.set_title('Kernel Density Estimation (KDE)', size = 20);\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with physiologic data from Serre & al 2007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:17.911101Z",
     "iopub.status.busy": "2022-05-13T15:25:17.910953Z",
     "iopub.status.idle": "2022-05-13T15:25:17.938729Z",
     "shell.execute_reply": "2022-05-13T15:25:17.938281Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [79]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_serre_07 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/laurentperrinet/PerrinetBednar15/master/database/AnimalnessIndex.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\u001b[38;5;66;03m#, index_col=['A', 'B', 'C'])\u001b[39;00m\n\u001b[1;32m      3\u001b[0m likes_ \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m goals \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df_serre_07 = pd.read_csv('https://raw.githubusercontent.com/laurentperrinet/PerrinetBednar15/master/database/AnimalnessIndex.csv', header=None)#, index_col=['A', 'B', 'C'])\n",
    "\n",
    "likes_ = []\n",
    "goals = []\n",
    "top1_human = []\n",
    "top1_model = []\n",
    "data_vgg_gen = df_serre.loc[df_serre['model'] == 'vgg16_gen_animal']\n",
    "for i in range(len(df_serre_07)):\n",
    "    top_1_human = 'target' if df_serre_07.iloc[i, 1]>50 else 'distractor'\n",
    "    top_1_model = 'target' if df_serre_07.iloc[i, 2]>50 else 'distractor'\n",
    "    top1_human.append(top_1_human)\n",
    "    top1_model.append(top_1_model)\n",
    "    for j in range(len(data_vgg_gen)):\n",
    "        if df_serre_07.iloc[i, 0] in data_vgg_gen.iloc[j, 7] :\n",
    "            goals.append(data_vgg_gen.iloc[j, 2])\n",
    "            if data_vgg_gen.iloc[j, 2] == 'target':\n",
    "                likes_.append(round(data_vgg_gen.iloc[j, 3]))\n",
    "            else:\n",
    "                likes_.append(100-round(data_vgg_gen.iloc[j, 3]))\n",
    "                df_serre_07.iloc[i, 1] = 100 - df_serre_07.iloc[i, 1]\n",
    "                df_serre_07.iloc[i, 2] = 100 - df_serre_07.iloc[i, 2]\n",
    "\n",
    "df_serre_07.insert( 3, 'human', top1_human)\n",
    "df_serre_07.insert( 4, 'model', top1_model)\n",
    "df_serre_07.insert(5, 'Gen', likes_)\n",
    "df_serre_07.insert(6, 'goals', goals)\n",
    "df_serre_07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:17.942203Z",
     "iopub.status.busy": "2022-05-13T15:25:17.942056Z",
     "iopub.status.idle": "2022-05-13T15:25:17.966089Z",
     "shell.execute_reply": "2022-05-13T15:25:17.965642Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [80]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, precision_score, f1_score\n\u001b[0;32m----> 2\u001b[0m cmap \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mcm\u001b[38;5;241m.\u001b[39mget_cmap(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mviridis\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m color_dict \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries({k:cmap(i\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m3\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m i,k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m))})\n\u001b[1;32m      4\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m10\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
    "cmap = plt.cm.get_cmap('viridis')\n",
    "color_dict = pd.Series({k:cmap(i/3) for i,k in enumerate(range(3))})\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15, 10))\n",
    "names_ = ['Model Serre_07', 'Human', 'Vgg_Gen_Animal']\n",
    "plt.scatter(df_serre_07[1], df_serre_07[2], label='Model Serre_07', color=color_dict[0])\n",
    "plt.scatter(df_serre_07[1], df_serre_07['Gen'], label='Vgg_Gen_Animal', color=color_dict[2])\n",
    "#plt.scatter(df_serre_07[1], df_serre_07[4], label='Vgg_Gen_Animal', color=color_dict[4])\n",
    "ax.tick_params(axis='y', labelsize=14)\n",
    "plt.xticks(fontsize=20,  fontweight='bold')\n",
    "plt.yticks(fontsize=20,  fontweight='bold')\n",
    "plt.legend(bbox_to_anchor=(1.17, .5), loc='center', fontsize=20)\n",
    "ax.set_ylabel(\"\"\"Model's likelihood\"\"\", size= 24, fontweight='bold' )\n",
    "ax.set_xlabel(\"\"\"Human's Accuracy\"\"\", size= 24, fontweight='bold' )\n",
    "plt.tight_layout()\n",
    "#plt.savefig('IJCNN_fig.5.pdf');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:17.971279Z",
     "iopub.status.busy": "2022-05-13T15:25:17.971125Z",
     "iopub.status.idle": "2022-05-13T15:25:17.976112Z",
     "shell.execute_reply": "2022-05-13T15:25:17.975669Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3111032472.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [81]\u001b[0;36m\u001b[0m\n\u001b[0;31m    for mode_ in [2, 'Gen']\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "for i in df_serre_07[1]:\n",
    "    moy_image = 0\n",
    "    for mode_ in [2, 'Gen']\n",
    "    if float(df_serre_07.iloc[i, 1]) > .5 and float(df_serre_07.iloc[i, mode_]) >.5:\n",
    "        moy_image += (df_serre_07.iloc[i, 1]*df_serre_07.iloc[i, 1] + (1-df_serre_07.iloc[i, 1])*df_serre_07.iloc[i, 1])\n",
    "    print('Average number of correct categorizations common to humans and the mode_' + mode_ +': '+ moy_image/1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "https://github.com/laurentperrinet/PerrinetBednar15/blob/master/notebooks/5%20notebook_figure_animalness.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The networks obtain an accuracy on the 'animal' synset similar to those found in the model and neurophysiological data of [Serre & al (2007)](http://vision.stanford.edu/teaching/cs131_fall1415/lectures/Serre2007.pdf) (about 83\\%). Yet, the bias found in is also present in the dataset used by [Serre & al (2007)](http://vision.stanford.edu/teaching/cs131_fall1415/lectures/Serre2007.pdf).  when we compare the performances of humans on this dataset with the performances achieved by the network on an image-by-image basis we found in  [experiment 1](#exp1). However, we also found a high correspondence (about 84%) between the correct predictions of human and our model. Indeed for some images the networks failed the categorization but the human succeeds and vice versa. For some images both the network and human succeed or failed to categorize an animal. These exemples could be the reflection of the specific features on which humans or our models rely to perform their categorization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus : How did we use the the pre-trained VGG network trained on the [Imagenet](http://image-net.org/) dataset ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo mettre le softmax après"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:17.980144Z",
     "iopub.status.busy": "2022-05-13T15:25:17.979967Z",
     "iopub.status.idle": "2022-05-13T15:25:17.982674Z",
     "shell.execute_reply": "2022-05-13T15:25:17.982163Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scriptname =  'UltraFastCat/bonus_vgg16.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:17.985255Z",
     "iopub.status.busy": "2022-05-13T15:25:17.985018Z",
     "iopub.status.idle": "2022-05-13T15:25:17.991168Z",
     "shell.execute_reply": "2022-05-13T15:25:17.990671Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting UltraFastCat/bonus_vgg16.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {scriptname}\n",
    "\n",
    "#import model's script and set the output file\n",
    "\n",
    "from UltraFastCat.experiment_train import *\n",
    "#from src.model import *\n",
    "from PIL import ImageFile\n",
    "import math\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "filename = f'results/{datetag}_results_vgg16_pytorch_{HOST}.json'\n",
    "print(f'{filename=}')\n",
    "\n",
    "def softmax(vec):\n",
    "    exponential = np.exp(vec)\n",
    "    probabilities = exponential / np.sum(exponential)\n",
    "    return probabilities\n",
    "\n",
    "task = 'animal'\n",
    "match = []\n",
    "class_loader = 'imagenet_label_to_wordnet_synset.json'\n",
    "with open(class_loader, 'r') as fp: \n",
    "    imagenet = json.load(fp)\n",
    "labels = []\n",
    "for a, img_id in enumerate(imagenet):\n",
    "    labels.append(imagenet[img_id]['label'])\n",
    "    syn_ = wn.synset_from_pos_and_offset('n', int(imagenet[img_id]['id'].replace('-n','')))\n",
    "    sem_ = syn_.hypernym_paths()[0]\n",
    "    for i in np.arange(len(sem_)):\n",
    "        if task in sem_[i].lemmas()[0].name() :\n",
    "            match.append(a)\n",
    "            \n",
    "models_vgg['vgg16'] = torchvision.models.vgg16(pretrained=True)\n",
    "likelihood = {}\n",
    "top_1 = {}\n",
    "serre = ['targets', 'distractors']\n",
    "paths['animal']['test'] = '/home/INT/jeremie.j/Serre_2007'\n",
    "model_name = 'vgg16'\n",
    "#def main():\n",
    "if os.path.isfile(filename):\n",
    "    test_serre = pd.read_json(filename)\n",
    "else:\n",
    "    i_trial = 0\n",
    "    test_serre = pd.DataFrame([], columns=['model', 'goal', 'fps', 'time', 'i_image', 'filename', \n",
    "                                           'like_1', 'like_2', 'top_1_1', 'top_1_2', 'device_type']) \n",
    "        # image preprocessing\n",
    "    (dataset_sizes, dataloaders, image_datasets, data_transforms) = datasets_transforms(image_size=args.image_size, batch_size=1)\n",
    "    pprint('GO!')\n",
    "    for i_image, (data, label) in enumerate(dataloaders[task]['test']):\n",
    "        for i in ['1', '2']:\n",
    "            likelihood[i], top_1[i] = 0,0\n",
    "        data, label = data.to(device), label.to(device)\n",
    "        model = models_vgg['vgg16'].to(device)\n",
    "        temp_ = 0\n",
    "        with torch.no_grad():\n",
    "            goal = 'target' if 'target' in image_datasets[task]['test'].imgs[i_image][0] else 'distractor'\n",
    "            tic = time.time()\n",
    "            out = model(data).squeeze(0)\n",
    "            percentage = torch.nn.functional.softmax(out, dim=0) * 100\n",
    "            for idx in np.arange(0,1000,1):\n",
    "                if idx in match:\n",
    "                    likelihood['1'] += percentage[idx].item()\n",
    "                    likelihood['2'] += np.exp(percentage[idx].item())  \n",
    "            likelihood['2'] = softmax(likelihood['2'])\n",
    "            top_1['1'] = 'target' if likelihood['1']>50 else 'distractor'\n",
    "            top_1['2'] = 'target' if likelihood['2']>50 else 'distractor' \n",
    "            elapsed_time = time.time() - tic\n",
    "        test_serre.loc[i_trial] = {'model':model_name, 'like_1':likelihood['1'],'like_2':likelihood['2'],\n",
    "                                   'top_1_1':top_1['1'], 'top_1_2':top_1['2'], 'goal':goal, 'time':elapsed_time, \n",
    "                                   'fps': 1/elapsed_time, 'i_image':i_image, 'filename':image_datasets[task]['test'].imgs[i_image][0],\n",
    "                                   'device_type':device.type}\n",
    "        i_trial += 1\n",
    "test_serre.to_json(filename)\n",
    "#main()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:17.993877Z",
     "iopub.status.busy": "2022-05-13T15:25:17.993667Z",
     "iopub.status.idle": "2022-05-13T15:25:18.538724Z",
     "shell.execute_reply": "2022-05-13T15:25:18.538068Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating file results/2022-05-13_config_args.json\n",
      "On date 2022-05-13 , Running benchmark on host babbage  with device cuda\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - '/home/laurent/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/corpus/util.py:84\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 84\u001b[0m     root \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mzip_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet.zip/wordnet/\u001b[0m\n\n  Searched in:\n    - '/home/laurent/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/metagit/JNJER/2022-03_UltraFastCat/UltraFastCat/bonus_vgg16.py:4\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#import model's script and set the output file\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mUltraFastCat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperiment_train\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#from src.model import *\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageFile\n",
      "File \u001b[0;32m~/metagit/JNJER/2022-03_UltraFastCat/UltraFastCat/experiment_train.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageFile\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n",
      "File \u001b[0;32m~/metagit/JNJER/2022-03_UltraFastCat/src/model.py:2\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnnf\u001b[39;00m\n",
      "File \u001b[0;32m~/metagit/JNJER/2022-03_UltraFastCat/src/init.py:116\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    114\u001b[0m reverse_id_labels \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i_img, img_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(Imagenet_urls_ILSVRC_2016):\n\u001b[0;32m--> 116\u001b[0m     syn_\u001b[38;5;241m=\u001b[39m \u001b[43mwn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msynset_from_pos_and_offset\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mint\u001b[39m(img_id\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[1;32m    117\u001b[0m     reverse_id_labels[img_id] \u001b[38;5;241m=\u001b[39m syn_\u001b[38;5;241m.\u001b[39mlemmas()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mname()\n\u001b[1;32m    118\u001b[0m     labels\u001b[38;5;241m.\u001b[39mappend(syn_\u001b[38;5;241m.\u001b[39mlemmas()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mname())\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/corpus/util.py:121\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLazyCorpusLoader object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# This looks circular, but its not, since __load() changes our\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# __class__ to something new:\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/corpus/util.py:86\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m             root \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubdir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mzip_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n\u001b[0;32m---> 86\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Load the corpus.\u001b[39;00m\n\u001b[1;32m     89\u001b[0m corpus \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__reader_cls(root, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__kwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/corpus/util.py:81\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m         root \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[1;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - '/home/laurent/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "%run {scriptname}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:18.544684Z",
     "iopub.status.busy": "2022-05-13T15:25:18.544168Z",
     "iopub.status.idle": "2022-05-13T15:25:18.563676Z",
     "shell.execute_reply": "2022-05-13T15:25:18.563116Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'HOST' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [85]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetag\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_results_vgg16_pytorch_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mHOST\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      2\u001b[0m results_bonus_vgg16 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_json(filename)\n\u001b[1;32m      3\u001b[0m results_bonus_vgg16\n",
      "\u001b[0;31mNameError\u001b[0m: name 'HOST' is not defined"
     ]
    }
   ],
   "source": [
    "filename = f'results/{datetag}_results_vgg16_pytorch_{HOST}.json'\n",
    "results_bonus_vgg16 = pd.read_json(filename)\n",
    "results_bonus_vgg16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-13T15:25:18.568913Z",
     "iopub.status.busy": "2022-05-13T15:25:18.568447Z",
     "iopub.status.idle": "2022-05-13T15:25:18.599391Z",
     "shell.execute_reply": "2022-05-13T15:25:18.598781Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results_bonus_vgg16' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [86]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtop_1_1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtop_1_2\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m names:\n\u001b[0;32m----> 6\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(f1_score(\u001b[43mresults_bonus_vgg16\u001b[49m[name],\n\u001b[1;32m      7\u001b[0m                             results_bonus_vgg16[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoal\u001b[39m\u001b[38;5;124m\"\u001b[39m],average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmicro\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      8\u001b[0m df_acc \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m: results},index \u001b[38;5;241m=\u001b[39m names)\n\u001b[1;32m      9\u001b[0m ax \u001b[38;5;241m=\u001b[39m df_acc\u001b[38;5;241m.\u001b[39mplot\u001b[38;5;241m.\u001b[39mbar(rot\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(fig_width, fig_width\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m), fontsize \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m18\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results_bonus_vgg16' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
    "fig_width = 15\n",
    "results = []\n",
    "names = ['top_1_1', 'top_1_2']\n",
    "for name in names:\n",
    "    results.append(f1_score(results_bonus_vgg16[name],\n",
    "                            results_bonus_vgg16[\"goal\"],average='micro'))\n",
    "df_acc = pd.DataFrame({'': results},index = names)\n",
    "ax = df_acc.plot.bar(rot=30, figsize=(fig_width, fig_width//2), fontsize = 18)\n",
    "ax.hlines(xmin=-.5, xmax=len(models_vgg)-.5, y=1/2, ls='--', ec='k', label='chance level')\n",
    "plt.legend(bbox_to_anchor=(1.15, .5), loc='right')\n",
    "for container in ax.containers: ax.bar_label(container, padding=-50, color='black', fontsize=14, fmt='%.3f', rotation=90)\n",
    "ax.set_ylabel('Accuracy', size= 20)\n",
    "ax.set_xlabel('Methods', size= 20)\n",
    "ax.set_title(f'Animal images f1 score for re-trained models with different depth', size=22)\n",
    "#plt.savefig('Cosyne_fig2.1.pdf')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "%%writefile {scriptname}\n",
    "\n",
    "#import model's script and set the output file\n",
    "\n",
    "from Prunning.experiment_train import *\n",
    "from PIL import ImageFile\n",
    "import math\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "filename = f'results/{datetag}_results_vgg16_{HOST}.json'\n",
    "print(f'{filename=}')\n",
    "\n",
    "task = 'animal'\n",
    "\n",
    "match = []\n",
    "class_loader = 'imagenet_label_to_wordnet_synset.json'\n",
    "with open(class_loader, 'r') as fp: \n",
    "    imagenet = json.load(fp)\n",
    "for a, img_id in enumerate(imagenet):\n",
    "    labels.append(imagenet[img_id]['label'])\n",
    "    syn_ = wn.synset_from_pos_and_offset('n', int(imagenet[img_id]['id'].replace('-n','')))\n",
    "    sem_ = syn_.hypernym_paths()[0]\n",
    "    for i in np.arange(len(sem_)):\n",
    "        if task in sem_[i].lemmas()[0].name() :\n",
    "            match.append(a)\n",
    "            \n",
    "models_vgg['vgg16'] = torchvision.models.vgg16(pretrained=True)\n",
    "likelihood = {}\n",
    "top_1 = {}\n",
    "\n",
    "model_name = 'vgg16'\n",
    "def main():\n",
    "    if os.path.isfile(filename):\n",
    "        test = pd.read_json(filename)\n",
    "    else:\n",
    "        i_trial = 0\n",
    "        test = pd.DataFrame([], columns=['model', 'goal', 'fps', 'time', 'i_image', 'filename', 'top_1_1', 'top_1_2', 'device_type']) \n",
    "            # image preprocessing\n",
    "        (dataset_sizes, dataloaders, image_datasets, data_transforms) = datasets_transforms(image_size=args.image_size, batch_size=1)\n",
    "        pprint('GO!')\n",
    "        for i_image, (data, label) in enumerate(dataloaders[task]['test']):\n",
    "            for i in ['1', '2']:\n",
    "                likelihood[i], top_1[i] = 0,0\n",
    "            data, label = data.to(device), label.to(device)\n",
    "            model = models_vgg['vgg16'].to(device)\n",
    "            temp_ = 0\n",
    "            with torch.no_grad():\n",
    "                goal = 'target' if 'target' in image_datasets[task]['test'].imgs[i_image][0] else 'distractor'\n",
    "                tic = time.time()\n",
    "                out = model(data).squeeze(0)\n",
    "                percentage = torch.nn.functional.softmax(out, dim=0) * 100\n",
    "                for idx in np.arange(0,1000,1):\n",
    "                    if idx in match:\n",
    "                        likelihood['1'] += percentage[idx].item()\n",
    "                        likelihood['2'] += math.exp(percentage[idx].item())\n",
    "                    else:\n",
    "                        temp_ += math.exp(percentage[idx].item())\n",
    "                likelihood['1'] = math.exp(likelihood['1'])/math.exp(1-likelihood['1'])   \n",
    "                likelihood['2'] = likelihood['2']/temp_\n",
    "                top_1['1'] = 'target' if likelihood['1']>50 else 'distractor'\n",
    "                top_1['2'] = 'target' if likelihood['2']>50 else 'distractor' \n",
    "                elapsed_time = time.time() - tic\n",
    "            test.loc[i_trial] = {'model':model_name, 'top_1_1':top_1['1'], 'top_1_2':top_1['2'], 'goal':goal, 'time':elapsed_time, 'fps': 1/elapsed_time,\n",
    "                                  'i_image':i_image, 'filename':image_datasets[task]['test'].imgs[i_image][0], 'device_type':device.type}\n",
    "            i_trial += 1\n",
    "    test.to_json(filename)\n",
    "main()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Todo : CCl"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "nteract": {
   "version": "0.28.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
