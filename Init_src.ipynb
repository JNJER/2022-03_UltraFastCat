{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7adfaf06",
   "metadata": {},
   "source": [
    "# Ultra-fast categorization of image containing animals *in computo*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78382ad5-66d9-45fc-b7e5-4a7b9f13d5da",
   "metadata": {},
   "source": [
    "Hi! I am  [Jean-Nicolas Jérémie](https://github.com/JNJER) in this notebook, I will use the [Pytorch](https://pytorch.org/) library for running the networks and the [pandas](https://pandas.pydata.org/docs/getting_started/index.html) library to collect and display the results. This notebook focused on the training and the test of Deep convolutional neuronal networks (DCNNs) for ecological tasks such as detecting an animal in a natural scene.\n",
    "\n",
    "Our coding strategy is to build up a small library as a package of scripts in the `src` folder and to run all calls to that library from this notebook. This notebook contains the scripts necessary to set the variables of the definition and the training of the networks (`init.py` & `model.py`). Thus this notebook allow the generation of dataset based on the [Imagenet database](https://www.image-net.org/) dedicates to a specific ecologic task (`dataset.py`). \n",
    "\n",
    "The set of labels of the Imagenet database is based on a large lexical database of English: [Wordnet](https://wordnet.princeton.edu/) . The nouns, verbs, adjectives, and adverbs in this database are grouped into a graphical set of cognitive synonyms (synset), each expressing a distinct concept. These synsets are linked between them by employing a small number of conceptual relations. I used the hyperonym link, for instance, a German shepherd is kind of a dog and a dog is a kind of an animal thus defining an hyperonym path. So the synset 'animal' is in the hyperonym path of the synset 'German sheperd'. Based on this relation, we selected a specific subset of labels in the Imagenet database to build our datasets.\n",
    "\n",
    "This notebook was done during my thesis at the Neurosciences Institute of Timone (INT) under the supervision of [Laurent PERRINET](https://laurentperrinet.github.io/). It is curated in the following [github repo](https://github.com/JNJER/2022-03_UltraFastCat)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "645d51cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-16T06:49:34.939462Z",
     "iopub.status.busy": "2022-05-16T06:49:34.937874Z",
     "iopub.status.idle": "2022-05-16T06:49:36.012534Z",
     "shell.execute_reply": "2022-05-16T06:49:36.013668Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%mkdir -p src\n",
    "%mkdir -p results\n",
    "%mkdir -p models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d4fc8f",
   "metadata": {},
   "source": [
    "## Initialization of the libraries/variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2492bf",
   "metadata": {},
   "source": [
    "First of all, a `src/init.py` to define all our usefull variables like the new labels to learn, the number of training images or the root. Also, we importe libraries to train the networks and display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe0c067d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-16T06:49:36.025568Z",
     "iopub.status.busy": "2022-05-16T06:49:36.024163Z",
     "iopub.status.idle": "2022-05-16T06:49:36.100176Z",
     "shell.execute_reply": "2022-05-16T06:49:36.101400Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-4db96e36003d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wordnet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'omw-1.4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mscriptname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'src/init.py'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "scriptname = 'src/init.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5f1b5e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-16T06:49:36.109816Z",
     "iopub.status.busy": "2022-05-16T06:49:36.108213Z",
     "iopub.status.idle": "2022-05-16T06:49:36.129839Z",
     "shell.execute_reply": "2022-05-16T06:49:36.131086Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing {scriptname}\n"
     ]
    }
   ],
   "source": [
    "%%writefile {scriptname}\n",
    "\n",
    "# Importing libraries\n",
    "import torch\n",
    "import argparse\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('xtick', labelsize=18)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=18)    # fontsize of the tick labels\n",
    "import numpy as np\n",
    "from nltk.corpus import wordnet as wn\n",
    "#from numpy import random\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "\n",
    "from time import strftime, gmtime\n",
    "datetag = strftime(\"%Y-%m-%d\", gmtime())\n",
    "\n",
    "HOST, device = os.uname()[1], torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    \n",
    "# to store results\n",
    "import pandas as pd\n",
    "\n",
    "def arg_parse():\n",
    "    #DEBUG = 25\n",
    "    DEBUG = 1\n",
    "    parser = argparse.ArgumentParser(description='DCNN_transfer_learning/init.py set root')\n",
    "    parser.add_argument(\"--root\", dest = 'root', help = \"Directory containing images to perform the training\",\n",
    "                        default = '../data', type = str)\n",
    "    parser.add_argument(\"--folders\", dest = 'folders', help =  \"Set the training, validation and testing folders relative to the root\",\n",
    "                        default = ['test', 'val', 'train'], type = list)\n",
    "    parser.add_argument(\"--tasks\", dest = 'tasks', help =  \"Set the training, validation and testing folders relative to the root\",\n",
    "                        default = ['animal'], type = list)\n",
    "    parser.add_argument(\"--goals\", dest = 'goals', help =  \"Set the training, validation and testing folders relative to the root\",\n",
    "                        default = ['target', 'distractor'], type = list)\n",
    "    parser.add_argument(\"--N_images\", dest = 'N_images', help =\"Set the number of images per classe in the train folder\",\n",
    "                        default = [600//DEBUG, 400//DEBUG, 1000//DEBUG], type = list)\n",
    "    parser.add_argument(\"--HOST\", dest = 'HOST', help = \"Set the name of your machine\",\n",
    "                    default=HOST, type = str)\n",
    "    parser.add_argument(\"--datetag\", dest = 'datetag', help = \"Set the datetag of the result's file\",\n",
    "                    default = datetag, type = str)\n",
    "    parser.add_argument(\"--image_size\", dest = 'image_size', help = \"Set the default image_size of the input\",\n",
    "                    default = 256)\n",
    "    parser.add_argument(\"--image_sizes\", dest = 'image_sizes', help = \"Set the image_sizes of the input for experiment 2 (downscaling)\",\n",
    "                    default = [64, 128, 256, 512], type = list)\n",
    "    parser.add_argument(\"--num_epochs\", dest = 'num_epochs', help = \"Set the number of epoch to perform during the traitransportationning phase\",\n",
    "                    default = 25//DEBUG)\n",
    "    parser.add_argument(\"--batch_size\", dest = 'batch_size', help=\"Set the batch size\", default = 32)\n",
    "    parser.add_argument(\"--lr\", dest = 'lr', help=\"Set the learning rate\", default = 0.0001)\n",
    "    parser.add_argument(\"--momentum\", dest = 'momentum', help=\"Set the momentum\", default = 0.9)\n",
    "    parser.add_argument(\"--beta2\", dest = 'beta2', help=\"Set the second momentum - use zero for SGD\", default = 0.)\n",
    "    parser.add_argument(\"--url_loader\", dest = 'url_loader', help = \"Set the file containing imagenet urls\",\n",
    "                        default = 'Imagenet_urls_ILSVRC_2016.json', type = str)\n",
    "    parser.add_argument(\"--model_path\", dest = 'model_path', help = \"Set the path to the pre-trained model\",\n",
    "                        default = 'models/re-trained_', type = str)\n",
    "    parser.add_argument(\"--model_names\", dest = 'model_names', help = \"Modes for the new trained networks\",\n",
    "                        default = ['vgg16_gen', 'vgg16_scale', 'vgg16_gray', ], type = list)\n",
    "    return parser.parse_args()\n",
    "\n",
    "args = arg_parse()\n",
    "datetag = args.datetag\n",
    "json_fname = os.path.join('results', datetag + '_config_args.json')\n",
    "load_parse = False # False to custom the config\n",
    "\n",
    "if load_parse:\n",
    "    with open(json_fname, 'rt') as f:\n",
    "        print(f'file {json_fname} exists: LOADING')\n",
    "        override = json.load(f)\n",
    "        args.__dict__.update(override)\n",
    "else:\n",
    "    print(f'Creating file {json_fname}')\n",
    "    with open(json_fname, 'wt') as f:\n",
    "        json.dump(vars(args), f, indent=4)\n",
    "    \n",
    "# matplotlib parameters\n",
    "colors = ['b', 'r', 'k', 'g', 'm', 'y']\n",
    "fig_width = 20\n",
    "phi = (np.sqrt(5)+1)/2 # golden ratio for the figures :-)\n",
    "\n",
    "#to plot & display \n",
    "def pprint(message): #display function\n",
    "    print('-'*len(message))\n",
    "    print(message)\n",
    "    print('-'*len(message))\n",
    "    \n",
    "#DCCN training\n",
    "print('On date', args.datetag, ', Running benchmark on host', args.HOST, ' with device', device.type)\n",
    "\n",
    "paths_task ={}\n",
    "paths = {}\n",
    "class_wnids = {}\n",
    "N_images_per_class = {}\n",
    "match = {}\n",
    "\n",
    "for task in args.tasks :\n",
    "    paths_task[task] = os.path.join(args.root, task) # data path\n",
    "    os.makedirs(paths_task[task], exist_ok=True)\n",
    "    paths[task] = {}\n",
    "    match[task] = []\n",
    "    for folder, N_image in zip(args.folders, args.N_images):\n",
    "        paths[task][folder] = os.path.join(args.root, task, folder) # data path\n",
    "        N_images_per_class[folder] = N_image\n",
    "        os.makedirs(paths[task][folder], exist_ok=True)\n",
    "        class_wnids[str(task)] = {}\n",
    "        for goal in args.goals:\n",
    "            class_wnids[str(task)][str(goal)] = []\n",
    "    \n",
    "with open(args.url_loader) as json_file:\n",
    "    Imagenet_urls_ILSVRC_2016 = json.load(json_file)\n",
    "\n",
    "# gathering labels\n",
    "labels = []\n",
    "reverse_id_labels = {}\n",
    "for i_img, img_id in enumerate(Imagenet_urls_ILSVRC_2016):\n",
    "    syn_= wn.synset_from_pos_and_offset('n', int(img_id.replace('n','')))\n",
    "    reverse_id_labels[img_id] = syn_.lemmas()[0].name()\n",
    "    labels.append(syn_.lemmas()[0].name())\n",
    "    sem_ = syn_.hypernym_paths()[0]\n",
    "    for task in args.tasks :\n",
    "        for i in np.arange(len(sem_)):\n",
    "            if sem_[i].lemmas()[0].name() == str(task) :\n",
    "                class_wnids[str(task)]['target'].append(img_id)\n",
    "                match[task].append(i_img)\n",
    "        if img_id not in class_wnids[str(task)]['target']:\n",
    "            class_wnids[str(task)]['distractor'].append(img_id)\n",
    "\n",
    "        \n",
    "# a reverse look-up-table giving the index of a given label (within the whole set of imagenet labels)\n",
    "reverse_labels = {}\n",
    "for i_label, label in enumerate(labels):\n",
    "    reverse_labels[label] = i_label\n",
    "\n",
    "# a reverse look-up-table giving the label of a given index in the last layer of the new model (within the sub-set of classes)\n",
    "reverse_model_labels = args.tasks\n",
    "reverse_model_labels.sort()\n",
    "\n",
    "pprint('List of Pre-selected tasks : ')\n",
    "# choosing the selected classes for recognition\n",
    "for task in args.tasks :\n",
    "    print(len(class_wnids[str(task)]['target']), ' Targets for the task :', task)\n",
    "    print(len(class_wnids[str(task)]['distractor']), ' Distractors for the task :', task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e137aff6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-16T06:49:36.140860Z",
     "iopub.status.busy": "2022-05-16T06:49:36.139464Z",
     "iopub.status.idle": "2022-05-16T06:49:37.785271Z",
     "shell.execute_reply": "2022-05-16T06:49:37.786371Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/hpc/neopto/model/2022-03_UltraFastCat/src/init.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ytick'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabelsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m18\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# fontsize of the tick labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwordnet\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;31m#from numpy import random\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "%run src/init.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd8423c",
   "metadata": {},
   "source": [
    "## Download the `train` & `val` dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb73e4b5-b648-4626-bb79-ac1644afec5c",
   "metadata": {},
   "source": [
    "In the dataset.py, we use an archive of the Imagenet fall 2011 urls to populate datasets based on the pre-selected synsets listed in the `src/init.py` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eea089d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-16T06:49:37.794839Z",
     "iopub.status.busy": "2022-05-16T06:49:37.793484Z",
     "iopub.status.idle": "2022-05-16T06:49:37.798422Z",
     "shell.execute_reply": "2022-05-16T06:49:37.797282Z"
    }
   },
   "outputs": [],
   "source": [
    "scriptname = 'src/dataset.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "326d6026",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-16T06:49:37.811126Z",
     "iopub.status.busy": "2022-05-16T06:49:37.809582Z",
     "iopub.status.idle": "2022-05-16T06:49:37.832577Z",
     "shell.execute_reply": "2022-05-16T06:49:37.833650Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/dataset.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {scriptname}\n",
    "\n",
    "from src.init import *  \n",
    "verbose = False\n",
    "\n",
    "with open(args.url_loader) as json_file:\n",
    "    Imagenet_urls_ILSVRC_2016 = json.load(json_file)\n",
    "\n",
    "def clean_list(list_dir, patterns=['.DS_Store']):\n",
    "    for pattern in patterns:\n",
    "        if pattern in list_dir: list_dir.remove('.DS_Store')\n",
    "    return list_dir\n",
    "\n",
    "import imageio\n",
    "def get_image(img_url, timeout=3., min_content=3, verbose=verbose):\n",
    "    try:\n",
    "        img_resp = imageio.imread(img_url)\n",
    "        if (len(img_resp.shape) < min_content): # TODO : raise error when min_content is not reached\n",
    "            if verbose : print(f\"Url {img_url} does not have enough content\")\n",
    "            return False\n",
    "        else:\n",
    "            if verbose : print(f\"Success with url {img_url}\")\n",
    "            return img_resp\n",
    "    except Exception as e:\n",
    "        if verbose : print(f\"Failed with {e} for url {img_url}\")\n",
    "        return False # did not work\n",
    "\n",
    "import hashlib # jah.\n",
    "\n",
    "# train, val and test folders\n",
    "    \n",
    "list_urls = {}\n",
    "list_img_name_used = {}\n",
    "for task in class_wnids :\n",
    "    list_urls[task] = {}\n",
    "    list_img_name_used[task] = {}\n",
    "    for goal in class_wnids[task]:\n",
    "        list_urls[task][goal] = {}\n",
    "        for class_wnid in class_wnids[task][goal]:\n",
    "            list_urls[task][goal][class_wnid] = Imagenet_urls_ILSVRC_2016[str(class_wnid)]\n",
    "        np.random.shuffle(list_urls[task][goal][class_wnid])\n",
    "        list_img_name_used[task][goal] = []\n",
    "            \n",
    "    \n",
    "# train, val and test folders\n",
    "for task in args.tasks:\n",
    "    pprint(f'Task \\\"{task}\\\"')\n",
    "    for folder in args.folders :\n",
    "        print(f'Folder \\\"{folder}\\\"')\n",
    "        filename = f'results/{datetag}_dataset_{folder}_{args.HOST}.json'\n",
    "        columns = ['task', 'goal', 'img_url', 'img_name', 'is_flickr', 'dt', 'worked', 'class_wnid', 'class_name']\n",
    "        if os.path.isfile(filename):\n",
    "            df_dataset = pd.read_json(filename)\n",
    "        else:\n",
    "            df_dataset = pd.DataFrame([], columns=columns)\n",
    "        for goal in args.goals :\n",
    "            print(f'Scraping images for task \\\"{task}\\\" : {goal} ')\n",
    "            task_goal_folder = os.path.join(paths[task][folder], goal)\n",
    "            os.makedirs(task_goal_folder, exist_ok=True)\n",
    "            list_img_name_used[task][goal] += clean_list(os.listdir(os.path.join(paths[task][folder], goal))) # join two lists\n",
    "            while (len(clean_list(os.listdir(task_goal_folder))) < N_images_per_class[folder]):\n",
    "                class_wnid = np.random.choice(class_wnids[task][goal], 1)[0]\n",
    "                pos = class_wnids[task][goal].index(class_wnid)\n",
    "                class_name = reverse_id_labels[class_wnid]\n",
    "                # pick and remove element from shuffled list\n",
    "                if len(list_urls[task][goal][class_wnid])==0:\n",
    "                    del class_wnids[task][goal][pos], list_urls[task][goal][class_wnid]\n",
    "                else:\n",
    "                    img_url = list_urls[task][goal][class_wnid].pop()\n",
    "\n",
    "                    if len(df_dataset[df_dataset['img_url']==img_url])==0 : # we have not yet tested this URL yet\n",
    "\n",
    "                        # Transform URL into filename\n",
    "                        # https://laurentperrinet.github.io/sciblog/posts/2018-06-13-generating-an-unique-seed-for-a-given-filename.html\n",
    "                        img_name = hashlib.sha224(img_url.encode('utf-8')).hexdigest() + '.png'\n",
    "\n",
    "                        if img_url.split('.')[-1] in ['.tiff', '.bmp', 'jpe', 'gif']:\n",
    "                            if verbose: print('Bad extension for the img_url', img_url)\n",
    "                            worked, dt = False, 0.\n",
    "                        # make sure it was not used in other folders\n",
    "                        elif not (img_name in list_img_name_used[task][goal]):\n",
    "                            tic = time.time()\n",
    "                            img_content = get_image(img_url, verbose=verbose)\n",
    "                            dt = time.time() - tic\n",
    "                            worked = img_content is not False\n",
    "                            if worked:\n",
    "                                if verbose : print('Good URl, now saving', img_url, ' in', task_goal_folder, ' as', img_name)\n",
    "                                imageio.imsave(os.path.join(task_goal_folder, img_name), img_content, format='png')\n",
    "                                list_img_name_used[task][goal].append(img_name)\n",
    "                        df_dataset.loc[len(df_dataset.index)] = {'task': task, 'goal': goal, 'img_url':img_url, 'img_name':img_name, 'is_flickr':1 if 'flickr' in img_url else 0, 'dt':dt,\n",
    "                                        'worked':worked, 'class_wnid':class_wnid, 'class_name':class_name}\n",
    "                        df_dataset.to_json(filename)\n",
    "                        print(f'\\r{len(clean_list(os.listdir(task_goal_folder)))} / {N_images_per_class[folder]}', end='\\n' if verbose else '', flush=not verbose)\n",
    "\n",
    "        if (len(clean_list(os.listdir(task_goal_folder))) < N_images_per_class[folder]) and (len(list_urls[task][goal]) == 0): \n",
    "            print('Not enough working url to complete the dataset') \n",
    "\n",
    "    df_dataset.to_json(filename)\n",
    "\n",
    "print('\\n')\n",
    "pprint(f'Some random images :')\n",
    "import imageio\n",
    "N_image_i = 4\n",
    "image_plot_paths = {}\n",
    "task_folder = {}\n",
    "x = 0\n",
    "folder = 'train'\n",
    "fig, axs = plt.subplots(len(args.tasks)*len(args.goals), N_image_i, figsize=(fig_width, fig_width))\n",
    "for task in args.tasks:\n",
    "    for goal in args.goals:\n",
    "        task_goal_folder = os.path.join(paths[task][folder], goal)\n",
    "        image_plot_paths = os.listdir(task_goal_folder)\n",
    "        for i_image in np.arange(N_image_i):\n",
    "            ax = axs[x][i_image]\n",
    "            path = os.path.join(task_goal_folder, image_plot_paths[i_image])\n",
    "            ax.imshow(imageio.imread(path))\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])  \n",
    "            if i_image%5 == 0:\n",
    "                ax.set_ylabel((task+' '+goal), fontsize = 18)\n",
    "        x +=1\n",
    "fig.set_facecolor(color='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0af8e3bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-16T06:49:37.842915Z",
     "iopub.status.busy": "2022-05-16T06:49:37.841565Z",
     "iopub.status.idle": "2022-05-16T06:49:37.923019Z",
     "shell.execute_reply": "2022-05-16T06:49:37.924121Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/hpc/neopto/model/2022-03_UltraFastCat/src/dataset.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl_loader\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/hpc/neopto/model/2022-03_UltraFastCat/src/init.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ytick'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabelsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m18\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# fontsize of the tick labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwordnet\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;31m#from numpy import random\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "%run {scriptname}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c90dd68",
   "metadata": {},
   "source": [
    "## Transfer learning and dataset config\n",
    "\n",
    "On the model.py we first define the `transforme`functions for the datasets. To perform image augmentation we apply the Pytorch `AutoAugment` function to the `train` and `val` dataset. I also add a grayscale, shuffle and resize function in order to test different training strategies and test the networks on various conditions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ed8f950",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-16T06:49:37.932712Z",
     "iopub.status.busy": "2022-05-16T06:49:37.931329Z",
     "iopub.status.idle": "2022-05-16T06:49:37.936406Z",
     "shell.execute_reply": "2022-05-16T06:49:37.935241Z"
    }
   },
   "outputs": [],
   "source": [
    "scriptname = 'src/model.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4b4b0c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-16T06:49:37.947564Z",
     "iopub.status.busy": "2022-05-16T06:49:37.946101Z",
     "iopub.status.idle": "2022-05-16T06:49:37.967298Z",
     "shell.execute_reply": "2022-05-16T06:49:37.966107Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {scriptname}\n",
    "\n",
    "from src.init import *  \n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as nnf\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.nn as nn\n",
    "\n",
    "class ShufflePatches(object): #https://stackoverflow.com/questions/66962837/shuffle-patches-in-image-batch\n",
    "    def __init__(self, patch_size):\n",
    "        self.ps = patch_size\n",
    "\n",
    "    def __call__(self, x):\n",
    "        # divide the batch of images into non-overlapping patches\n",
    "        u = nnf.unfold(x.unsqueeze(dim=0), kernel_size=self.ps, stride=self.ps, padding=0)\n",
    "        # permute the patches of each image in the batch\n",
    "        pu = torch.cat([b_[:, torch.randperm(b_.shape[-1])][None,...] for b_ in u], dim=0)\n",
    "        # fold the permuted patches back together\n",
    "        f = nnf.fold(pu, x.shape[-2:], kernel_size=self.ps, stride=self.ps, padding=0)\n",
    "        return f.squeeze(dim=0)\n",
    "\n",
    "# normalization used to train VGG\n",
    "# see https://pytorch.org/hub/pytorch_vision_vgg/\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "transforms_norm = transforms.Normalize(mean=mean, std=std) # to normalize colors on the imagenet dataset\n",
    "\n",
    "import seaborn as sns\n",
    "import sklearn.metrics\n",
    "from scipy import stats\n",
    "from scipy.special import logit, expit\n",
    "\n",
    "image_datasets = {}\n",
    "dataloaders = {}\n",
    "dataset_sizes = {}\n",
    "\n",
    "# VGG-16 datasets initialisation\n",
    "def datasets_transforms(image_size=args.image_size, p=0, shuffle=args.image_size , num_workers=1, angle=0, batch_size=args.batch_size, **kwargs):\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.Resize((int(image_size), int(image_size))),\n",
    "            transforms.AutoAugment(), # https://pytorch.org/vision/master/transforms.html#torchvision.transforms.AutoAugment\n",
    "            transforms.RandomGrayscale(p=p),\n",
    "            transforms.ToTensor(),      # Convert the image to pyTorch Tensor data type.\n",
    "            transforms_norm ]),\n",
    "\n",
    "        'val': transforms.Compose([\n",
    "            transforms.Resize((int(image_size), int(image_size))),\n",
    "            transforms.AutoAugment(), \n",
    "            transforms.RandomGrayscale(p=p),\n",
    "            transforms.ToTensor(),    \n",
    "            transforms_norm ]),\n",
    "\n",
    "        'test': transforms.Compose([\n",
    "            transforms.Resize((int(image_size), int(image_size))),\n",
    "            transforms.RandomGrayscale(p=p),\n",
    "            transforms.ToTensor(),\n",
    "            transforms_norm, \n",
    "            ShufflePatches(patch_size=(shuffle,shuffle)) ]), # our new transform to shuffle patches of images\n",
    "    }\n",
    "    \n",
    "    for task in args.tasks:\n",
    "        image_datasets[task] = {\n",
    "            folder: datasets.ImageFolder(\n",
    "                paths[task][folder], \n",
    "                transform=data_transforms[folder]\n",
    "            )\n",
    "            for folder in args.folders\n",
    "        }\n",
    "\n",
    "        dataloaders[task] = {\n",
    "            folder: torch.utils.data.DataLoader(\n",
    "                image_datasets[task][folder], batch_size=batch_size,\n",
    "                shuffle=True if folder == \"train\" else False, num_workers=num_workers\n",
    "            )\n",
    "            for folder in args.folders\n",
    "        }\n",
    "\n",
    "        dataset_sizes[task] = {folder: len(image_datasets[task][folder]) for folder in args.folders}\n",
    "\n",
    "    return dataset_sizes, dataloaders, image_datasets, data_transforms\n",
    "\n",
    "(dataset_sizes, dataloaders, image_datasets, data_transforms) = datasets_transforms(image_size=args.image_size)\n",
    "\n",
    "for task in args.tasks :\n",
    "    pprint(task)\n",
    "    for folder in args.folders : print(f\"Loaded {dataset_sizes[task][folder]} images under {folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfc11549",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-16T06:49:37.976442Z",
     "iopub.status.busy": "2022-05-16T06:49:37.975058Z",
     "iopub.status.idle": "2022-05-16T06:49:38.011842Z",
     "shell.execute_reply": "2022-05-16T06:49:38.013099Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/hpc/neopto/model/2022-03_UltraFastCat/src/model.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnnf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/hpc/neopto/model/2022-03_UltraFastCat/src/init.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ytick'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabelsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m18\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# fontsize of the tick labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwordnet\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;31m#from numpy import random\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "%run {scriptname}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
